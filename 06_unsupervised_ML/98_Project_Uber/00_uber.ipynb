{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Uber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"./assets/ny.png\" alt=\"drawing\" width=\"800\"/>\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read \n",
    "    * https://app.jedha.co/course/projects-unsupervised-machine-learning-ft/uber-pickups-ft\n",
    "\n",
    "* Goals \n",
    "    * Make sure the driver are at the right place at the right time such that wating time for the user does not exceed 5 to 7 minutes \n",
    "    * Ideally app would recommend hot-zones in major cities to be in at any given time of day\n",
    "    * Create an algorithm to find hot zones\n",
    "    * Visualize results on a dashboard \n",
    "\n",
    "* Instructions \n",
    "    * Get the data\n",
    "    * Focus on New-York\n",
    "    * Use cluster coordinates to pin hot zones\n",
    "        * Pickup locations can be gathered into different clusters. Use cluster coordinates to pin hot zones\n",
    "    * Create maps with plotly\n",
    "    * Start small then generalize\n",
    "        * Pick one day and a given hour\n",
    "        * **and then** start to generalize your approach\n",
    "\n",
    "* Deliverables\n",
    "  * Have a map with hot-zones (plotly)\n",
    "  * At least describe hot-zones per day of week\n",
    "  * Compare results with at least : KMeans and DBScan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO & Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DBSCAN \n",
    "  * ~~metric = haversine car la terre est ronde et pas plate (enfin je crois)~~\n",
    "  * ~~unité de epsilon~~\n",
    "  * https://blog.stackademic.com/mastering-clustering-dbscan-a880566704bc\n",
    "* ~~warning KMeans~~\n",
    "  * ~~set OMP_NUM_THREADS=5~~\n",
    "  * ~~Get-ChildItem Env:~~\n",
    "  * ~~echo $env:OMP_NUM_THREADS~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prelude\n",
    "\n",
    "# avoid warnings with KMeans OpenMP memory leaks under windows blablabla...\n",
    "import platform\n",
    "system = platform.system()\n",
    "if system == \"Windows\":\n",
    "  import os\n",
    "  os.environ[\"OMP_NUM_THREADS\"] = \"5\"\n",
    "else:\n",
    "  None\n",
    "\n",
    "\n",
    "import pandas             as pd\n",
    "import plotly.express     as px\n",
    "import numpy              as np\n",
    "import seaborn            as sns\n",
    "import matplotlib.pyplot  as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "# from sklearn.model_selection    import train_test_split, GridSearchCV \n",
    "from sklearn.pipeline           import make_pipeline\n",
    "from sklearn.impute             import SimpleImputer\n",
    "from sklearn.preprocessing      import OneHotEncoder, StandardScaler    \n",
    "from sklearn.compose            import make_column_transformer                  \n",
    "# from sklearn.linear_model       import LinearRegression, Lasso, Ridge\n",
    "# from sklearn.metrics            import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.decomposition      import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "k_AssetsDir     = \"assets/\"\n",
    "# k_FileName    = \"walmart_store_sales.csv\"\n",
    "k_Gold          = 1.618         # gold number for ratio\n",
    "k_Width         = 12\n",
    "k_Height        = k_Width/k_Gold\n",
    "k_WidthPx       = 1024\n",
    "k_HeightPx      = k_WidthPx/k_Gold\n",
    "\n",
    "k_target        = \"weekly_sales\"\n",
    "k_random_state  = 0                       \n",
    "k_test_size     = 20/100        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(f\"assets/taxi-zone-lookup.csv\", nrows=10)\n",
    "display (tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With this file we could relate LocationID to geographical area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(f\"assets/uber-raw-data-janjune-15.csv\", nrows=10)\n",
    "display (tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the locationID from the taxi look up table we could extend the content this DataFrame with Borough and Zone\n",
    "* However, this DataFrame lack longitude and latitude\n",
    "* We need both of them if we want to a tool that helps to deliver services within a 5 min. timeframe\n",
    "    * For example, it is not said if a zone within a borough can/should be consiederd as a \"5 min\" area\n",
    "    * Even though, we would have to take into acount the traffic in order to estimate what is a 5 min zone at 1 PM vs a 5 min zone at 2 AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(f\"assets/uber-raw-data-apr14.csv\", nrows=5)\n",
    "display (tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We cannot use the column Base since we cannot relate it to either a borough or a zone\n",
    "* Indeed, as we can see in the 2015 file, a dispatching base number can be related to multiple affiliated base number and a an affiliated bas number can be related to multiple location id. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>Comments :</b></span>\n",
    "\n",
    "For the reasons explained before, in the rest of this notebook :\n",
    "\n",
    "* We do not use data from 2015\n",
    "* We do not use the taxi zone look up\n",
    "* In files from 2014, we drop the column \"Base\" and keep onyl ``date``, ``latitude`` and ``longitue``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uber_preprocessor(df):\n",
    "  df.columns = df.columns.str.lower()\n",
    "  df.columns = df.columns.str.replace(\"/\", \"_\")\n",
    "\n",
    "  # df[\"base\"] = df[\"base\"].astype(\"category\")\n",
    "  df.drop(columns=\"base\", inplace=True)\n",
    "\n",
    "  df[\"date_time\"] = pd.to_datetime(df[\"date_time\"]) # , dayfirst=True\n",
    "  df[\"year\"] = df[\"date_time\"].dt.year\n",
    "  df[\"month\"] = df[\"date_time\"].dt.month\n",
    "  df[\"day\"] = df[\"date_time\"].dt.day\n",
    "  df[\"weekday\"] = df[\"date_time\"].dt.weekday\n",
    "  df[\"hour\"] = df[\"date_time\"].dt.hour\n",
    "  df[\"minute\"] = df[\"date_time\"].dt.minute\n",
    "  df.drop(columns=\"date_time\", inplace=True)\n",
    "\n",
    "  # may be we could drop hour and min. We will see how it goes \n",
    "  df[\"bin\"] = df[\"hour\"]*12 + df[\"minute\"]//5\n",
    "  # df.drop(columns=\"hour\", inplace=True)\n",
    "  # df.drop(columns=\"minute\", inplace=True)\n",
    "\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"may\"]\n",
    "# months = [\"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\"]            # uncomment/comment this line to take all the months available into account \n",
    "\n",
    "df = pd.DataFrame()\n",
    "for month in months:\n",
    "  tmp_df = pd.read_csv(f\"assets/uber-raw-data-{month}14.csv\")\n",
    "  df = pd.concat([df, tmp_df])\n",
    "\n",
    "df = uber_preprocessor(df)\n",
    "# display(df.sort_values(by=\"bin\", ascending=False))\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes : \n",
    "* In the preprocessed dataframe\n",
    "* A ``bin`` is a time unit of 5 minutes \n",
    "* Ànd so, the ``bin`` column indicates at which ``time bin`` the observation belongs\n",
    "* Each day there are [0, 287] time bins from 00H00 to 23H29\n",
    "* This might be useful later since users are not willing to wait more that 5-7 minutes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"At this point the dataset consists of :\")\n",
    "print(f\"\\t{len(df.shape):>9_} dimensions\")\n",
    "print(f\"\\t{df.shape[0]:>9_} observations\")\n",
    "print(f\"\\t{df.shape[1]:>9_} features    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df = pd.DataFrame ({\n",
    "  \"types\" : df.dtypes.value_counts()\n",
    "})\n",
    "types_df[\"as_%\"] = (100 * types_df[\"types\"]/types_df[\"types\"].sum()).round(2)\n",
    "\n",
    "display(types_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "def quick_View(df):\n",
    "  summary_lst = []\n",
    "  \n",
    "  for col_name in df.columns:\n",
    "    col_dtype               = df[col_name].dtype\n",
    "    num_of_null             = df[col_name].isnull().sum()\n",
    "    percent_of_null         = num_of_null/len(df)\n",
    "    num_of_non_null         = df[col_name].notnull().sum()\n",
    "    num_of_distinct_values  = df[col_name].nunique()\n",
    "    \n",
    "    if num_of_distinct_values <= 10:\n",
    "        distinct_values_counts = df[col_name].value_counts().to_dict()\n",
    "    else:\n",
    "        top_10_values_counts    = df[col_name].value_counts().head(10).to_dict()\n",
    "        distinct_values_counts  = {k: v for k, v in sorted(top_10_values_counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    if col_dtype != \"object\":\n",
    "       max_of_col = df[col_name].max()\n",
    "       min_of_col = df[col_name].min()\n",
    "       outlier_hi = df[col_name].mean() + 3*df[col_name].std()\n",
    "       outlier_lo = df[col_name].mean() - 3*df[col_name].std()\n",
    "    else:\n",
    "       max_of_col = -1\n",
    "       min_of_col =  1\n",
    "       outlier_hi = -1\n",
    "       outlier_lo =  1\n",
    "    \n",
    "    summary_lst.append({\n",
    "      \"name\"                : col_name,\n",
    "      \"dtype\"               : col_dtype,\n",
    "      \"# null\"              : num_of_null,\n",
    "      \"% null\"              : (100*percent_of_null).round(2),\n",
    "      \"# NOT null\"          : num_of_non_null,\n",
    "      \"distinct val\"        : num_of_distinct_values,\n",
    "      \"-3*sig\"              : round(outlier_lo,2) ,\n",
    "      \"min\"                 : round(min_of_col,2),\n",
    "      \"max\"                 : round(max_of_col,2),\n",
    "      \"+3*sig\"              : round(outlier_hi,2) ,\n",
    "      \"distinct val count\"  : distinct_values_counts\n",
    "    })\n",
    "  \n",
    "  tmp_df = pd.DataFrame(summary_lst)\n",
    "  return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe(include=\"all\").T\n",
    "# df.info()\n",
    "\n",
    "tmp_df = quick_View(df)\n",
    "display(tmp_df.sort_values(by=\"# null\", ascending=False))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>Comments :</b></span>\n",
    "* 4.5 M observations (when all months are loaded, 560k observation for april 2014)\n",
    "* 0 % of null\n",
    "* outliers ($\\bar{x}$ + 3 $\\sigma$ ) are in  \n",
    "    * latitude\n",
    "    * longigute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_outliers = [\"lat\", \"lon\", ]\n",
    "\n",
    "for col in col_outliers:\n",
    "  # fig = px.box(df, y=col)\n",
    "  # fig.show()\n",
    "  # Plottly can't handle the whole dataset from april to sept. \n",
    "  # Let's go back to an always working safe bet. \n",
    "  fig, ax = plt.subplots(figsize=(k_Width, k_Height))\n",
    "  sns.boxplot(df, x=col)\n",
    "  ax.set_title(\"Outliers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many observations are considered as outliers ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_outliers:\n",
    "  upper_bound = df[col].mean() + 3*df[col].std()\n",
    "  lower_bound = df[col].mean() - 3*df[col].std()\n",
    "  nb_out = df.shape[0] - df[((df[col] >= lower_bound) & (df[col] <= upper_bound)) | df[col].isna()].shape[0]\n",
    "  print(f\"{col} have {nb_out:>6_} outliers ({100*nb_out/df.shape[0]:.2} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Outliers_Sigma(df, column):\n",
    "    mean_col = df[column].mean()\n",
    "    sigma_col = df[column].std()\n",
    "\n",
    "    lower_bound = mean_col - 3 * sigma_col\n",
    "    upper_bound = mean_col + 3 * sigma_col\n",
    "    df = df[((df[column] >= lower_bound) & (df[column] <= upper_bound)) | df[column].isna()]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before outliers removal : {df.shape}\")\n",
    "for col in col_outliers:\n",
    "    df = remove_Outliers_Sigma(df, col)\n",
    "print(f\"After  outliers removal : {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour      = 7\n",
    "day       = 9                                                      # 4 would be very cool but it's a Sunday, 9 is Friday\n",
    "month     = 5                                                      # select another month if needed (at least it has been loarded in df)\n",
    "year      = 2014                                                   # so far year must be 2014\n",
    "\n",
    "date_obj = datetime.datetime(year, month, day)                     # day is mandatory to create a date object but not yet used\n",
    "date_string = date_obj.strftime(\"%Y-%B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df  = df[(df[\"month\"] == month) & (df[\"year\"] == year)] \n",
    "month_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickups during the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(\n",
    "  month_df, \n",
    "  x=\"day\",\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - Pickups per day\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The graph here above shows pickups per day during the month  \n",
    "* It seems there is a kind of cycle along the weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of the pickups per day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "  month_df, \n",
    "  x=\"weekday\", \n",
    "  height = k_HeightPx, \n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - Pickups per day (0=Monday)\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The weekly pattern is confirmed over april 20124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "  df, \n",
    "  x=\"weekday\", \n",
    "  height = k_HeightPx, \n",
    "  width = k_WidthPx,\n",
    "  title = \"Apr-Sept 2014 - Pickups per day (0=Monday)\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>Comments :</b></span>\n",
    "\n",
    "* The weekly pattern is confirmed over the april-sept period of 2014\n",
    "* Most active days of the week : Wenesday-Friday\n",
    "* Least active days of the week : Sunday-Monday \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(k_Width, k_Height))\n",
    "ax = sns.kdeplot(data = month_df, x = 'hour', fill = True, hue = 'weekday', palette = 'coolwarm', alpha = 0.2) \n",
    "ax.set_title(f\"{date_string} - KDE plots pickups of each day vs hour\")\n",
    "ax.set_ylabel('Density of pickups')\n",
    "ax.set_xticks([i for i in range(25)]) # using bw_adjust= low value ??? and cut=None does'nt work\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>Comments :</b></span>\n",
    "\n",
    "* Saturday and Sunday show a pick of activities between 0 and 1 AM\n",
    "* Otherwise all the other days show 2 picks around 7AM and 6 PM \n",
    "* The density helps to realize why friday (day 4) is so important : not only the peak in the afternoon is hign but it is also very large \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localization of the pickups during the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# it is safer to sort the values to be used as an animation_frame \n",
    "month_df = month_df.sort_values(by= \"day\", ascending=True)\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "  month_df,\n",
    "  lat=\"lat\",\n",
    "  lon=\"lon\",\n",
    "  animation_frame='day', \n",
    "  mapbox_style=\"carto-positron\",\n",
    "  radius=3,\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title= f\"{date_string} - Localized pickups per day over the selected month\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The more pickups you have on one spot, the higher the \"temperature\" of the spot\n",
    "* \"temperature\" obsiously refers to the number of pickups\n",
    "* The view is per day along the month of study\n",
    "* At this point there is no information about timing along the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"./assets/hotspots.png\" alt=\"drawing\" width=\"800\"/>\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>Comments :</b></span>\n",
    "\n",
    "* No matter the day of the month, the areas here below are always on the top of the list : \n",
    "    * LaGuardia\n",
    "    * Brooklyn\n",
    "    * Greenpoint\n",
    "    * Manhattan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df = month_df.sort_values(by= \"hour\", ascending=True)\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "  month_df,\n",
    "  lat=\"lat\",\n",
    "  lon=\"lon\",\n",
    "  animation_frame='hour', \n",
    "  mapbox_style=\"carto-positron\",\n",
    "  radius=3,\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title= f\"{date_string} - Localized pickups per hour over the selected month\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We look at all the days of the month at once\n",
    "* We look how the pickups go per hour\n",
    "* Brooklyn and LaGardia slow down their pickups from 1AM to respectively 4 and 5AM\n",
    "* On the other hand Manhattan and Greenpoint never stop (NY, the city that never sleeps ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! One must order the dataframe by \"bin\" before the statement animation_frame='bin' otherwise the animation slider is really weird\n",
    "month_df = month_df.sort_values(by= \"bin\", ascending=True)\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "  month_df,\n",
    "  lat=\"lat\",\n",
    "  lon=\"lon\",\n",
    "  animation_frame=\"bin\", \n",
    "  mapbox_style=\"carto-positron\",\n",
    "  radius=5,                        # ! radius changed from 3 to 10\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title= f\"{date_string} - Localized pickups per bin of 5 minutes over the selected month\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This graph is similar to the previous one but has a higher time resolution\n",
    "* 12 (from 0 to 11) bins correspond to 1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obj = datetime.datetime(year, month, day)\n",
    "date_string = date_obj.strftime(\"%Y-%B-%d-%a\")          # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = month_df[month_df[\"day\"]==day]\n",
    "day_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = day_df.sort_values(by= \"hour\", ascending=True)\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "  day_df,\n",
    "  lat=\"lat\",\n",
    "  lon=\"lon\",\n",
    "  animation_frame='hour', \n",
    "  mapbox_style=\"carto-positron\",\n",
    "  radius=5,\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title= f\"{date_string} - Localized pickups during the next hour\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No surprises. \n",
    "* For one day, we find the same pattern as we had with the monthly data, whether on the map or over the course of the day\n",
    "* Bear in mind that the graph shows where the pickups will take place in the next hour for every hour of the day\n",
    "* With a radius of 5 and some adjustment in zooming and panning, we can observe that at 6AM, the area of Soho (south Manhattan) and east and west side of the midle of Central Park \"lite up\" synchronously\n",
    "* Then the center of Manhattan lites up\n",
    "* Throughout the day, the “fire” spreads and covers the whole of Manhattan\n",
    "* Combine with the next density graph, we can see where the peak of 6 PM takes palce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(k_Width, k_Height))\n",
    "ax = sns.kdeplot(data = day_df, x = 'hour', fill = True, hue = 'weekday', palette = 'coolwarm', alpha = 0.2) \n",
    "ax.set_title(f\"{date_string} - KDE plots pickups of each day vs hour\")\n",
    "ax.set_ylabel('Density of pickups')\n",
    "ax.set_xticks([i for i in range(25)]) # using bw_adjust= low value ??? and cut=None does'nt work\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This graph is similar to the previous density plots\n",
    "* Usufull when used in conjonction with the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = day_df.sort_values(by= \"bin\", ascending=True)\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "  day_df,\n",
    "  lat=\"lat\",\n",
    "  lon=\"lon\",\n",
    "  animation_frame='bin', \n",
    "  mapbox_style=\"carto-positron\",\n",
    "  radius=10,                          # ! radius changed from 3 to 10\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title= f\"{date_string} - Localized pickups during the next 5 minutes\",\n",
    "  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same graph but with a higher time resolution\n",
    "* Here too, let's keep in mind that the graph shows where the pickups will take place within the next 5 minutes, for every time bin ff the day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a try with a ``scatter_mapbox()`` instead of ``density_mapbox``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "  day_df, \n",
    "  lat=\"lat\", \n",
    "  lon=\"lon\", \n",
    "  # opacity = 0.8,\n",
    "  animation_frame='bin', \n",
    "  mapbox_style = \"carto-positron\",  \n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - Localized pickups during the next 5 minutes\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obj = datetime.datetime(year, month, day, hour)\n",
    "date_string = date_obj.strftime(\"%Y-%B-%d-%a-%HH\") # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "print(date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df = day_df[day_df[\"hour\"]==hour]\n",
    "hour_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "  hour_df, \n",
    "  lat=\"lat\", \n",
    "  lon=\"lon\", \n",
    "  opacity = 0.5,\n",
    "  mapbox_style = \"carto-positron\",  \n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - Localized pickups during the next hour\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "  hour_df, \n",
    "  lat=\"lat\", \n",
    "  lon=\"lon\", \n",
    "  opacity = 0.5,\n",
    "  animation_frame='bin', \n",
    "  mapbox_style = \"carto-positron\",  \n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - Localized pickups during the next 5 minutes\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>Comments :</b></span>\n",
    "\n",
    "* Surprisigly the graph using bins of 5 minustes seems more difficult to read\n",
    "* On the frist graph we can see that \n",
    "    * LaGardia is up and running,  \n",
    "    * East and west side of central park\n",
    "    * South Manhattan & Greenpoint\n",
    "    * Brookling waking up\n",
    "* Know what we know from the initial study, we could identify 6 zones for this hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPRENDRE À PARTIR D'ICI -----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_hour = hour_df[[\"lat\", \"lon\"]]\n",
    "lat_lon_hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lat_lon_hour = scaler.fit_transform(lat_lon_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(1, 20):\n",
    "  kmeans = KMeans(n_clusters=i, n_init='auto', init='k-means++', random_state = k_random_state)\n",
    "  kmeans.fit(lat_lon_hour)\n",
    "  wcss.append(kmeans.inertia_)\n",
    "\n",
    "fig = px.line(\n",
    "  wcss, \n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  x = ([i for i in range(1, 20)]),\n",
    "  y = wcss,\n",
    "  title = f\"{date_string} - KMEANS - Determine the best # of clusters\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_extended_df = hour_df.copy()\n",
    "\n",
    "optimal_clusters = 6\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, n_init='auto', random_state=k_random_state)\n",
    "hour_extended_df['cluster'] = kmeans.fit_predict(lat_lon_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter_mapbox(\n",
    "  hour_extended_df, \n",
    "  lat=\"lat\", \n",
    "  lon=\"lon\", \n",
    "  opacity = 0.5,\n",
    "  # animation_frame='bin', \n",
    "  mapbox_style = \"carto-positron\",  \n",
    "  color='cluster',\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - KMeans - Hot spots for the next hour\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_lon_hour = hour_df[[\"lat\", \"lon\"]]\n",
    "lat_lon_hour = np.deg2rad(hour_df[[\"lat\", \"lon\"]])\n",
    "lat_lon_hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lat_lon_hour = scaler.fit_transform(lat_lon_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickups within 200 m\n",
    "kms_per_radian = 6371.0088                                  # radius of Earth in kilometers\n",
    "epsilon = 0.25/ kms_per_radian\n",
    "\n",
    "# db = DBSCAN(eps=0.25, min_samples=6, metric=\"euclidean\", algorithm=\"auto\")\n",
    "db = DBSCAN(eps=epsilon, min_samples=5, metric='haversine', algorithm=\"auto\") # algorithm='ball_tree', metric=\"euclidean\"\n",
    "db.fit(lat_lon_hour)                                        # le fit fait le predict. Y a pas de predict\n",
    "\n",
    "hour_extended_df = hour_df.copy()\n",
    "hour_extended_df['cluster'] = db.labels_\n",
    "\n",
    "tmp_df = pd.DataFrame(db.labels_)\n",
    "tmp_df[0].value_counts()\n",
    "\n",
    "# print(len(set(db.labels_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "  hour_extended_df, \n",
    "  lat=\"lat\", \n",
    "  lon=\"lon\", \n",
    "  opacity = 0.5,\n",
    "  mapbox_style = \"carto-positron\",  \n",
    "  color='cluster',\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - DBSCAN - Hot spots for the next hour\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "  hour_extended_df[hour_extended_df[\"cluster\"]!=-1], \n",
    "  lat=\"lat\", \n",
    "  lon=\"lon\", \n",
    "  opacity = 0.5,\n",
    "  # animation_frame='bin', \n",
    "  mapbox_style = \"carto-positron\",  \n",
    "  color='cluster',\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  title = f\"{date_string} - KMeans - Hot spots for the next hour\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "neighbors = NearestNeighbors(n_neighbors=20)\n",
    "neighbors_fit = neighbors.fit(lat_lon_hour)\n",
    "distances, indices = neighbors_fit.kneighbors(lat_lon_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "\n",
    "# distances_df = pd.DataFrame(distances)\n",
    "# fig = px.line(distances_df,  title='')\n",
    "fig = px.line(distances,  title='Points sorted by distance to the 20th nearest neighbor')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sefidian.com/2022/12/18/how-to-determine-epsilon-and-minpts-parameters-of-dbscan-clustering/\n",
    "\n",
    "Optimal eps = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NearestNeighbors(n_neighbors=2)\n",
    "nn_model.fit(lat_lon_OfTheDay)\n",
    "distances, indices = nn_model.kneighbors(lat_lon_OfTheDay)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "\n",
    "\n",
    "fig = px.line(distances,  title='Points sorted by distance to the 20th nearest neighbor')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAP BOOK - Please ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = day_df.pivot_table(index=\"day\", columns=\"hour\", values='minute', aggfunc='count')\n",
    "display(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       \n",
    "# # -----------------------------------------------------------------------------\n",
    "# def get_Tranformer(X):\n",
    "#   numeric_features      = X.select_dtypes(include=\"number\").columns\n",
    "#   # categorical_features  = X.select_dtypes(exclude=\"number\").columns\n",
    "\n",
    "#   numerical_transformer = make_pipeline(\n",
    "#       # SimpleImputer(strategy=\"median\"),\n",
    "#       StandardScaler(),\n",
    "#   )\n",
    "\n",
    "#   # categorical_transformer = make_pipeline(\n",
    "#   #     SimpleImputer(strategy=\"most_frequent\"),\n",
    "#   #     OneHotEncoder(drop=\"first\"),                 \n",
    "#   # )\n",
    "\n",
    "#   col_transformer = make_column_transformer(\n",
    "#     (numerical_transformer,     numeric_features),\n",
    "#     # (categorical_transformer, categorical_features),\n",
    "#   )\n",
    "#   return col_transformer\n",
    "\n",
    "\n",
    "# wcss        = []\n",
    "# nb_clstr    = []\n",
    "# # silhouette  = []\n",
    "\n",
    "# col_transformer = get_Tranformer(X)\n",
    "\n",
    "# for n in range(2,20):\n",
    "#   nb_clstr.append(n)\n",
    "#   model = make_pipeline(\n",
    "#     col_transformer,\n",
    "#     KMeans(n_clusters= n, n_init='auto', random_state = k_random_state)        # default init = \"k-means++\", \n",
    "#   )\n",
    "#   model.fit_transform(X)\n",
    "#   # KMeans est le dernier élément du pipeline => utiliser -1\n",
    "#   # .steps() renvoie des tuples (nom, objet)\n",
    "#   # L'objet KMeans est accédé via [1]\n",
    "#   kmeans_model = model.steps[-1][1] \n",
    "#   wcss.append(kmeans_model.inertia_)\n",
    "#   print(f\"WCSS for             K = {n:02} is wcss = {wcss[-1]:_.2f}\")\n",
    "\n",
    "#   # silhouette.append(silhouette_score(X, model.predict(X)))\n",
    "#   # print(f\"Silhouette score for K = {n:02} is {silhouette[-1]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# april_04_2014_df = april_04_2014_df.sort_values(by = 'hour')\n",
    "fig = px.density_mapbox(\n",
    "  day_df, \n",
    "  lat = \"lat\", \n",
    "  lon = \"lon\", \n",
    "  z = \"hour\", \n",
    "  radius = 10,  # default = 30\n",
    "  # opacity = 0.05,\n",
    "  mapbox_style=\"open-street-map\", \n",
    "  color_continuous_scale=px.colors.sequential.Rainbow,\n",
    "  zoom = 10.0,\n",
    "  height = k_HeightPx,\n",
    "  width = k_WidthPx,\n",
    "  animation_frame = \"hour\",\n",
    "  title= \"april 04 2014 - Pickup per hour\", \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcss_df = pd.DataFrame(wcss)\n",
    "# nb_clstr_df = pd.Series(nb_clstr)\n",
    "\n",
    "# fig= px.line(\n",
    "#     wcss_df,\n",
    "#     x = nb_clstr_df,\n",
    "#     y = wcss_df.iloc[:,-1]\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     yaxis_title=\"Inertia\",\n",
    "#     xaxis_title=\"# Clusters\",\n",
    "#     title=\"Inertia per cluster\"\n",
    "# )\n",
    "# fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a data frame\n",
    "# cluster_scores=pd.DataFrame(silhouette)\n",
    "# nb_clstr_df = pd.Series(nb_clstr)\n",
    "\n",
    "# # Create figure\n",
    "# fig = px.bar(data_frame=cluster_scores,\n",
    "#              x=nb_clstr_df,\n",
    "#              y=cluster_scores.iloc[:, -1]\n",
    "#             )\n",
    "\n",
    "# # Add title and axis labels\n",
    "# fig.update_layout(\n",
    "#     yaxis_title=\"Silhouette Score\",\n",
    "#     xaxis_title=\"# Clusters\",\n",
    "#     title=\"Silhouette Score per cluster\"\n",
    "# )\n",
    "\n",
    "# # Render\n",
    "# #fig.show(renderer=\"notebook\")\n",
    "# fig.show() # if using workspace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
