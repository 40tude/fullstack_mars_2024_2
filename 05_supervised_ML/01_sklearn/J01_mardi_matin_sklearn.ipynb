{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mardi 09 Avril\n",
    "\n",
    "## Preprocessing with Sklearn\n",
    "\n",
    "* Voir   • https://app.jedha.co/course/preprocessing-with-sklearn-course-ft/introduction-ft\n",
    "\n",
    "\n",
    "# Data preprocessing for supervised machine learning\n",
    "\n",
    "## What you'll learn in this course\n",
    "\n",
    "The example below implements all the necessary steps to train a machine learning model and make predictions on a dataset.\n",
    "\n",
    "- Use pandas and the preprocessing module of the scikit-learn library to prepare your data.\n",
    "- Use scikit-learn to train a supervised machine learning model and assess its performance.\n",
    "\n",
    "We have a sample dataset of conversions available (has someone purchased a product). The objective is to predict whether a person has made a purchase, based on information about that person: nationality, age, and income level.\n",
    "\n",
    "- We will call \"variable to predict\", \"variable to explain\" or \"target\", noted Y, the column corresponding to \"Purchased\" in the dataset\n",
    "- The other columns of the dataset, called \"explanatory variables\" and denoted X, will be used to try to predict the value of Y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\n",
    "#     \"ignore\", category=DeprecationWarning\n",
    "# )  # to avoid deprecation warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File reading and basic exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = pd.read_csv(\"../12_assets/05_supervised_ML/Dataset_preprocessing.csv\")\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 12\n",
      "\n",
      "Display of dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>useless_col</th>\n",
       "      <th>almost_empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000</td>\n",
       "      <td>No</td>\n",
       "      <td>useless</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>useless</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000</td>\n",
       "      <td>No</td>\n",
       "      <td>useless</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000</td>\n",
       "      <td>No</td>\n",
       "      <td>useless</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>69000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>useless</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Country   Age  Salary Purchased useless_col  almost_empty\n",
       "0   0   France  44.0   72000        No     useless           NaN\n",
       "1   1    Spain  27.0   48000       Yes     useless          40.0\n",
       "2   2  Germany  30.0   54000        No     useless           NaN\n",
       "3   3    Spain  38.0   61000        No     useless          20.0\n",
       "4   4  Germany  40.0   69000       Yes     useless           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basics statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>useless_col</th>\n",
       "      <th>almost_empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>useless</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.909091</td>\n",
       "      <td>8.338958e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.605551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.002392</td>\n",
       "      <td>2.886574e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.142136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>3.200000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>5.350000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>6.400000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>7.375000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id Country        Age        Salary Purchased useless_col  \\\n",
       "count   12.000000      12  11.000000  1.200000e+01        12          12   \n",
       "unique        NaN       3        NaN           NaN         2           1   \n",
       "top           NaN  France        NaN           NaN       Yes     useless   \n",
       "freq          NaN       5        NaN           NaN         7          12   \n",
       "mean     5.500000     NaN  36.909091  8.338958e+07       NaN         NaN   \n",
       "std      3.605551     NaN  19.002392  2.886574e+08       NaN         NaN   \n",
       "min      0.000000     NaN -10.000000  3.200000e+04       NaN         NaN   \n",
       "25%      2.750000     NaN  32.500000  5.350000e+04       NaN         NaN   \n",
       "50%      5.500000     NaN  38.000000  6.400000e+04       NaN         NaN   \n",
       "75%      8.250000     NaN  46.000000  7.375000e+04       NaN         NaN   \n",
       "max     11.000000     NaN  67.000000  1.000000e+09       NaN         NaN   \n",
       "\n",
       "        almost_empty  \n",
       "count       2.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean       30.000000  \n",
       "std        14.142136  \n",
       "min        20.000000  \n",
       "25%        25.000000  \n",
       "50%        30.000000  \n",
       "75%        35.000000  \n",
       "max        40.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               0.000000\n",
       "Country          0.000000\n",
       "Age              8.333333\n",
       "Salary           0.000000\n",
       "Purchased        0.000000\n",
       "useless_col      0.000000\n",
       "almost_empty    83.333333\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(f\"Number of rows : {dataset.shape[0]}\")\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "display(dataset.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = dataset.describe(include=\"all\")\n",
    "display(data_desc)\n",
    "print()\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "display(100 * dataset.isnull().sum() / dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "* Age\n",
    "  * Une valeur negative\n",
    "  * Une valeur abhérante si on utilise\n",
    "  * ~~TODO : revoir median et 1.5 espace inter quartile~~\n",
    "\n",
    "* Salary\n",
    "  * 1 Mds\n",
    "\n",
    "* Useless\n",
    "  * toujours la même valeur\n",
    "\n",
    "* Empty\n",
    "  * pas assez de valeur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploration of the above data makes it possible to know which pre-processing steps will be necessary:\n",
    "\n",
    "**1. Preprocessing to be planned with pandas**\n",
    "\n",
    "**Unnecessary columns for prediction, to be thrown away** :\n",
    "\n",
    "- _id_ is an identifier, it should never be used for prediction (this column contains no information)\n",
    "- _useless_col_ will also be useless, because it always contains the same value\n",
    "\n",
    "**Columns with too many missing values, to be discarded** : _almost_empty_\n",
    "\n",
    "**Lines containing outliers, discarded** :\n",
    "\n",
    "- Lines for which _Age_ is negative\n",
    "- Lines for which _Salary_ is more than 2 standard deviations away (std) (this is not a rule to be applied in general, but here we notice that it allows to discard the value of 1Billion which seems aberrant)\n",
    "\n",
    "**Target variable/target (Y) that we will try to predict, to separate from the others** : Purchased\n",
    "\n",
    "**------------**\n",
    "\n",
    "**2. Preprocessings to be planned with scikit-learn\\*\\***.\n",
    "\n",
    "**Explanatory variables (X)**\n",
    "We need to identify which columns contain categorical variables and which columns contain numerical variables, as they will be treated differently.\n",
    "\n",
    "- Categorical variables : Country\n",
    "- Numerical variables : Age, Salary\n",
    "\n",
    "In this dataset, we have both types of variables. It will thus be necessary to plan to create a numeric_transformer (which will call the StandardScaler class) and a categorical_transformer (which will call the OneHotEncoder class). On the other hand, as we observe missing values in the starting dataset, we will have to plan to call the SimpleImputer class to handle the missing values.\n",
    "\n",
    "**Target variable Y**\n",
    "Finally, here it should be noted that the variable Y to be predicted is categorical: it will thus be necessary to provide an encoding with the LabelEncoder class.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - Pandas 🐼🐼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping useless columns...\n",
      "...Done.\n",
      "   Country   Age  Salary Purchased\n",
      "0   France  44.0   72000        No\n",
      "1    Spain  27.0   48000       Yes\n",
      "2  Germany  30.0   54000        No\n",
      "3    Spain  38.0   61000        No\n",
      "4  Germany  40.0   69000       Yes\n"
     ]
    }
   ],
   "source": [
    "# Drop useless columns / columns with too many missing values\n",
    "useless_cols = [\"id\", \"useless_col\", \"almost_empty\"]\n",
    "\n",
    "print(\"Dropping useless columns...\")\n",
    "\n",
    "# on vire les colonnes\n",
    "dataset = dataset.drop(\n",
    "    useless_cols, axis=1\n",
    ")  # axis = 1 indicates that we are dropping along the column axis\n",
    "# never hesitate to look at a function's documentation using the command name_of_the_function?\n",
    "print(\"...Done.\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping outliers in Age...\n",
      "Done. Number of lines remaining :  11\n",
      "\n",
      "Dropping outliers in Salary...\n",
      "Done. Number of lines remaining :  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>69000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age  Salary Purchased\n",
       "0   France  44.0   72000        No\n",
       "1    Spain  27.0   48000       Yes\n",
       "2  Germany  30.0   54000        No\n",
       "3    Spain  38.0   61000        No\n",
       "4  Germany  40.0   69000       Yes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop lines containing outliers (using masks)\n",
    "\n",
    "print(\"Dropping outliers in Age...\")\n",
    "\n",
    "# on fait un masque\n",
    "to_keep = (dataset[\"Age\"] > 0) | (\n",
    "    dataset[\"Age\"].isnull()\n",
    ")  # We want keeping positives values or missings\n",
    "\n",
    "# on slice avec le masque\n",
    "dataset = dataset.loc[to_keep, :]\n",
    "print(\"Done. Number of lines remaining : \", dataset.shape[0])\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# on garde que les salaires\n",
    "print(\"Dropping outliers in Salary...\")\n",
    "to_keep = dataset[\"Salary\"] < dataset[\"Salary\"].mean() + 2 * dataset[\"Salary\"].std()\n",
    "# to_keep = dataset[\"Salary\"] < dataset[\"Salary\"].quantile(0.5) + 1.5 * dataset[\"Salary\"].quantile(0.75) - ?????????????\n",
    "\n",
    "# on slice avec le masque\n",
    "dataset = dataset.loc[to_keep, :]\n",
    "print(\"Done. Number of lines remaining : \", dataset.shape[0])\n",
    "print()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "   Country   Age  Salary\n",
      "0   France  44.0   72000\n",
      "1    Spain  27.0   48000\n",
      "2  Germany  30.0   54000\n",
      "3    Spain  38.0   61000\n",
      "4  Germany  40.0   69000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "target_name = \"Purchased\"\n",
    "\n",
    "print(\"Separating labels from features...\")\n",
    "Y = dataset.loc[:, target_name]\n",
    "X = dataset.drop(target_name, axis=1)  # All columns are kept, except the target\n",
    "print(\"...Done.\")\n",
    "print(Y.head())\n",
    "print()\n",
    "print(X.head())\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - Scikit-Learn 🔬🔬\n",
    "\n",
    "### Train-test splitting\n",
    "\n",
    "Before doing any preprocessing, let's put a little part (10-20%) of the dataset aside. This data will be refered to as the _test set_ and won't be used to train the model. Later in this notebook, we'll use the biggest part (80-90%) of the data (the _train set_) to train our model, and then the test set will allow us to estimate what are the performances we could expect on new data that has never been seen by the model.\n",
    "\n",
    "<Note type=\"tip\">\n",
    "\n",
    "If it's not obvious to you why this train/test splitting is important, don't worry, we'll go deeper into this topic at the end of the module 🤓 for now, you can just blindly apply this simple rule: always make a train/test splitting before you make any transformation on your data using scikit-learn !\n",
    "\n",
    "</Note>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First : always divide dataset into train set & test set !!\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# test_size indicates the proportion of rows from X and Y that will go into the test dataset while\n",
    "# maintaining the correspondance between the rows from X and Y\n",
    "\n",
    "# random_state is an argument that can be found in all functions that have a pseudo-random behaviour\n",
    "# if random_state is not stated the function will derive a different random result everytime the cell\n",
    "# runs, if random_state is given a value the results will be the same everytime the cell runs while\n",
    "# each different value of radom_state will derive a specific result\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessings : imputation of missing values, standardizing and one-hot encoding\n",
    "\n",
    "Let's apply the remaining transformations required to prepare the data for model training.\n",
    "\n",
    "There's one main difficulty: we want to apply different transformations to the features, depending on their types. Numeric columns will be standardized whereas categorical columns will be one-hot-encoded. As regards missing values imputation, it can apply to every column, but different rules may be used. For example, we might want to replace missing values by the median in numeric features, and by the variable's mode in categorical features. You can imagine that, with many different columns and many different types, this can lead to a lot of code with many exceptions 🤯\n",
    "\n",
    "Fortunately, scikit-learn's `Pipeline` and `ColumnTransformer` classes will help us \"tidy\" our code and make it as readable as possible while allowing to choose different steps for different columns.\n",
    "\n",
    "<Note type=\"note\" title=\"Pipeline vs. ColumnTransformer\">\n",
    "\n",
    "- The `Pipeline` class allows to describe the successive steps that we want to apply to a feature. For example: \"1. replace missing values by the median 2. standardize the variable\". Once this pipeline has been declared, it's possible to apply it to every column that is concerned.\n",
    "- The `ColumnTransformer` class allows to apply a given `Pipeline` to a whole set of columns at once\n",
    "\n",
    "</Note>\n",
    "\n",
    "<Note type=\"warning\" title=\"Don't panic!\">\n",
    "\n",
    "This may seem a bit complicated to you at first, but you'll use these classes every single day from now on, and you'll see that it actually always behaves the same. In the end, it's likely that you'll know these lines of code by heart, repeating and practicing are key 😌 But in the beginning, you can settle for copy/pasting these lines whenever you need to make some preprocessings !\n",
    "\n",
    "</Note>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_features = [\"Age\", \"Salary\"]  # Names of numeric columns in X_train/X_test\n",
    "\n",
    "# On a 2 étapes dans notre pipe\n",
    "# Une liste de tuples à 2 éléments\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputer_num\",\n",
    "            SimpleImputer(strategy=\"median\"),     # un transformer de sklearn. Missing values will be replaced by columns' median\n",
    "        ),  \n",
    "        (\n",
    "            \"scaler\", \n",
    "            StandardScaler()                      # moy=0 std=1\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for categorical features\n",
    "categorical_features = [\"Country\"]  # Names of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputer_cat\",\n",
    "            SimpleImputer(strategy=\"most_frequent\"),  # missing values will be replaced by most frequent value\n",
    "        ),  \n",
    "        (\n",
    "            \"encoder\",\n",
    "            OneHotEncoder(drop=\"first\"),              # drop => avoid correlations between features\n",
    "        ),  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "\n",
    "# Une liste de tuples à 3 éléments\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer,     numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "   Country   Age  Salary\n",
      "4  Germany  40.0   69000\n",
      "9   France  37.0   67000\n",
      "1    Spain  27.0   48000\n",
      "6    Spain   NaN   52000\n",
      "7   France  48.0   79000\n",
      "...Done.\n",
      "[[ 0.27978024  0.58858382  1.          0.        ]\n",
      " [-0.23673712  0.38385901  0.          0.        ]\n",
      " [-1.95846165 -1.56102665  0.          1.        ]\n",
      " [-0.06456467 -1.15157703  0.          1.        ]\n",
      " [ 1.65715986  1.61220785  0.          0.        ]]\n",
      "\n",
      "Performing preprocessings on test set...\n",
      "   Country   Age  Salary\n",
      "2  Germany  30.0   54000\n",
      "8  Germany  50.0   83000\n",
      "...Done.\n",
      "[[-1.44194429 -0.94685223  1.          0.        ]\n",
      " [ 2.00150476  2.02165746  1.          0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train.head())\n",
    "X_train = preprocessor.fit_transform(X_train) # fit et Transform\n",
    "print(\"...Done.\")\n",
    "print(\n",
    "    X_train[0:5] # ! MUST use this syntax because X_train is a numpy array and not a pandas DataFrame anymore\n",
    ")  \n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test.head())\n",
    "X_test = preprocessor.transform(                 # ! Que transform PAS de fit. On ne fait que appliquer les transformation on ne les calcule pas \n",
    "    X_test\n",
    ")  # Don't fit again !! The test set is used for validating decisions\n",
    "# we made based on the training set, therefore we can only apply transformations that were parametered using the training set.\n",
    "# Otherwise this creates what is called a leak from the test set which will introduce a bias in all your results.\n",
    "print(\"...Done.\")\n",
    "print(\n",
    "    X_test[0:5, :] # ! MUST use this syntax because X_test is a numpy array and not a pandas DataFrame anymore\n",
    ")  \n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Note type=\"warning\" title=\"Type conversion\">\n",
    "\n",
    "Scikit-learn's ColumnTransformer converts pandas DataFrames into numpy arrays. You can check that by displaying the type of the object returned by the fit_transform() method. The cell below won't execute because all the methods from pandas won't be available anymore once the conversion has been made. To display the first lines of your dataset, you'll have to use the numpy syntax as shown below.\n",
    "\n",
    "</Note>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! This will create an AttributeError because X_train is NOT a pandas DataFrame anymore !\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actually, X_train is a numpy array\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27978024,  0.58858382,  1.        ,  0.        ],\n",
       "       [-0.23673712,  0.38385901,  0.        ,  0.        ],\n",
       "       [-1.95846165, -1.56102665,  0.        ,  1.        ],\n",
       "       [-0.06456467, -1.15157703,  0.        ,  1.        ],\n",
       "       [ 1.65715986,  1.61220785,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Numpy syntax to display 5 first lines\n",
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels on train set...\n",
      "4    Yes\n",
      "9    Yes\n",
      "1    Yes\n",
      "6     No\n",
      "7    Yes\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "...Done.\n",
      "[1 1 1 0 1]\n",
      "\n",
      "Encoding labels on test set...\n",
      "2    No\n",
      "8    No\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "...Done.\n",
      "[0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode target variable Y\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "print(\"Encoding labels on train set...\")\n",
    "print(Y_train.head())\n",
    "print()\n",
    "\n",
    "Y_train = labelencoder.fit_transform(Y_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train[0:5])\n",
    "print()\n",
    "\n",
    "print(\"Encoding labels on test set...\")\n",
    "print(Y_test.head())\n",
    "print()\n",
    "Y_test = labelencoder.transform(Y_test)  # Don't fit again !!\n",
    "print(\"...Done.\")\n",
    "\n",
    "print(Y_test[0:5])\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training 🏃\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = LogisticRegression()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train)  # Training is always done on train set !!\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions 🔮\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[1 1 1 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = model.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = model.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred[0:5])\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation 💯\n",
    "\n",
    "To assess the performances of your model, you can load the function corresponding to the metric you're interested in from the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module. There exist a lot of scoring methods, you'll get familiar with some of them during the next lectures. In this demo, we use the accuracy score, which is the most widespread score for classification problems.\n",
    "\n",
    "**Here the accuracy on the test is bad because there is not enough data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.75\n",
      "Accuracy on test set :  0.0\n"
     ]
    }
   ],
   "source": [
    "# Print scores\n",
    "print(\n",
    "    \"Accuracy on training set : \", accuracy_score(Y_train, Y_train_pred)\n",
    ")  # Always pass true label first, and predictions in second position\n",
    "print(\"Accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way of computing the accuracy score\n",
    "\n",
    "In scikit-learn, every class implementing a machine learning model has a `score()` method that can be used to assess the score without explicitely computing the model's predictions beforehand.\n",
    "\n",
    "<Note type=\"warning\" title=\"Always check the metric used !\">\n",
    "\n",
    "The `score()` method will return a basic score that is consistent with the type of problem (in this demo it's the accuracy). To be sure what metric is used, you can refer to the [model's documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score).\n",
    "\n",
    "</Note>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.75\n",
      "Accuracy on test set :  0.0\n"
     ]
    }
   ],
   "source": [
    "# Print scores\n",
    "print(\n",
    "    \"Accuracy on training set : \", model.score(X_train, Y_train)\n",
    ")  # Here, the features must be passed first, and then the true label\n",
    "print(\"Accuracy on test set : \", model.score(X_test, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources 📚📚\n",
    "\n",
    "- Introduction Pratique à Python - Antoine Krajnc-Rosenthal & Anais Armandy\n",
    "- Sklearn - [Documentation officielle de scikit-learn](https://scikit-learn.org/stable/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
