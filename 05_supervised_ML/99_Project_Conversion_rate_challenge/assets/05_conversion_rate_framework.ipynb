{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures   \n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "k_result_file   = \"results\"\n",
    "k_target        = \"converted\"\n",
    "k_samples_ratio = 10/100  # percentage of observation to be taken into account. Pass 100/100 for final testing \n",
    "k_test_size     = 20/100  # see train_test_split\n",
    "k_random_state  = 42      # you know why...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./assets/conversion_data_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :\n",
      "(284580, 6)\n",
      "\n",
      "Numnber of null val :\n",
      "country                0.0\n",
      "age                    0.0\n",
      "new_user               0.0\n",
      "source                 0.0\n",
      "total_pages_visited    0.0\n",
      "converted              0.0\n",
      "dtype: float64\n",
      "\n",
      "Number of unique category :\n",
      "Unique countries :  ['China' 'UK' 'Germany' 'US']\n",
      "Unique sources   :  ['Direct' 'Ads' 'Seo']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape :\")\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "print(f\"Numnber of null val :\")\n",
    "print(100 * df.isnull().sum() / df.shape[0])\n",
    "\n",
    "print(f\"\\nNumber of unique category :\")\n",
    "print(\"Unique countries : \", df[\"country\"].unique())\n",
    "print(\"Unique sources   : \", df[\"source\"].unique())\n",
    "\n",
    "# display(df.head())\n",
    "# print(df.describe(include=\"all\").T)\n",
    "# print(df.duplicated().sum())\n",
    "# print (df.isnull().any().any())\n",
    "# print(f\"Info :\\n\", df.info(), \"\\n\")\n",
    "# print(df[\"col_name\"].value_counts())\n",
    "# print(df.isnull().sum().sort_values(ascending=False).head(11))\n",
    "# df[k_target].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(int(k_samples_ratio*len(df)))\n",
    "df_nouveau = df.iloc[:int(k_samples_ratio*len(df))]\n",
    "\n",
    "\n",
    "X = df.drop(k_target, axis=1)\n",
    "X = df.drop(columns=k_target)\n",
    "\n",
    "y = df[k_target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "   country  age  new_user  source  total_pages_visited\n",
      "0    China   22         1  Direct                    2\n",
      "1       UK   21         1     Ads                    3\n",
      "2  Germany   20         0     Seo                   14\n",
      "3       US   23         1     Seo                    3\n",
      "4       US   28         1  Direct                    3\n",
      "(284580, 5)\n",
      "\n",
      "y :\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: converted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X :\")\n",
    "print(X.head())\n",
    "print(X.shape)\n",
    "print()\n",
    "\n",
    "print(\"y :\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=k_test_size, random_state=k_random_state, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (227664, 5)\n",
      "\n",
      "Shape of X_train : (56916, 5)\n",
      "\n",
      "Shape of X_train : (227664,)\n",
      "\n",
      "Shape of X_train : (56916,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO Faire une fonction\n",
    "print(f\"Shape of X_train : {X_train.shape}\")\n",
    "print()\n",
    "print(f\"Shape of X_train : {X_test.shape}\")\n",
    "print()\n",
    "print(f\"Shape of X_train : {y_train.shape}\")\n",
    "print()\n",
    "print(f\"Shape of X_train : {y_test.shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'new_user', 'total_pages_visited'], dtype='object')\n",
      "Index(['country', 'source'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X.select_dtypes(include=\"number\").columns\n",
    "print(numeric_features)\n",
    "\n",
    "categorical_features = X.select_dtypes(exclude=\"number\").columns\n",
    "print(categorical_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transformer = Pipeline(\n",
    "  steps=[\n",
    "    (\"imputer_num\", SimpleImputer()),\n",
    "    (\"scaler_num\", StandardScaler()),\n",
    "  ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "  steps=[\n",
    "      (\"imputer_cat\", SimpleImputer(fill_value=\"missing\", strategy=\"constant\")),  \n",
    "      # (\"encoder_cat\", OneHotEncoder(drop=\"first\")),                 \n",
    "      (\"encoder_cat\", OneHotEncoder(handle_unknown='ignore', sparse=False)),                 \n",
    "    ]\n",
    "  )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "      (\"num\", numeric_transformer,     numeric_features),\n",
    "      (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.27650481  0.6761303  -0.2618471   0.          0.          0.\n",
      "   1.          1.          0.          0.        ]\n",
      " [-0.18867057  0.6761303  -0.56090876  1.          0.          0.\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.65742272 -1.47900486 -0.56090876  0.          0.          0.\n",
      "   1.          0.          0.          1.        ]\n",
      " [-0.9138934   0.6761303   0.93439955  0.          0.          0.\n",
      "   1.          0.          0.          1.        ]\n",
      " [ 1.26177508  0.6761303  -0.56090876  0.          0.          1.\n",
      "   0.          1.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_China</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Ads</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.276505</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.261847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.188671</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657423</td>\n",
       "      <td>-1.479005</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.913893</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.261775</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_China  \\\n",
       "0 -1.276505       0.676130                 -0.261847                 0.0   \n",
       "1 -0.188671       0.676130                 -0.560909                 1.0   \n",
       "2  0.657423      -1.479005                 -0.560909                 0.0   \n",
       "3 -0.913893       0.676130                  0.934400                 0.0   \n",
       "4  1.261775       0.676130                 -0.560909                 0.0   \n",
       "\n",
       "   cat__country_Germany  cat__country_UK  cat__country_US  cat__source_Ads  \\\n",
       "0                   0.0              0.0              1.0              1.0   \n",
       "1                   0.0              0.0              0.0              1.0   \n",
       "2                   0.0              0.0              1.0              0.0   \n",
       "3                   0.0              0.0              1.0              0.0   \n",
       "4                   0.0              1.0              0.0              1.0   \n",
       "\n",
       "   cat__source_Direct  cat__source_Seo  \n",
       "0                 0.0              0.0  \n",
       "1                 0.0              0.0  \n",
       "2                 0.0              1.0  \n",
       "3                 0.0              1.0  \n",
       "4                 0.0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print(X_train[0:5])\n",
    "X_train = pd.DataFrame(X_train, columns=preprocessor.get_feature_names_out())\n",
    "display(X_train.head())\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_China</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Ads</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.276505</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.261847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.188671</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657423</td>\n",
       "      <td>-1.479005</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.913893</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.261775</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_China  \\\n",
       "0 -1.276505       0.676130                 -0.261847                 0.0   \n",
       "1 -0.188671       0.676130                 -0.560909                 1.0   \n",
       "2  0.657423      -1.479005                 -0.560909                 0.0   \n",
       "3 -0.913893       0.676130                  0.934400                 0.0   \n",
       "4  1.261775       0.676130                 -0.560909                 0.0   \n",
       "\n",
       "   cat__country_Germany  cat__country_UK  cat__country_US  cat__source_Ads  \\\n",
       "0                   0.0              0.0              1.0              1.0   \n",
       "1                   0.0              0.0              0.0              1.0   \n",
       "2                   0.0              0.0              1.0              0.0   \n",
       "3                   0.0              0.0              1.0              0.0   \n",
       "4                   0.0              1.0              0.0              1.0   \n",
       "\n",
       "   cat__source_Direct  cat__source_Seo  \n",
       "0                 0.0              0.0  \n",
       "1                 0.0              0.0  \n",
       "2                 0.0              1.0  \n",
       "3                 0.0              1.0  \n",
       "4                 0.0              0.0  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(X_train[5:,].round(3))\n",
    "\n",
    "# print()\n",
    "# print(X_test[5:,].round(3))\n",
    "\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_engineering(data, strategy='None', **kwargs):\n",
    "\n",
    "  \"\"\"\n",
    "  Applies a feature engineering strategy to the data.      \n",
    "\n",
    "  Args: \n",
    "  - data (DataFrame)  : The DataFrame containing the initial data.     \n",
    "  - strategy (str)    : The feature engineering strategy to apply.     \n",
    "  - kwargs            : Parameters specific to the feature engineering strategy.      \n",
    "\n",
    "  Returns: DataFrame  : The DataFrame containing the transformed data.     \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  match strategy:\n",
    "\n",
    "    case 'None':\n",
    "      transformed_df = data.copy()\n",
    "     \n",
    "    case 'polynomial_features':\n",
    "      degree = kwargs.get('degree', 2)          # 2 by default\n",
    "      poly = PolynomialFeatures(degree=degree)\n",
    "      transformed_data = poly.fit_transform(data)\n",
    "\n",
    "      original_feature_names = data.columns\n",
    "      feature_combinations = poly.powers_\n",
    "\n",
    "      # Generate names for the new features\n",
    "      feature_names = [\"\"]\n",
    "      for feature_combination in feature_combinations[1:]:\n",
    "          new_feature_name = \"*\".join([f\"{orig_feature}^{power}\" if power > 1 else orig_feature for orig_feature, power in zip(original_feature_names, feature_combination)])\n",
    "          feature_names.append(new_feature_name)\n",
    "\n",
    "      # new df - transformed features and their names\n",
    "      transformed_df = pd.DataFrame(transformed_data, columns=feature_names)\n",
    "\n",
    "\n",
    "      # columns = poly.get_feature_names_out(data.columns)\n",
    "      # transformed_df = pd.DataFrame(transformed_data, columns=columns)\n",
    "\n",
    "    case 'log_transform':\n",
    "      features_to_transform = kwargs.get('features_to_transform', [])\n",
    "      transformed_df = data.copy()\n",
    "      transformed_df[features_to_transform] = np.log(data[features_to_transform] + 1) # log neperien\n",
    "\n",
    "    case 'custom_feature_engineering':\n",
    "      # Design your own pizza\n",
    "      # One can use kwargs\n",
    "      transformed_df = data.copy()\n",
    "      # Ajouter ici votre logique de feature engineering personnalis√©e\n",
    "\n",
    "    case _:\n",
    "      raise ValueError(\"Feature engineering strategy not recognized.\")\n",
    "\n",
    "  return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(X_train, y_train, X_test, feature_selection_method='None', **kwargs):\n",
    "\n",
    "  match feature_selection_method:\n",
    "      case \"None\":\n",
    "        X_train_selected_df = X_train\n",
    "        X_test_selected_df = X_test\n",
    "               \n",
    "      case 'SelectKBest':\n",
    "        k = kwargs.get('k', 10)                            # 10 by default\n",
    "        if df.shape[1]<k:\n",
    "          k = df.shape[1]\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "        X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_train.columns[selector.get_support()])\n",
    "\n",
    "\n",
    "\n",
    "      case 'chi2':\n",
    "        selector = SelectKBest(score_func=chi2)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "        X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_train.columns[selector.get_support()])\n",
    "\n",
    "      case 'custom_feature_selection':\n",
    "        # Design your own pizza\n",
    "        # One can use kwargs\n",
    "        X_train_selected_df = X_train\n",
    "        X_test_selected_df = X_test\n",
    "      \n",
    "      case _:\n",
    "        raise ValueError(\"Feature selection method not recognized.\")\n",
    "\n",
    "  return X_train_selected_df, X_test_selected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_scores(model, params, X_train, y_train, X_test, y_test):\n",
    "\n",
    "  grid_search = GridSearchCV(model, params, cv=5, scoring='f1', n_jobs=-1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  best_params = grid_search.best_params_\n",
    "\n",
    "  model.set_params(**best_params)\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  scores = {\n",
    "    'accuracy'  : accuracy_score(y_test, y_pred),\n",
    "    'precision' : precision_score(y_test, y_pred),\n",
    "    'recall'    : recall_score(y_test, y_pred),\n",
    "    'f1'        : f1_score(y_test, y_pred)\n",
    "  }\n",
    "\n",
    "  return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Feature_Engineering', 'Feature_Selection', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies for feature engineering\n",
    "feature_engineering_strategies = [\n",
    "  'None',\n",
    "  'polynomial_features',         # degree\n",
    "  # 'log_transform',             # features_to_transform\n",
    "]\n",
    "\n",
    "engineering_params = {\n",
    "  'None'                : {},\n",
    "  'polynomial_features' : {'degree':2},                         \n",
    "  'log_transform'       : {'features_to_transform': [0, 1, 2]}, # ! PAS TESTE !!!!!!!!!!!!!!!!!!!! \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies for feature selection\n",
    "feature_selection_strategies = [\n",
    "  ('None', 'None'),\n",
    "  (\"SelectKBest\", 'SelectKBest_2'), \n",
    "  ('SelectKBest', \"SelectKBest_1\") , \n",
    "  # 'chi2',                            # !!! PAS TESTE\n",
    "]\n",
    "\n",
    "selection_params_sets = {\n",
    "  'None'          : {},\n",
    "  'SelectKBest_1' : {'k':1},                         \n",
    "  'SelectKBest_2' : {'k':2},                         \n",
    "  'chi2'          : {}, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "models = [\n",
    "    (\"LogisticRegression_0\", LogisticRegression()),\n",
    "    (\"LogisticRegression_1\", LogisticRegression()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    # ('SVM', SVC()),\n",
    "    # ('KNN', KNeighborsClassifier()),\n",
    "    # ('Logistic Regression', LogisticRegression())\n",
    "]\n",
    "\n",
    "# Hyperparamters to test with each model\n",
    "models_params = {\n",
    "    'LogisticRegression_0'  : {},\n",
    "    'LogisticRegression_1'  : {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
    "    'Random Forest'         : {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]},\n",
    "    'SVM'                   : {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'KNN'                   : {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.76083332        nan 0.76202531        nan 0.76206268]\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.72631268        nan 0.72631268        nan 0.72631268]\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.69253859        nan 0.69253859        nan 0.69253859]\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.76082383        nan 0.76069317        nan 0.76078292]\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 0 39 40 41 46 47 52 61 62 64] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.69253859        nan 0.69253859        nan 0.69253859]\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 0 39 40 41 46 47 52 61 62 64] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.69253859        nan 0.69253859        nan 0.69253859]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Engineering</th>\n",
       "      <th>Feature_Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.986559</td>\n",
       "      <td>0.865529</td>\n",
       "      <td>0.690632</td>\n",
       "      <td>0.768252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression_1</td>\n",
       "      <td>0.986559</td>\n",
       "      <td>0.865529</td>\n",
       "      <td>0.690632</td>\n",
       "      <td>0.768252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.986278</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.688998</td>\n",
       "      <td>0.764120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression_1</td>\n",
       "      <td>0.986278</td>\n",
       "      <td>0.858113</td>\n",
       "      <td>0.688453</td>\n",
       "      <td>0.763977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>None</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.986243</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.686819</td>\n",
       "      <td>0.763086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.986032</td>\n",
       "      <td>0.855290</td>\n",
       "      <td>0.682462</td>\n",
       "      <td>0.759164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>SelectKBest_2</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.984872</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.734341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>SelectKBest_2</td>\n",
       "      <td>LogisticRegression_1</td>\n",
       "      <td>0.984872</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.734341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>SelectKBest_2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.984872</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.734341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>SelectKBest_1</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>SelectKBest_1</td>\n",
       "      <td>LogisticRegression_1</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>SelectKBest_1</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>SelectKBest_2</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>SelectKBest_2</td>\n",
       "      <td>LogisticRegression_1</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>SelectKBest_2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>SelectKBest_1</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>SelectKBest_1</td>\n",
       "      <td>LogisticRegression_1</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>polynomial_features</td>\n",
       "      <td>SelectKBest_1</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.705475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_Engineering Feature_Selection                 Model  Accuracy  \\\n",
       "0                  None              None  LogisticRegression_0  0.986559   \n",
       "1                  None              None  LogisticRegression_1  0.986559   \n",
       "9   polynomial_features              None  LogisticRegression_0  0.986278   \n",
       "10  polynomial_features              None  LogisticRegression_1  0.986278   \n",
       "11  polynomial_features              None         Random Forest  0.986243   \n",
       "2                  None              None         Random Forest  0.986032   \n",
       "3                  None     SelectKBest_2  LogisticRegression_0  0.984872   \n",
       "4                  None     SelectKBest_2  LogisticRegression_1  0.984872   \n",
       "5                  None     SelectKBest_2         Random Forest  0.984872   \n",
       "6                  None     SelectKBest_1  LogisticRegression_0  0.983555   \n",
       "7                  None     SelectKBest_1  LogisticRegression_1  0.983555   \n",
       "8                  None     SelectKBest_1         Random Forest  0.983555   \n",
       "12  polynomial_features     SelectKBest_2  LogisticRegression_0  0.983555   \n",
       "13  polynomial_features     SelectKBest_2  LogisticRegression_1  0.983555   \n",
       "14  polynomial_features     SelectKBest_2         Random Forest  0.983555   \n",
       "15  polynomial_features     SelectKBest_1  LogisticRegression_0  0.983555   \n",
       "16  polynomial_features     SelectKBest_1  LogisticRegression_1  0.983555   \n",
       "17  polynomial_features     SelectKBest_1         Random Forest  0.983555   \n",
       "\n",
       "    Precision    Recall        F1  \n",
       "0    0.865529  0.690632  0.768252  \n",
       "1    0.865529  0.690632  0.768252  \n",
       "9    0.857627  0.688998  0.764120  \n",
       "10   0.858113  0.688453  0.763977  \n",
       "11   0.858407  0.686819  0.763086  \n",
       "2    0.855290  0.682462  0.759164  \n",
       "3    0.846975  0.648148  0.734341  \n",
       "4    0.846975  0.648148  0.734341  \n",
       "5    0.846975  0.648148  0.734341  \n",
       "6    0.835320  0.610566  0.705475  \n",
       "7    0.835320  0.610566  0.705475  \n",
       "8    0.835320  0.610566  0.705475  \n",
       "12   0.835320  0.610566  0.705475  \n",
       "13   0.835320  0.610566  0.705475  \n",
       "14   0.835320  0.610566  0.705475  \n",
       "15   0.835320  0.610566  0.705475  \n",
       "16   0.835320  0.610566  0.705475  \n",
       "17   0.835320  0.610566  0.705475  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_lst=[]\n",
    "for engineering_name in feature_engineering_strategies:\n",
    "\n",
    "  # display(X_train.head(5))\n",
    "  # print(\"X_train            : \", type(X_train))\n",
    "\n",
    "  # Loop over feature engineering\n",
    "  X_train_engineered = apply_feature_engineering(X_train, engineering_name, **engineering_params[engineering_name])\n",
    "  X_test_engineered  = apply_feature_engineering(X_test,  engineering_name, **engineering_params[engineering_name])\n",
    "  # display(X_train_engineered.head(5))\n",
    "  # print(\"X_train_engineered : \", type(X_train_engineered))\n",
    "\n",
    "  # Loop over features selection\n",
    "  for selection_method, selection_params_id in feature_selection_strategies:\n",
    "    X_train_selected, X_test_selected = apply_feature_selection(X_train_engineered, y_train, X_test_engineered, selection_method, **selection_params_sets[selection_params_id])\n",
    "    # display(X_train_selected.head(5))\n",
    "    # print(\"X_train_selected   : \", type(X_train_selected))\n",
    "    \n",
    "    # Loop over models\n",
    "    for model_name, model in models:\n",
    "      scores = evaluate_model_scores(model, models_params[model_name], X_train_selected, y_train, X_test_selected, y_test)\n",
    "      \n",
    "      results_lst.append(\n",
    "        {\n",
    "            'Feature_Engineering': engineering_name,\n",
    "            'Feature_Selection': selection_params_id,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': scores['accuracy'],\n",
    "            'Precision': scores['precision'],\n",
    "            'Recall': scores['recall'],\n",
    "            'F1': scores['f1']\n",
    "        }\n",
    "      )\n",
    "\n",
    "results_df = pd.concat([pd.DataFrame([result]) for result in results_lst], ignore_index=True)\n",
    "display(results_df.sort_values(by=\"F1\", ascending=False))\n",
    "\n",
    "out_file = k_result_file + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".csv\"\n",
    "results_df.to_csv(out_file, encoding=\"utf8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
