{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier \n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures   \n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "\n",
    "k_result_file   = \"results\"\n",
    "k_target        = \"converted\"\n",
    "k_samples_ratio = 10/100  # percentage of observation to be taken into account. Pass 100/100 for final testing \n",
    "k_test_size     = 20/100  # see train_test_split\n",
    "k_random_state  = 42      # you know why...\n",
    "k_header        = \"conversion_data_test_predictions_\"\n",
    "k_author        = \"PHILIPPE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./assets/conversion_data_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick'n dirty EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (284580, 6)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>284580</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>160124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>284580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.564203</td>\n",
       "      <td>8.266789</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_user</th>\n",
       "      <td>284580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685452</td>\n",
       "      <td>0.464336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>284580</td>\n",
       "      <td>3</td>\n",
       "      <td>Seo</td>\n",
       "      <td>139477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pages_visited</th>\n",
       "      <td>284580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873252</td>\n",
       "      <td>3.341995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>284580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.176685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count unique  top    freq       mean       std   min  \\\n",
       "country                284580      4   US  160124        NaN       NaN   NaN   \n",
       "age                  284580.0    NaN  NaN     NaN  30.564203  8.266789  17.0   \n",
       "new_user             284580.0    NaN  NaN     NaN   0.685452  0.464336   0.0   \n",
       "source                 284580      3  Seo  139477        NaN       NaN   NaN   \n",
       "total_pages_visited  284580.0    NaN  NaN     NaN   4.873252  3.341995   1.0   \n",
       "converted            284580.0    NaN  NaN     NaN   0.032258  0.176685   0.0   \n",
       "\n",
       "                      25%   50%   75%    max  \n",
       "country               NaN   NaN   NaN    NaN  \n",
       "age                  24.0  30.0  36.0  123.0  \n",
       "new_user              0.0   1.0   1.0    1.0  \n",
       "source                NaN   NaN   NaN    NaN  \n",
       "total_pages_visited   2.0   4.0   7.0   29.0  \n",
       "converted             0.0   0.0   0.0    1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"shape : {df.shape}\\n\")\n",
    "print()\n",
    "\n",
    "display(df.describe(include=\"all\").T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284580 entries, 0 to 284579\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   country              284580 non-null  object\n",
      " 1   age                  284580 non-null  int64 \n",
      " 2   new_user             284580 non-null  int64 \n",
      " 3   source               284580 non-null  object\n",
      " 4   total_pages_visited  284580 non-null  int64 \n",
      " 5   converted            284580 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 13.0+ MB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null val :\n",
      "country                0.0\n",
      "age                    0.0\n",
      "new_user               0.0\n",
      "source                 0.0\n",
      "total_pages_visited    0.0\n",
      "converted              0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of null val :\")\n",
    "print(100 * df.isnull().sum() / df.shape[0])\n",
    "# print (df.isnull().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates     :  268769\n",
      "Col duplicated :  [False False False False False False]\n",
      "\n",
      "Unique countries :  ['China' 'UK' 'Germany' 'US']\n",
      "Unique sources   :  ['Direct' 'Ads' 'Seo']\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicates     : \", df.duplicated().sum())\n",
    "print(\"Col duplicated : \", df.columns.duplicated() )\n",
    "\n",
    "print()\n",
    "print(\"Unique countries : \", df[\"country\"].unique())\n",
    "print(\"Unique sources   : \", df[\"source\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-preprocessing on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "bPrepocess_df = True            # this flab indicates to do pre-preprocessing or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pre_preprocessing(df):\n",
    "  df['poids'] = df.groupby(df.columns.tolist(), sort=False).transform('size')\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# It is pre_preprocessing since it impact the number of rows\n",
    "# This mean it MUST be done on df \n",
    "# Indeed later, preprocessing has acces to X only and so rows cannot be changed\n",
    "\n",
    "def pre_preprocessing2(df):\n",
    "  \n",
    "  # print(f\"shape : {df.shape}\\n\")\n",
    "  # df.drop_duplicates(inplace=True)\n",
    "  # print(f\"shape : {df.shape}\\n\")\n",
    "\n",
    "  # print(f\"shape : {df.shape}\")\n",
    "\n",
    "  # Créer une colonne avec l poids des doublons\n",
    "  # Supprimer les doublons\n",
    "  df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "  # Compter le nombre d'occurrences de chaque ligne dans le DataFrame d'origine\n",
    "  counts = df.groupby(df.columns.tolist()).size().reset_index(name='poids')\n",
    "\n",
    "  # Fusionner la colonne occurences avec le df sans doublons\n",
    "  df = pd.merge(df_no_duplicates, counts, on=df.columns.tolist(), how='left')\n",
    "\n",
    "  # print(f\"shape : {df.shape}\")\n",
    "\n",
    "\n",
    "  # sample va faire un échantillonnage de m lignes dans df\n",
    "  # ATTENTION ca n'aide pas à comparer les résultats\n",
    "  # df = df.sample(int(k_samples_ratio*len(df)))\n",
    "\n",
    "  # Un peu dans le même esprit\n",
    "  # Afin d'accélerer les tests preliminaires on peut ne retenir que les m 1ere lignes de df\n",
    "  # Les les résultats sont constants car on prend toujours les mêmes lignes\n",
    "  # df_nouveau = df.iloc[:int(k_samples_ratio*len(df))]\n",
    "\n",
    "\n",
    "\n",
    "  return df  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (284580, 6)\n",
      "shape : (284580, 7)\n"
     ]
    }
   ],
   "source": [
    "if(bPrepocess_df):\n",
    "  print(f\"shape : {df.shape}\")\n",
    "  df = pre_preprocessing(df)  \n",
    "  print(f\"shape : {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(k_target, axis=1)\n",
    "X = df.drop(columns=k_target)\n",
    "\n",
    "y = df[k_target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "   country  age  new_user  source  total_pages_visited  poids\n",
      "0    China   22         1  Direct                    2     71\n",
      "1       UK   21         1     Ads                    3     44\n",
      "2  Germany   20         0     Seo                   14      6\n",
      "3       US   23         1     Seo                    3    253\n",
      "4       US   28         1  Direct                    3    151\n",
      "(284580, 6)\n",
      "\n",
      "y :\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: converted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X :\")\n",
    "print(X.head())\n",
    "print(X.shape)\n",
    "print()\n",
    "\n",
    "print(\"y :\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=k_test_size, random_state=k_random_state, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (227664, 6)\n",
      "\n",
      "Shape of X_train : (56916, 6)\n",
      "\n",
      "Shape of X_train : (227664,)\n",
      "\n",
      "Shape of X_train : (56916,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO Faire une fonction\n",
    "print(f\"Shape of X_train : {X_train.shape}\")\n",
    "print()\n",
    "print(f\"Shape of X_train : {X_test.shape}\")\n",
    "print()\n",
    "print(f\"Shape of X_train : {y_train.shape}\")\n",
    "print()\n",
    "print(f\"Shape of X_train : {y_test.shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'new_user', 'total_pages_visited', 'poids'], dtype='object')\n",
      "Index(['country', 'source'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X.select_dtypes(include=\"number\").columns\n",
    "print(numeric_features)\n",
    "\n",
    "categorical_features = X.select_dtypes(exclude=\"number\").columns\n",
    "print(categorical_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transformer = Pipeline(\n",
    "  steps=[\n",
    "    # (\"imputer_num\", SimpleImputer()),\n",
    "    (\"imputer_num\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler_num\", StandardScaler()),\n",
    "  ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "  steps=[\n",
    "      # (\"imputer_cat\", SimpleImputer(fill_value=\"missing\", strategy=\"constant\")),  \n",
    "      (\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),  \n",
    "      (\"encoder_cat\", OneHotEncoder(drop=\"first\")),                 \n",
    "      # (\"encoder_cat\", OneHotEncoder(handle_unknown='ignore', sparse=False)),                 \n",
    "    ]\n",
    "  )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "      (\"num\", numeric_transformer,     numeric_features),\n",
    "      (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.277  0.676 -0.262  0.23   0.     0.     1.     0.     0.   ]\n",
      " [-0.189  0.676 -0.561  0.266  0.     0.     0.     0.     0.   ]\n",
      " [ 0.657 -1.479 -0.561  0.364  0.     0.     1.     0.     1.   ]\n",
      " [-0.914  0.676  0.934  0.327  0.     0.     1.     0.     1.   ]\n",
      " [ 1.262  0.676 -0.561 -0.784  0.     1.     0.     0.     0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>num__poids</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.276505</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.261847</td>\n",
       "      <td>0.229605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.188671</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.266250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657423</td>\n",
       "      <td>-1.479005</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.363970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.913893</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>0.327325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.261775</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>-0.784242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  num__poids  \\\n",
       "0 -1.276505       0.676130                 -0.261847    0.229605   \n",
       "1 -0.188671       0.676130                 -0.560909    0.266250   \n",
       "2  0.657423      -1.479005                 -0.560909    0.363970   \n",
       "3 -0.913893       0.676130                  0.934400    0.327325   \n",
       "4  1.261775       0.676130                 -0.560909   -0.784242   \n",
       "\n",
       "   cat__country_Germany  cat__country_UK  cat__country_US  cat__source_Direct  \\\n",
       "0                   0.0              0.0              1.0                 0.0   \n",
       "1                   0.0              0.0              0.0                 0.0   \n",
       "2                   0.0              0.0              1.0                 0.0   \n",
       "3                   0.0              0.0              1.0                 0.0   \n",
       "4                   0.0              1.0              0.0                 0.0   \n",
       "\n",
       "   cat__source_Seo  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "print(X_train[0:5].round(3))\n",
    "\n",
    "# ! IMPORTANT because we work with df NOT nd array most of the time\n",
    "X_train = pd.DataFrame(X_train, columns=preprocessor.get_feature_names_out())\n",
    "display(X_train.head())\n",
    "\n",
    "X_test = pd.DataFrame(X_test, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_engineering(data, strategy='None', **kwargs):\n",
    "\n",
    "  \"\"\"\n",
    "  Applies a feature engineering strategy to the data.      \n",
    "\n",
    "  Args: \n",
    "  - data (DataFrame)  : The DataFrame containing the initial data.     \n",
    "  - strategy (str)    : The feature engineering strategy to apply.     \n",
    "  - kwargs            : Parameters specific to the feature engineering strategy.      \n",
    "\n",
    "  Returns: DataFrame  : The DataFrame containing the transformed data.     \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  match strategy:\n",
    "\n",
    "    case 'None':\n",
    "      transformed_df = data.copy()\n",
    "     \n",
    "    case 'polynomial_features':\n",
    "      degree = kwargs.get('degree', 2)          # 2 by default\n",
    "      poly = PolynomialFeatures(degree=degree)\n",
    "      transformed_data = poly.fit_transform(data)\n",
    "\n",
    "      original_feature_names = data.columns\n",
    "      feature_combinations = poly.powers_\n",
    "\n",
    "      # Generate names for the new features\n",
    "      feature_names = [\"\"]\n",
    "      for feature_combination in feature_combinations[1:]:\n",
    "          new_feature_name = \"*\".join([f\"{orig_feature}^{power}\" if power > 1 else orig_feature for orig_feature, power in zip(original_feature_names, feature_combination)])\n",
    "          feature_names.append(new_feature_name)\n",
    "\n",
    "      # new df - transformed features and their names\n",
    "      transformed_df = pd.DataFrame(transformed_data, columns=feature_names)\n",
    "\n",
    "\n",
    "      # columns = poly.get_feature_names_out(data.columns)\n",
    "      # transformed_df = pd.DataFrame(transformed_data, columns=columns)\n",
    "\n",
    "    case 'log_transform':\n",
    "      features_to_transform = kwargs.get('features_to_transform', [])\n",
    "      transformed_df = data.copy()\n",
    "      transformed_df[features_to_transform] = np.log(data[features_to_transform] + 1) # log neperien\n",
    "\n",
    "    case 'custom_feature_engineering':\n",
    "      # Design your own pizza\n",
    "      # One can use kwargs\n",
    "      transformed_df = data.copy()\n",
    "      # Ajouter ici votre logique de feature engineering personnalisée\n",
    "\n",
    "    case _:\n",
    "      raise ValueError(\"Feature engineering strategy not recognized.\")\n",
    "\n",
    "  return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(X_train, y_train, X_test, feature_selection_method='None', **kwargs):\n",
    "\n",
    "  match feature_selection_method:\n",
    "      case \"None\":\n",
    "        X_train_selected_df = X_train\n",
    "        X_test_selected_df = X_test\n",
    "               \n",
    "      case 'SelectKBest':\n",
    "        k = kwargs.get('k', 10)                            # 10 by default\n",
    "        if df.shape[1]<k:\n",
    "          k = df.shape[1]\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "        X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_train.columns[selector.get_support()])\n",
    "\n",
    "\n",
    "\n",
    "      case 'chi2':\n",
    "        selector = SelectKBest(score_func=chi2)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "        X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_train.columns[selector.get_support()])\n",
    "\n",
    "      case 'custom_feature_selection':\n",
    "        # Design your own pizza\n",
    "        # One can use kwargs\n",
    "        X_train_selected_df = X_train\n",
    "        X_test_selected_df = X_test\n",
    "      \n",
    "      case _:\n",
    "        raise ValueError(\"Feature selection method not recognized.\")\n",
    "\n",
    "  return X_train_selected_df, X_test_selected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_scores(model, params, X_train, y_train, X_test, y_test):\n",
    "\n",
    "  grid_search = GridSearchCV(model, params, cv=5, scoring='f1', n_jobs=-1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  best_params = grid_search.best_params_\n",
    "\n",
    "  model.set_params(**best_params)\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  scores = {\n",
    "    'accuracy'  : accuracy_score(y_test, y_pred),\n",
    "    'precision' : precision_score(y_test, y_pred),\n",
    "    'recall'    : recall_score(y_test, y_pred),\n",
    "    'f1'        : f1_score(y_test, y_pred)\n",
    "  }\n",
    "\n",
    "  return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Feature_Engineering', 'Feature_Selection', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies for feature engineering\n",
    "feature_engineering_strategies = [\n",
    "  'None',\n",
    "  # 'polynomial_features',         # degree\n",
    "  # 'log_transform',             # features_to_transform\n",
    "]\n",
    "\n",
    "engineering_params = {\n",
    "  'None'                : {},\n",
    "  'polynomial_features' : {'degree':2},                         \n",
    "  'log_transform'       : {'features_to_transform': [0, 1, 2]}, # ! PAS TESTE !!!!!!!!!!!!!!!!!!!! \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies for feature selection\n",
    "feature_selection_strategies = [\n",
    "  ('None', 'None'),\n",
    "  # ('SelectKBest_2', \"SelectKBest\"), \n",
    "  # (\"SelectKBest_1\", 'SelectKBest') , \n",
    "  # 'chi2',                            # !!! PAS TESTE\n",
    "]\n",
    "\n",
    "selection_params_sets = {\n",
    "  'None'          : {},\n",
    "  'SelectKBest_1' : {'k':1},                         \n",
    "  'SelectKBest_2' : {'k':2},                         \n",
    "  'chi2'          : {}, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model = a model id and a model function\n",
    "models = [\n",
    "    #(\"LogisticRegression_0\", LogisticRegression()),\n",
    "    # (\"LogisticRegression_1\", LogisticRegression()),\n",
    "    # (\"LogisticRegression_2\", LogisticRegression()),\n",
    "    #('Random Forest', RandomForestClassifier()),\n",
    "    #('XGBoost', XGBClassifier()),\n",
    "    (\"Gradient Boost Clf\", GradientBoostingClassifier())\n",
    "    # ('SVM', SVC()),\n",
    "    # ('KNN', KNeighborsClassifier()),\n",
    "    # ('Logistic Regression', LogisticRegression())\n",
    "]\n",
    "\n",
    "# Set of hyperparameters for each model_id\n",
    "models_params = {\n",
    "    'LogisticRegression_0'  : {},\n",
    "    'LogisticRegression_1'  : {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
    "    'LogisticRegression_2'  : {'C': [100], 'max_iter': [1000], 'random_state': [k_random_state]},\n",
    "    'Random Forest'         : {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]},\n",
    "    'SVM'                   : {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'KNN'                   : {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']},\n",
    "    'XGBoost'               : {'booster':['gbtree']},\n",
    "    # https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "    \"Gradient Boost Clf\"    : {'learning_rate' : [0.1, 0.01], 'n_estimators': [100, 200], 'subsample' : [1.0, 0.8]},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_engineered :  <class 'pandas.core.frame.DataFrame'>\n",
      "X_train_selected   :  <class 'pandas.core.frame.DataFrame'>\n",
      "None-None-Gradient Boost Clf : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pre processing</th>\n",
       "      <th>Feature_Engineering</th>\n",
       "      <th>Feature_Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Gradient Boost Clf</td>\n",
       "      <td>0.991373</td>\n",
       "      <td>0.878873</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.864027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pre processing Feature_Engineering Feature_Selection               Model  \\\n",
       "0            True                None              None  Gradient Boost Clf   \n",
       "\n",
       "   Accuracy  Precision    Recall        F1  \n",
       "0  0.991373   0.878873  0.849673  0.864027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_lst=[]\n",
    "\n",
    "for engineering_name in feature_engineering_strategies:\n",
    "  \n",
    "  # display(X_train.head(5))\n",
    "  # print(\"X_train            : \", type(X_train))\n",
    "\n",
    "  # Loop over feature engineering\n",
    "  X_train_engineered = apply_feature_engineering(X_train, engineering_name, **engineering_params[engineering_name])\n",
    "  X_test_engineered  = apply_feature_engineering(X_test,  engineering_name, **engineering_params[engineering_name])\n",
    "  # DataFrame\n",
    "  # display(X_train_engineered.head(5))\n",
    "  print(\"X_train_engineered : \", type(X_train_engineered))\n",
    "\n",
    "  # Loop over features selection\n",
    "  for selection_id, selection_fn in feature_selection_strategies:\n",
    "    X_train_selected, X_test_selected = apply_feature_selection(X_train_engineered, y_train, X_test_engineered, selection_fn, **selection_params_sets[selection_id])\n",
    "    # DataFrame\n",
    "    # display(X_train_selected.head(5))\n",
    "    print(\"X_train_selected   : \", type(X_train_selected))\n",
    "    \n",
    "    # Loop over models\n",
    "    for model_id, model_fn in models:\n",
    "      print(f\"{engineering_name}-{selection_id}-{model_id} : \")\n",
    "      scores = evaluate_model_scores(model_fn, models_params[model_id], X_train_selected, y_train, X_test_selected, y_test)\n",
    "      \n",
    "      results_lst.append(\n",
    "        {\n",
    "            'Pre processing'      : bPrepocess_df,\n",
    "            'Feature_Engineering' : engineering_name,\n",
    "            'Feature_Selection'   : selection_id,\n",
    "            'Model'               : model_id,\n",
    "            'Accuracy'            : scores['accuracy'],\n",
    "            'Precision'           : scores['precision'],\n",
    "            'Recall'              : scores['recall'],\n",
    "            'F1'                  : scores['f1']\n",
    "        }\n",
    "      )\n",
    "\n",
    "results_df = pd.concat([pd.DataFrame([result]) for result in results_lst], ignore_index=True)\n",
    "display(results_df.sort_values(by=\"F1\", ascending=False))\n",
    "\n",
    "trailer = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_file = \"./assets/\" + k_result_file + \"-\" + trailer + \".csv\"\n",
    "results_df.to_csv(out_file, encoding=\"utf8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement sur l'ensemble du jeu de données \n",
    "* sans le diviser en train et test\n",
    "* L'idée c'est d'utiliser un max d'observations pour ajuster les paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>poids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  age  new_user  source  total_pages_visited  poids\n",
       "0   China   22         1  Direct                    2     71\n",
       "1      UK   21         1     Ads                    3     44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284580, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = k_target)\n",
    "y = df[k_target]\n",
    "\n",
    "display(X.head(2))\n",
    "print(X.shape)\n",
    "print(type(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.036  0.677 -0.86  -0.222  0.     0.     0.     1.     0.   ]\n",
      " [-1.157  0.677 -0.561 -0.552  0.     1.     0.     0.     0.   ]\n",
      " [-1.278 -1.476  2.731 -1.017  1.     0.     0.     0.     1.   ]\n",
      " [-0.915  0.677 -0.561  2.002  0.     0.     1.     0.     1.   ]\n",
      " [-0.31   0.677 -0.561  0.755  0.     0.     1.     1.     0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>num__poids</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.276505</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.261847</td>\n",
       "      <td>0.229605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.188671</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.266250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657423</td>\n",
       "      <td>-1.479005</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.363970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.913893</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>0.327325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.261775</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>-0.784242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  num__poids  \\\n",
       "0 -1.276505       0.676130                 -0.261847    0.229605   \n",
       "1 -0.188671       0.676130                 -0.560909    0.266250   \n",
       "2  0.657423      -1.479005                 -0.560909    0.363970   \n",
       "3 -0.913893       0.676130                  0.934400    0.327325   \n",
       "4  1.261775       0.676130                 -0.560909   -0.784242   \n",
       "\n",
       "   cat__country_Germany  cat__country_UK  cat__country_US  cat__source_Direct  \\\n",
       "0                   0.0              0.0              1.0                 0.0   \n",
       "1                   0.0              0.0              0.0                 0.0   \n",
       "2                   0.0              0.0              1.0                 0.0   \n",
       "3                   0.0              0.0              1.0                 0.0   \n",
       "4                   0.0              1.0              0.0                 0.0   \n",
       "\n",
       "   cat__source_Seo  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284580, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X = preprocessor.fit_transform(X)\n",
    "print(X[0:5].round(3))\n",
    "\n",
    "# ! IMPORTANT because we work with df NOT nd array most of the time\n",
    "X = pd.DataFrame(X, columns=preprocessor.get_feature_names_out())\n",
    "display(X_train.head())\n",
    "\n",
    "print(X.shape)\n",
    "print(type(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=200, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=200, subsample=0.8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=200, subsample=0.8)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrouver les composants du meilleur classifier\n",
    "# fes       = feature engineering strategy\n",
    "# fs        = feature selection\n",
    "# model_id  = model id\n",
    "\n",
    "\n",
    "id  = results_df['F1'].idxmax()\n",
    "\n",
    "fes = results_df.at[id, \"Feature_Engineering\"]\n",
    "fs  = results_df.at[id, \"Feature_Selection\"]\n",
    "\n",
    "# fes = results_df.loc[0,\"Feature_Engineering\"]\n",
    "# fs = results_df.loc[0,\"Feature_Selection\"]\n",
    "\n",
    "for fs_current, fs_method_current in feature_selection_strategies:\n",
    "    if  fs == fs_current:\n",
    "        fs_method = fs_method_current\n",
    "        break\n",
    "\n",
    "# model_id = results_df.loc[0,\"Model\"]\n",
    "model_id = results_df.at[id, \"Model\"]\n",
    "for current_id, current_fn in models:\n",
    "    if  model_id == current_id:\n",
    "        model_fn = current_fn\n",
    "        break\n",
    "\n",
    "# On rappelle tout le monde dans le bon ordre\n",
    "X_engineered  = apply_feature_engineering(X, fes, **engineering_params[fes])\n",
    "print(type(X_engineered))\n",
    "\n",
    "X_selected, _ = apply_feature_selection(X_engineered, y, X_engineered, fs_method, **selection_params_sets[fs])\n",
    "print(type(X_selected))\n",
    "\n",
    "# Replace the call to evaluate_model_scores beacause we need access to best_params_ from here\n",
    "# scores = evaluate_model_scores(model, models_params[model_name], X_selected, y, X_selected, y)\n",
    "grid_search = GridSearchCV(model_fn, models_params[model_id], cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "model_fn.set_params(**best_params)\n",
    "\n",
    "model_fn.fit(X_selected, y) # TODO faire  un test. Sans doute à virer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 \t\t precision \t recall\n",
      "0.861616 \t 0.872293 \t 0.851198\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_fn.predict(X)\n",
    "\n",
    "print(f\"f1 \\t\\t precision \\t recall\")\n",
    "print(f\"{f1_score(y,  y_pred):.6f} \\t {precision_score(y,  y_pred):.6f} \\t {recall_score(y,  y_pred):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions sur le jeu sans label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(31620, 5)\n"
     ]
    }
   ],
   "source": [
    "df_no_labels = pd.read_csv('./assets/conversion_data_test.csv')\n",
    "print(type(df_no_labels))\n",
    "print(df_no_labels.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (31620, 5)\n",
      "shape : (31620, 6)\n"
     ]
    }
   ],
   "source": [
    "if(bPrepocess_df):\n",
    "  print(f\"shape : {df_no_labels.shape}\")\n",
    "  X_no_labels = pre_preprocessing(df_no_labels) \n",
    "  print(f\"shape : {X_no_labels.shape}\")\n",
    "else:\n",
    "  X_no_labels = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31620, 9)\n",
      "[[-0.31  -1.476  3.329 -1.078  0.     1.     0.     0.     1.   ]\n",
      " [-1.036  0.677  0.038 -1.053  0.     1.     0.     1.     0.   ]\n",
      " [ 0.174  0.677 -1.159 -0.956  0.     0.     0.     0.     1.   ]\n",
      " [ 0.174  0.677  0.337 -0.846  0.     0.     1.     0.     0.   ]\n",
      " [-0.673 -1.476 -0.561 -0.956  0.     0.     0.     0.     1.   ]]\n"
     ]
    }
   ],
   "source": [
    "X_no_labels = preprocessor.transform(X_no_labels)\n",
    "\n",
    "print(X_no_labels.shape)\n",
    "print(X_no_labels[0:5,:].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "  'converted': model_fn.predict(X_no_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'], data=data)\n",
    "\n",
    "trailer         = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_file = \"./assets/\" + k_header + k_author + \"-\" + trailer + \".csv\"\n",
    "Y_predictions.to_csv(out_file, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
