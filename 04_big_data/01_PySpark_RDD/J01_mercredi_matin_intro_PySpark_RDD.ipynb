{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b2a405a-ccc1-4de3-a2e8-8f508d5b606e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Mercredi 03 Avril\n",
    "\n",
    "# Introduction to PySpark - Part 1 - RDDs üêç‚ú®\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "This course is a demo that will introduce to you one of the main data formats in spark which is spark RDDs (Resilient Distributed Datasets), we will walk you through how to use this low level data format using pyspark.\n",
    "Here's the outline:\n",
    "\n",
    "* Databricks\n",
    "    * Login Page\n",
    "    * Homepage\n",
    "    * Workspace\n",
    "    * Create Folder\n",
    "    * Upload Notebook\n",
    "    * Notebook View\n",
    "* Spark Session and Spark Context\n",
    "* RDDs\n",
    "    * Creating RDDs\n",
    "        * Parallelizing existing collection\n",
    "        * Loading from file\n",
    "    * Playing with RDDs\n",
    "        * Actions\n",
    "            * `.take()`\n",
    "            * `.collect()`\n",
    "            * `.count()`\n",
    "            * `.sum()`\n",
    "            * `.mean()`\n",
    "            * `.reduce()`\n",
    "        * Transformations\n",
    "            * `.map()`\n",
    "            * Chaining operations\n",
    "            * `.filter()`\n",
    "        * Tuple Key-Value\n",
    "            * `.groupByKey()`\n",
    "            * `.reduceByKey()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks üß±üß±\n",
    "Databricks is a cloud service provider which makes available clusters of machines with the spark framework already installed on them. Spark can be a real pain to set up, but gets amazing results once it's all up and running. We'll use databricks here so we can all work on a standardized environment!\n",
    "\n",
    "In order to set you up with it, visit this page: [Databricks Community](https://community.cloud.databricks.com/).\n",
    "\n",
    "We'll use the community edition which is free, but limits the number and performance of the machines in our cluster. However this is not going to change a thing in terms of the code we'll write, whatever we'll learn here can scale up by connecting to a bigger cluster.\n",
    "\n",
    "Here's a walkthrough of what you should do once you are logged in ;)\n",
    "\n",
    "### Login Page üîë\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_login.PNG)\n",
    "\n",
    "### Homepage üè†\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_homepage.PNG)\n",
    "\n",
    "### Workspace üë∑\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_workspace.PNG)\n",
    "\n",
    "### Create Folder üìÅ\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_create_folder.PNG)\n",
    "\n",
    "### Upload Notebook üì§\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_import_notebook.PNG)\n",
    "\n",
    "### Notebook View üìù\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_notebook_view.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Session and Spark Context ‚ú®‚ú®\n",
    "The spark context is the original access point to the spark framework and let's you use RDDs.\n",
    "The spark session as created later and is a unified access point to the spark framework, it let's you use Spark Dataframes which we'll study later. Normally you'd have to set them up, fortunately, in databricks it is already all set up for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "355ece48-441a-496d-987f-1463afa7c873",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you wish to see what's inside the spark object and the sparkContext run these commands\n",
    "# but your code will work regardless since they have already been set up.\n",
    "spark\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0b165219-ea35-43df-95ae-06fac25d37a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## RDDs üìÑüìÑ\n",
    "\n",
    "> An immutable distributed collection of objects. Each RDD is split into multiple *partitions*, which maybe computed on different nodes of the cluster.  \n",
    "- Learning Spark, page 23 (Holden Karau, Andy Konwinski, Patrick Wendell & Matei Zaharia)\n",
    "\n",
    "\n",
    "**R**esilient **D**istributed **D**ataset (aka RDD) are the primary data abstraction in Apache Spark. They are:\n",
    "- **Resilient**: fault tolerant, they can recompute missing or damaged partitions.\n",
    "- **Distributed**: data is spread on multiple clusters\n",
    "- **Dataset**: RDDs are a collection of objects\n",
    "\n",
    "RDDs do not have a data schema, which means they do not have properly defined columns. Think of it a list of entries (rows of data) where the information contained may differ from line to line. This gives this data format great flexibility to store any type of data, but also changing data overtime (the fact that there is no predefined schema means that a new entry maybe added to the data even if it contains information that was never stored before, like a new column, which would not be possible otherwise).\n",
    "\n",
    "Moreover, RDDs are immutable (you can't change their value inplace, most like tuples) and their operations are lazy; fault-tolerance is achieved by keeping track of the \"lineage\" of each RDD (the sequence of operations that produced it) so that it can be reconstructed in the case of data loss. RDDs can contain any type of Python, Java, or Scala objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8e1e1081-df99-4fda-ab54-d1ce4a002693",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating RDDs üìÉ\n",
    "\n",
    "Spark provides two ways to create RDDs: loading an external dataset and \"parallelizing\" a collection in your driver program.  \n",
    "\n",
    "NOTE: on the most frequent usage being to load from external dataset, because usually the collection won't fit into the memory of a single machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9433ecba-f4b0-4e69-89ba-80fdd427a9fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Parallelizing an existing collection üîÄ\n",
    "\n",
    "Parallelizing an existing collection means taking a collection of objects that is not stored on a distributed file system and converting it into a distributed object by splitting the data across the machines in the cluster.\n",
    "\n",
    "To this we use then`sc.parallelize` function from the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "413fbaed-d955-48b9-a2c4-62a046829b4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[2]: PythonRDD[4] at RDD at PythonRDD.scala:58</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[2]: PythonRDD[4] at RDD at PythonRDD.scala:58</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd = sc.parallelize(range(50)) # create a collection of int and splitting it across the cluster\n",
    "numbers_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eb1f7ff8-6057-4d68-8ae9-758fc9733fb9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Loading from a file üì•\n",
    "So far we've been building RDDs from existing Python objects. We can also directly load from a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e1e230ca-cf8c-480c-9688-2563d09ded73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `sc.textFile(...)`\n",
    "This function let's Spark create an RDD from a text file, treating it as a collection of lines (which means any `\\n` newline character will define where a new element in the collection begins and ends).\n",
    "All we need for this is the **URI** from the file, and we are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "08e8b0f1-1f37-4e10-9394-7658498f3536",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[3]: s3://full-stack-bigdata-datasets/Big_Data/tears_in_rain.txt MapPartitionsRDD[6] at textFile at NativeMethodAccessorImpl.java:0</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[3]: s3://full-stack-bigdata-datasets/Big_Data/tears_in_rain.txt MapPartitionsRDD[6] at textFile at NativeMethodAccessorImpl.java:0</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_rdd = sc.textFile('s3://full-stack-bigdata-datasets/Big_Data/tears_in_rain.txt')\n",
    "text_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2658cbe1-18ce-4c77-9c1a-54c107b5bd1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Playing with RDDs üéÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2bc64fb9-0d3e-43c5-848d-ad41d89f3773",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Some resources: https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4d833465-e391-4525-9137-29dc57db45a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can perform 2 types of operations on RDDs, **actions** and **transformations**. All transformations are lazy: computations are not done until we apply an action.\n",
    "RDDs are **immutable**, we cannot change them inplace, we need to apply a **transformation** that will return an **uncomputed** RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "77281865-36e6-4705-be2f-9d08d04ab5a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### ACTIONS ü¶∏\n",
    "We will start by performing some **actions** on our RDDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "759478b3-11d1-4e97-bd65-ad34af4c67f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.take(num)`\n",
    "Returns the first `num` values of the RDD, where `num` is an integer. Like all actions, this will compute immediately.\n",
    "It is a method associated with RDD objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2f77657-3576-4d0d-940f-5cf41776fc90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[4]: [0, 1, 2]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[4]: [0, 1, 2]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6ccee970-6be3-4bd2-9ddf-27f83a1db3c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[5]: [&#34;I&#39;ve seen things you people wouldn&#39;t believe. &#34;,\n",
       " &#39;Attack ships on fire off the shoulder of Orion. &#39;,\n",
       " &#39;I watched C-beams glitter in the dark near the Tannh√§user Gate. &#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[5]: [&#34;I&#39;ve seen things you people wouldn&#39;t believe. &#34;,\n &#39;Attack ships on fire off the shoulder of Orion. &#39;,\n &#39;I watched C-beams glitter in the dark near the Tannh√§user Gate. &#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0f7380c7-b4fc-4393-bdf5-9f9b4accc1c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.collect()`\n",
    "Like `.take(...)` but will take effect on all values of the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9f903a7c-24d4-4642-8c96-844992ea4117",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[6]: [0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[6]: [0,\n 1,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n 27,\n 28,\n 29,\n 30,\n 31,\n 32,\n 33,\n 34,\n 35,\n 36,\n 37,\n 38,\n 39,\n 40,\n 41,\n 42,\n 43,\n 44,\n 45,\n 46,\n 47,\n 48,\n 49]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54bf382e-c73e-4206-85c0-b03382445733",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[7]: [&#34;I&#39;ve seen things you people wouldn&#39;t believe. &#34;,\n",
       " &#39;Attack ships on fire off the shoulder of Orion. &#39;,\n",
       " &#39;I watched C-beams glitter in the dark near the Tannh√§user Gate. &#39;,\n",
       " &#39;All those moments will be lost in time, like tears in rain. &#39;,\n",
       " &#39;Time to die.&#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[7]: [&#34;I&#39;ve seen things you people wouldn&#39;t believe. &#34;,\n &#39;Attack ships on fire off the shoulder of Orion. &#39;,\n &#39;I watched C-beams glitter in the dark near the Tannh√§user Gate. &#39;,\n &#39;All those moments will be lost in time, like tears in rain. &#39;,\n &#39;Time to die.&#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2a55ec44-da55-4b6c-93c1-e7675f4930a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If this monologue sounds familiar, that's because **[it is](https://www.youtube.com/watch?v=NoAzpa1x7jU)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6a08d4f0-996b-43ba-a6a6-0c4827559ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.count()`\n",
    "Another very useful action that returns the number of elments in a RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "192d0c20-01c7-4502-a13b-33ff78a7470c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[8]: 50</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[8]: 50</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a6c96ff2-8e66-4c9e-a3ee-9488e7411627",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.sum()`\n",
    "An action to compute the sum of elements in an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e6f5b40f-d68c-4da3-a111-ad93e23e888a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[24]: 1225</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[24]: 1225</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9bf711d-da26-4a0e-9afd-0faf89d04bee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.mean()`\n",
    "Computes the average of the RDD (requires numerical values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "71f97978-48a9-46c3-b274-254dee58d292",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[9]: 24.5</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[9]: 24.5</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ef6cefd6-daca-4753-833c-7ee077997053",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text_rdd.mean() # this will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c151ca7b-cbeb-4e55-8c51-2e6d57cd4ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you may have noticed, error messages are quite hard to read and understand in Spark, what you see here is only the tip of the iceberg, the main error message that you are getting.\n",
    "\n",
    "At the end of the message you can read `TypeError: unsupported operand type(s) for -: &#39;str&#39; and &#39;float&#39;&#39;.` this is were the useful information usually resides, at the very end, same as python. If that does not help, feel free to expand the error message and run a more detailed analysis, but for most cases the main message should suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e28f24b3-ecab-4204-ab85-64a854f1a66b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.reduce()`\n",
    "\n",
    "Spark RDD `reduce()` aggregate action function is used to calculate min, max, and total of elements in a dataset, we will explain RDD reduce function syntax and usage. The <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.RDD.reduce.html\"> documentation may be found here </a>.\n",
    "\n",
    "This function works similarly to map, but it's an action an will return a result immediately. It is used to agregate so the function we may use inside reduce take two arguments and return one, let's give a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "384369d2-6adb-41d6-a6c1-8d72a4d76fe4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[30]: 1225</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[30]: 1225</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.reduce(lambda a,b: a+b) # sums all the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "399e8fb3-7700-440d-a2cb-ae584147a130",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[31]: 0</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[31]: 0</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_rdd.reduce(lambda a,b: min(a,b)) # returns the min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c28261ab-2aa4-449f-ac6f-84b0ac14f187",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### TRANSFORMATIONS üßô\n",
    "And now we will apply some **transformations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2aa3736e-aeb5-4c3b-aa56-59468358ef85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### `.map(func)`\n",
    "Applies `func` to every element of the RDD. Won't compute anything until an action is called. It works just like the `.apply(lambda x: func(x))` method in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41f986c8-787d-4616-b269-c2d4d10586b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_rdd = text_rdd.map(lambda s: s.lower()) # we apply a function to each row in the RDD\n",
    "# since the elements of the RDD are character strings, we may use the .lower method\n",
    "# note that this lower method is a method from the SparkContext it is not a pythn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4d977e2d-b18f-495b-9fd0-e3c14845b755",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[12]: PythonRDD[12] at RDD at PythonRDD.scala:58</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[12]: PythonRDD[12] at RDD at PythonRDD.scala:58</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_rdd # when returning the mapped object, no computing happens, only the object type will be returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3ac2ebbe-5c75-4f7f-88c6-5cb8c7831738",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "How do I get my result? Use an ACTION! -> `.take(...)` or `.collect()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "691cd3e5-7395-49ce-9f8e-b94d3675f2b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[13]: [&#34;i&#39;ve seen things you people wouldn&#39;t believe. &#34;,\n",
       " &#39;attack ships on fire off the shoulder of orion. &#39;,\n",
       " &#39;i watched c-beams glitter in the dark near the tannh√§user gate. &#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[13]: [&#34;i&#39;ve seen things you people wouldn&#39;t believe. &#34;,\n &#39;attack ships on fire off the shoulder of orion. &#39;,\n &#39;i watched c-beams glitter in the dark near the tannh√§user gate. &#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_rdd.take(3) # This will returned the first 3 elements of the RDD after applying the transformation!\n",
    "# note that we only compute the transformation on the elements we will display, and not the rest, the last few elements \n",
    "# of the RDD have not been touched at all, which saves time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "09b65527-aa43-4c22-bf80-4f77608a78ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's try another example, but this time we will attempt a transformation that will fail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfef1a39-88a9-4cfd-9efc-94a2b53a215a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[14]: PythonRDD[14] at RDD at PythonRDD.scala:58</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[14]: PythonRDD[14] at RDD at PythonRDD.scala:58</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_fail_rdd = text_rdd.map(lambda s : abs(s)) # let's try and calculate the inner sum of each element in the RDD\n",
    "text_fail_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "deba94af-ae02-4485-b044-5d4a48257cf4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No error!? This is most suprising since we are attempting to run a numerical operation on character strings, let's use an action to display the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2c9d213c-ef9f-4b46-ba39-123cb5556b75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text_fail_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b7ed801-3d09-40f3-ae41-09e64567fdbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "AH, now get the error! This is the main pitfall of lazy execution, since transformations do not compute (they are lazy) they do not get to see the data until an action is run, which is why this type of error is called a runtime error, an error that occurs when operations are run, even though it comes from an operation you scheduled one or ten cells prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "165f3043-80e5-4357-9754-fd576a7483e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Chaining operations ‚õìÔ∏è\n",
    "It is possible to chain operations if you wish to run several transformations back to back, this is very useful but be careful, the more transformations you run back to back the more likely you will get a run time error later, and the harder it may be to identify exactly which transformation is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7d1322a0-ea61-4de7-b184-f99ccc8c94e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_rdd = text_rdd.map(lambda s: s.replace(\" \",\"\")).map(lambda s: len(s)) # we remove all space characters\n",
    "# then count the number of characters in each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3cdb941d-6ba3-4b9f-adf2-eb8b74caa54e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[17]: PythonRDD[16] at RDD at PythonRDD.scala:58</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[17]: PythonRDD[16] at RDD at PythonRDD.scala:58</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b2efb8e7-522a-42a1-81ba-560666cfc890",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here as well, you need to call an action (like `take` or `collect`) for the computation perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2f397961-85ed-4db9-a2cc-9b159029e570",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: [39, 39, 53, 48, 10]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[18]: [39, 39, 53, 48, 10]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "52ce45aa-3f50-4503-9498-b32a7fb4297b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "But don't do it in between two transformations!\n",
    "\n",
    "Actions convert your RDDs to lists, which means none of the things you can use on RDDs would work anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "11f8ffa6-a247-43a8-accf-03b449ec6e97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-2835273710881813&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># This will fail</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> rdd_lower <span class=\"ansi-blue-fg\">=</span> text_rdd<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> s<span class=\"ansi-blue-fg\">:</span> s<span class=\"ansi-blue-fg\">.</span>lower<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>take<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>rdd_lower<span class=\"ansi-blue-fg\">.</span>filter<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> len<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">8</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;list&#39; object has no attribute &#39;filter&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2835273710881813&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># This will fail</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> rdd_lower <span class=\"ansi-blue-fg\">=</span> text_rdd<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> s<span class=\"ansi-blue-fg\">:</span> s<span class=\"ansi-blue-fg\">.</span>lower<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>take<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>rdd_lower<span class=\"ansi-blue-fg\">.</span>filter<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> len<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">8</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;list&#39; object has no attribute &#39;filter&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;list&#39; object has no attribute &#39;filter&#39;",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will fail\n",
    "rdd_lower = text_rdd.map(lambda s: s.lower()).take(3)\n",
    "rdd_lower.filter(lambda x: len(s) > 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d0e10f58-e535-4cb0-9f24-db90f0d0b79d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**`.filter(Bool)`**\n",
    "Let's add a new **transformation**, `filter`, it will filter the RDD based on a function returning a boolean value.  \n",
    "\n",
    "*Note that when we're chaining operations, we go back to the line using Python syntax to do do, e.g. `\\`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e63ef480-58d2-48d6-87bc-45c6adb226c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = text_rdd \\\n",
    "    .map(lambda s: s.replace(\" \",\"\")) \\\n",
    "    .map(lambda s: len(s)) \\\n",
    "    .filter(lambda c: c > 50) \\\n",
    "    .collect()\n",
    "# the function inside filter returns true for each element above 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "44d5fb04-5e72-4fe8-9c6b-f50f72c141fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[21]: [53]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[21]: [53]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a89f7916-4851-4054-afc0-c05ff46572c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Seems like the only line in the text that contains more than 50 non-space characters contains 53 non-space characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7b844dd7-ff5e-45a6-a04b-e7061c7a4f9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Key-value tuples üîëüî¢\n",
    "It's common to use tuple values, as key-value pairs, this comes from the mapReduce algorithm formalism which deals with key-value pairs.\n",
    "\n",
    "Let's give an example here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bfa3b757-ee0a-4a15-af90-ccf49bda370c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[22]: ParallelCollectionRDD[19] at readRDDFromInputStream at PythonRDD.scala:413</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[22]: ParallelCollectionRDD[19] at readRDDFromInputStream at PythonRDD.scala:413</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples_rdd = sc.parallelize([\n",
    "    ('banana', 4), ('orange', 12), ('apple', 3),\n",
    "    ('pineapple', 1), ('banana', 3), ('orange', 6)])\n",
    "tuples_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c2e93a1-e443-438c-ab0f-fd1a5948328e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's now use the `.groupByKey()` method.\n",
    "This method works on key-value tuples (K,V) and automatically sets the first element of the tuple (K here) to be the key, and will group each element with the same key together to run some aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a0c94273-9d17-4eec-ac4b-45ff8a687dfa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[23]: [(&#39;orange&#39;, 18), (&#39;apple&#39;, 3), (&#39;pineapple&#39;, 1), (&#39;banana&#39;, 7)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[23]: [(&#39;orange&#39;, 18), (&#39;apple&#39;, 3), (&#39;pineapple&#39;, 1), (&#39;banana&#39;, 7)]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples_rdd.groupByKey().map(lambda t: (t[0], sum(t[1]))).collect() # after grouping by keys we use the map function to\n",
    "# tuples containing the keys and the sum of values for each key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "882c7b80-caf9-4b40-a239-2e20efb3a86a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We could also use `.reduceByKey(...)`, an action that groups and returns an aggregated result all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3bbf8b76-75d5-4c22-b000-540678ab8a0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[33]: [(&#39;orange&#39;, 18), (&#39;apple&#39;, 3), (&#39;pineapple&#39;, 1), (&#39;banana&#39;, 7)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[33]: [(&#39;orange&#39;, 18), (&#39;apple&#39;, 3), (&#39;pineapple&#39;, 1), (&#39;banana&#39;, 7)]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples_rdd.reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41363fda-62da-4895-a183-b5e9807c95db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This concludes our demo on manipulating RDD with spark, now let's move on to the exercises to get some practice!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04-Hands_on_introduction_to_PySpark_RDD",
   "notebookOrigID": 2835273710881775,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc4d3870518eee81184ced0d2279c769a0eca59aab465c4e7ec13e5e6c47a3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
