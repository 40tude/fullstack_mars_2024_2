{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b2a405a-ccc1-4de3-a2e8-8f508d5b606e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Jeudi 04 Avril\n",
    "\n",
    "# Introduction to PySpark - Part 2 - Dataframes üóÑÔ∏èüóÑÔ∏è\n",
    "\n",
    "## What will you learn in this course? üßêüßê\n",
    "\n",
    "* DataFrames\n",
    "    * Differences vs RDDs\n",
    "        * Pros of DataFrames vs RDDs\n",
    "    * Creation\n",
    "        * From a RDD\n",
    "        * From a pandas DataFrame\n",
    "* Running SQL queries against DataFrames\n",
    "    * Select columns in Spark DataFrames\n",
    "    * Actions\n",
    "        * `.show()`\n",
    "        * `.printSchema()`\n",
    "        * `.take()`\n",
    "        * `.collect()`\n",
    "        * `.count()`\n",
    "        * `.describe()`\n",
    "        * `display()`\n",
    "        * `.toPandas()`\n",
    "        * `..write()`\n",
    "    * Transformations\n",
    "        * `.na`\n",
    "        * `.fill()`\n",
    "        * `.drop()`\n",
    "        * `.isNull()`\n",
    "        * `.replace()`\n",
    "        * `.sql()`\n",
    "        * `.select()`\n",
    "        * `.alias(...)`\n",
    "        * `.drop(...)`\n",
    "        * `.limit()`\n",
    "        * `.filter()`\n",
    "        * `.selectExpr()`\n",
    "        * `.dropDuplicates()`\n",
    "        * `.distinct()`\n",
    "        * `.orderBy()`\n",
    "        * `.groupBy()`\n",
    "        * `.withColumn()`\n",
    "        * `.withColumnRenamed()`\n",
    "        * Chaining everything together\n",
    "        \n",
    "* Some differences with pandas' DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "769baeee-6bd2-4158-abde-94000cce1b6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DataFrames üóÑÔ∏èüóÑÔ∏è\n",
    "\n",
    "A distributed collection of data grouped into named columns.  \n",
    "\n",
    "A¬†DataFrame¬†is equivalent to a relational table in SQL.\n",
    "\n",
    "---\n",
    "> ‚ö†Ô∏è Although they're called DataFrames, Spark DataFrames are actually closer to SQL tables than pandas'.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "> üí° If you want an API closer to pandas while maintaining fast big data processing capabilities, take a look at [koalas](https://github.com/databricks/koalas) (still in beta).\n",
    "---\n",
    "\n",
    "Spark DataFrames actually have richer optimizations than both SQL tables and pandas DataFrames (cf. [doc](https://spark.apache.org/docs/2.2.0/sql-programming-guide.html#overview))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e9aa041-7bf9-4ee9-a597-911ceb39aa28",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DataFrames vs RDDs üóÑÔ∏èüÜöüìÉ\n",
    "\n",
    "Contrary to Spark's RDDs, DataFrames are not schema-less.\n",
    "\n",
    "#### Pros of DataFrames vs RDDs ‚ûï‚ûñ\n",
    "\n",
    "* \\- they enforce a schema\n",
    "* \\+ you can run SQL queries against them\n",
    "* \\+ faster than RDDs\n",
    "* \\+ much smaller than RDDs when stored in parquet format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "56867cab-e233-4ff6-974d-3ea031020c27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creation ‚ú®\n",
    "\n",
    "There are several ways of creating a Spark DataFrame, one way is to build it from an RDD, or from a pandas DataFrame, another way is to create it directly from a `.csv` or `.parquet` file stored in a distributed file system. (`.parquet` is a compression format for column oriented files, it encodes the values in each column and stores the actual values in correspondance tables, which allows for much smaller storage format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ac1f328c-8bb0-4a4b-9306-3bea2afaa643",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### From a RDD üìÉ‚û°üóÑÔ∏è\n",
    "\n",
    "Let's see how we can create a Spark DataFrame from and RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a2fd0dab-cae4-4414-9af8-610cd8acfc8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9912c4b2-0506-4952-87f5-bb218abb4e13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers = [i for i in range(10)]\n",
    "numbers_rdd = sc.parallelize(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e388d9b0-92e1-4de4-85d8-94fdc9d61bd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This will fail, requires either rdd of tuples or a pandas DataFrame\n",
    "spark.createDataFrame(numbers_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "726ae837-4a7f-4ad1-b359-c59f68e949eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We know how to transform values of a RDD: `.map(...)`. Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "209fe431-e15d-46f3-a3c0-19bace323a7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_1</th></tr></thead><tbody><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>5</td></tr><tr><td>6</td></tr><tr><td>7</td></tr><tr><td>8</td></tr><tr><td>9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0
        ],
        [
         1
        ],
        [
         2
        ],
        [
         3
        ],
        [
         4
        ],
        [
         5
        ],
        [
         6
        ],
        [
         7
        ],
        [
         8
        ],
        [
         9
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": [],
        "xColumns": [],
        "yColumns": []
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_1",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.createDataFrame(numbers_rdd.map(lambda k: (k,)))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a331478d-8a14-4063-9e29-f4c99c28b310",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### From a pandas DataFrame üêº‚û°üóÑÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "15c8d721-81d8-4cf0-924b-4fd94f128611",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[6]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[6]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>e</th>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_dict = {'a': 1, 'b': 2, 'c': 3, 'd':np.NaN, 'e':3}\n",
    "pandas_df = pd.DataFrame.from_dict(\n",
    "    data_dict, orient='index', columns=['position'])\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3d50d6a7-95f4-4e31-8bd9-7bfdb7d6ce0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[8]: DataFrame[position: double]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[8]: DataFrame[position: double]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1d8156ab-3c5d-4b99-ae04-00c512530e28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>position</th></tr></thead><tbody><tr><td>1.0</td></tr><tr><td>2.0</td></tr><tr><td>3.0</td></tr><tr><td>null</td></tr><tr><td>3.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ],
        [
         2
        ],
        [
         3
        ],
        [
         null
        ],
        [
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": [],
        "xColumns": [],
        "yColumns": []
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "position",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aa19656e-f069-4438-9bcb-ff2d4be04879",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Running sql queries against DataFrames üóÑÔ∏èüî¢\n",
    "\n",
    "Spark let's you run classic SQL queries on your tables, however, using classic SQL in Spark requires you to load the data in memory before running any query. We will use the `.createOrReplaceTempView` Spark DataFrame method in order to load the data in memory under a certain table name, we will then be able to run SQL queries on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "960e847f-da3e-4761-9854-173dae3974f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.createOrReplaceTempView('my_table') # Creates a temporary view of the spark dataframe table in memory under the name\n",
    "# my_table, which we can now query!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36a05858-4f65-4f07-b7a5-4a9cf6aab2f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The `.sql` method let's you write queries in SQL while benefiting from the distributed computing advantages of Spark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d897b9b1-13ba-4aa4-b6cd-c73fcbdc9ad0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>position</th></tr></thead><tbody><tr><td>2.0</td></tr><tr><td>3.0</td></tr><tr><td>3.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2
        ],
        [
         3
        ],
        [
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": [],
        "xColumns": [],
        "yColumns": []
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "position",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = spark.sql(\"SELECT * FROM my_table WHERE position >= 2\") # filters elements from my_table where position \n",
    "# is greater or equal to 2\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "543a9152-037c-4352-be57-457656cdb004",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This will return a `DataFrame` but **will not compute until an action is called**. Even though the query we wrote is SQL, we use it through the Spark framework which is lazy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fd0d7c41-c02a-4fed-8f98-56995635105b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Select columns in Spark DataFrames ‚¨áÔ∏è\n",
    "There are three ways of selecting columns in spark dataframes. Note that columns in dataframes in spark are objects in themselves, and sometimes it is not enough to call them simply by name, we need to refer to the column object directly to prevent ambiguity and bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "19f0c36f-fa98-4860-913d-c1164c83f9a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[24]: Column&lt;&#39;position&#39;&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[24]: Column&lt;&#39;position&#39;&gt;</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First way: refer to column by indexing\n",
    "result[\"position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc01a81d-3d74-4f84-abab-cfb4aa30f182",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[25]: Column&lt;&#39;position&#39;&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[25]: Column&lt;&#39;position&#39;&gt;</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second way: refer to column like an attribute\n",
    "result.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "761408d3-9923-4ec9-8267-30a45d3b8e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[26]: DataFrame[position: double]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[26]: DataFrame[position: double]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third way: use pyspark sql (you'll learn a lot more about this in further lectures)\n",
    "from pyspark.sql import functions as F\n",
    "result.select(F.col(\"position\")) # this works only inside pyspark sql commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e21e0764-1797-4a33-9ca7-32c4b80d6435",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Actions ü¶∏\n",
    "All actions perform computations, some like `show` or `printSchema` print out results without returning anything, others, like `count` will return a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3b076c93-9e42-40b9-b552-b6fe12b7c708",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.show(...)`\n",
    "Prints out the first 20 values of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b028b752-4799-462a-abad-a2a75af30452",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "84f73a22-3670-4380-a89d-141de79b874c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Default can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfe59933-5253-426d-8614-63dacdf4c0ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "+--------+\n",
       "only showing top 2 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n+--------+\nonly showing top 2 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "45ea562b-368f-4eb6-9460-e6e06fccb542",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.printSchema()`\n",
    "Prints out the schema of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ff498d8-2438-4295-83c4-35d8acb826be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- position: double (nullable = true)\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- position: double (nullable = true)\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7d665624-3046-4355-9cba-7f0ea5df7da3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A schema is a description of the content of structured data. A schema is composed of column names and types. For example, the DataFrame above contains a single column called `position`, which type is `double` meaning a long floating point number. Columns may be of many other types, like `int`, `str`, or even interables like lists or dictionnaries. We will teach you more about schemas when we cover the topics of nested schemas and flat schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d6f688d2-0bf0-414e-8a13-f13af096314e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[15]: [&#39;position&#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[15]: [&#39;position&#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.columns  # not an `action` (nor a transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96d5828e-616a-42f5-bdb6-fe359e59eacc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.take(...)`\n",
    "Compute the first n values of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b7cf2705-d8fe-47c0-b27b-9003876ec1c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: [Row(position=1.0), Row(position=2.0)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[16]: [Row(position=1.0), Row(position=2.0)]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ad60a32e-2300-4003-8b69-7a17b52fa6a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can see, a PySpark `DataFrame` is a collection of [`Row`](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.Row) objects (cf [doc](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.Row))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a93dd727-7ee5-49c1-bbb3-b7c99331601e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.collect(...)`\n",
    "Like `.take(...)` but will take effect on all rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ba9cf118-a3f1-4a20-903d-17f51d4cf185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[17]: [Row(position=1.0),\n",
       " Row(position=2.0),\n",
       " Row(position=3.0),\n",
       " Row(position=None),\n",
       " Row(position=3.0)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[17]: [Row(position=1.0),\n Row(position=2.0),\n Row(position=3.0),\n Row(position=None),\n Row(position=3.0)]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "675a0264-f6a4-4914-8df4-57179ba79fd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---\n",
    "‚ö†Ô∏è `.collect()` will collect all the values, do **NOT** perform this action on a full DataFrame, only on small DataFrames like aggregated results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "74134c76-41f2-439e-a86b-81ff4af60a44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.count(...)`\n",
    "Returns the number of `Rows` in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c20e7ea1-5e9d-474c-9f8f-2ef0de1c8857",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: 5</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[18]: 5</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Databrick's `display(...)`\n",
    "For when `.show()` won't cut it...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "058ee6bc-5211-483d-ab9a-eff9958604bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>position</th></tr></thead><tbody><tr><td>1.0</td></tr><tr><td>2.0</td></tr><tr><td>3.0</td></tr><tr><td>null</td></tr><tr><td>3.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ],
        [
         2
        ],
        [
         3
        ],
        [
         null
        ],
        [
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": [],
        "xColumns": [],
        "yColumns": []
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "position",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slow and won't work everywhere... BUT! Let's you access the GraphX interface to do some visualization, all you have to do is click on the barchart button to start visualizing, and use the button plot options that just appeared to refine your viz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative: converting to pandas with `.toPandas()`\n",
    "Using `toPandas()`: this is an action, it will compute.  \n",
    "Hence, do **NOT** forget to `limit` or you'll explode the memory (unless the DataFrame is small, like the result of an aggregate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "73c43e3b-617b-4558-89d3-869d3a32fc04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[126]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[126]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.write()`\n",
    "\n",
    "If you wish to save your files to a location in the S3 it is possible with the `.write()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.write(\"path\", mode=\"overwrite\") # mode overwrite will erase any file that \n",
    "# already occupies the destination path.\n",
    "\n",
    "# If you wish to save the file in compressed parquet format it is possible using this option\n",
    "playlog_processed.write.parquet(output_path, mode='overwrite')\n",
    "\n",
    "# To load a parquet file as a dataframe use\n",
    "spark_df = spark.read.parquet(\"path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4fe35256-bd2a-48ba-96ea-b2bcbfc07d06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transformations üßô\n",
    "Let's study some transformations available on spark DataFrames, more exhaustive content may be found in the following link:\n",
    "- [PySpark Doc](https://spark.apache.org/docs/2.1.0/sql-programming-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f7140b52-8dec-453c-90b8-b1ce9ead0455",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.na` for missing values\n",
    "This is a method associated with spark DataFrame that let's you run jobs on the missing values, like replacig them etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eadb6b9a-ee65-48f2-a2aa-f41b58d056df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[19]: &lt;pyspark.sql.dataframe.DataFrameNaFunctions at 0x7f8fe5848910&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[19]: &lt;pyspark.sql.dataframe.DataFrameNaFunctions at 0x7f8fe5848910&gt;</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d09ef3ca-1ae2-427e-9570-9d750d8e6362",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.fill(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3ef4030a-6ce5-4f78-808d-7f70b91a3cd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "     0.0|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|     0.0|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.na.fill(0).show() # this will replace the missing value with 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b156ed34-1f6c-44f7-b966-eb7483f51d5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "508ab18b-fa4f-4baa-8a17-5e882a7d9d74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.na.drop().show() # this will drop the lines containing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "03d125bf-82be-403e-94da-34a227312fc9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Equivalent to `.dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "98c63bd1-5967-4b8d-9845-a7ac18a663ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.dropna(subset=['position']).show() # this will also drop the lines with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b55f0845-e390-4266-b1b2-5a11e6f90605",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Optional parameter, select a `subset` of columns. This is useful if you only wish to drop lines with missing values on specific columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f14feb5a-fc6d-4137-80e2-539544e885a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.isNull()`\n",
    "Another way to detect missing values in specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dab8e058-70cd-470d-9e0e-c65ac42447c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4434948684774541&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>spark_df<span class=\"ansi-blue-fg\">.</span>isNull<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, name)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1664</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1665</span>         <span class=\"ansi-green-fg\">if</span> name <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>columns<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1666</span><span class=\"ansi-red-fg\">             raise AttributeError(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1667</span>                 &#34;&#39;%s&#39; object has no attribute &#39;%s&#39;&#34; % (self.__class__.__name__, name))\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1668</span>         jc <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;isNull&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4434948684774541&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>spark_df<span class=\"ansi-blue-fg\">.</span>isNull<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1664</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   1665</span>         <span class=\"ansi-green-fg\">if</span> name <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>columns<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1666</span><span class=\"ansi-red-fg\">             raise AttributeError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1667</span>                 &#34;&#39;%s&#39; object has no attribute &#39;%s&#39;&#34; % (self.__class__.__name__, name))\n<span class=\"ansi-green-intense-fg ansi-bold\">   1668</span>         jc <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;isNull&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;isNull&#39;",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select(spark_df[\"position\"].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5ac1670f-d21c-4186-90e3-40dfd0f99ede",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.replace(pattern, value)`\n",
    "This method will replace every data point equal to `pattern` with `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0c845991-3ee1-40f0-b433-6145aad1d2b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     4.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     4.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.replace(2, 4).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "360c5564-6415-433d-8f47-2dad7ae688ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Be careful however you may not replace values in the DataFrame that conflict with the schema, for example it is not possible to replace the value 2 in a double type column with a character string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "72fd3ad0-a633-481c-803b-7ba49117b8bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4434948684774453&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;jedha&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">replace</span><span class=\"ansi-blue-fg\">(self, to_replace, value, subset)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2247</span>                    <span class=\"ansi-green-fg\">and</span> all_of_type<span class=\"ansi-blue-fg\">(</span>x <span class=\"ansi-green-fg\">for</span> x <span class=\"ansi-green-fg\">in</span> rep_dict<span class=\"ansi-blue-fg\">.</span>values<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">if</span> x <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2248</span>                    for all_of_type in [all_of_bool, all_of_str, all_of_numeric]):\n",
       "<span class=\"ansi-green-fg\">-&gt; 2249</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Mixed type replacements are not supported&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2250</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2251</span>         <span class=\"ansi-green-fg\">if</span> subset <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">ValueError</span>: Mixed type replacements are not supported</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4434948684774453&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;jedha&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">replace</span><span class=\"ansi-blue-fg\">(self, to_replace, value, subset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2247</span>                    <span class=\"ansi-green-fg\">and</span> all_of_type<span class=\"ansi-blue-fg\">(</span>x <span class=\"ansi-green-fg\">for</span> x <span class=\"ansi-green-fg\">in</span> rep_dict<span class=\"ansi-blue-fg\">.</span>values<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">if</span> x <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2248</span>                    for all_of_type in [all_of_bool, all_of_str, all_of_numeric]):\n<span class=\"ansi-green-fg\">-&gt; 2249</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Mixed type replacements are not supported&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2250</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2251</span>         <span class=\"ansi-green-fg\">if</span> subset <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">ValueError</span>: Mixed type replacements are not supported</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">ValueError</span>: Mixed type replacements are not supported",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.replace(2, \"jedha\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "edb7bce8-aa83-45c5-919d-9c41b5b97550",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.sql()` \n",
    "We can run SQL queries against a registered view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d10439ec-6aec-4a63-9ede-a848f9cee104",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_table LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "182088b2-f85b-45d9-9085-b23aa37b797c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Multi-line statements need the use of triple quotes `\"\"\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "15f23c54-0577-44ca-aa2a-f3dd93e4a632",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT position\n",
    "    FROM my_table\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "71952cfb-33a5-4b10-9015-5e598ffeab0f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "That's convenient, but we can use PySpark DataFrames API to perform the same operations. The main difference between writing standard SQL and using PysparkSQL is that you will no longer need to load the entire data in memory to start running queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "209d32b1-e389-4a88-8bbb-1399b8e274f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.select()`\n",
    "The select method works similarly to the select statement in SQL, it let's you access columns of your DataFrame by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d9be7232-5f75-413e-93c6-ed90c3d1542c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- position: double (nullable = true)\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- position: double (nullable = true)\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2731c4e0-90dc-4853-b475-734ef4e3ecb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[92]: DataFrame[position: double]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[92]: DataFrame[position: double]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select('position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b9a32470-3ae9-4c7b-912f-1222e858f82d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Similar to `spark.sql.select(\"SELECT position FROM my_table\")`.  \n",
    "To claim equivalence, we would have to check the execution plan of both (which is beyond the content of this course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fcfcea5d-e334-4391-9064-9e5b3704c723",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.alias(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "77efebf1-9347-4663-88f8-51b7eeeb0492",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------+\n",
       "aliased_column|\n",
       "+--------------+\n",
       "           1.0|\n",
       "           2.0|\n",
       "           3.0|\n",
       "          null|\n",
       "           3.0|\n",
       "+--------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------+\n|aliased_column|\n+--------------+\n|           1.0|\n|           2.0|\n|           3.0|\n|          null|\n|           3.0|\n+--------------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select(spark_df['position'].alias('aliased_column')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5693654-6c30-4933-b310-412a9f94d14f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------+\n",
       "aliased_column|\n",
       "+--------------+\n",
       "           1.0|\n",
       "           2.0|\n",
       "           3.0|\n",
       "          null|\n",
       "           3.0|\n",
       "+--------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------+\n|aliased_column|\n+--------------+\n|           1.0|\n|           2.0|\n|           3.0|\n|          null|\n|           3.0|\n+--------------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select(spark_df['position'].alias('aliased_column')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a6cb4837-0ca1-4271-a2c8-3bedb3bace06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4434948684774400&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Won&#39;t work on this, it requires a Column selector, this is where the ambiguity of calling colums by name hurts</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;position&#39;</span><span class=\"ansi-blue-fg\">.</span>alias<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;aliased_column&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;str&#39; object has no attribute &#39;alias&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4434948684774400&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Won&#39;t work on this, it requires a Column selector, this is where the ambiguity of calling colums by name hurts</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;position&#39;</span><span class=\"ansi-blue-fg\">.</span>alias<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;aliased_column&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;str&#39; object has no attribute &#39;alias&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;str&#39; object has no attribute &#39;alias&#39;",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Won't work on this, it requires a Column selector, this is where the ambiguity of calling colums by name hurts\n",
    "spark_df.select('position'.alias('aliased_column')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1585a1a-5345-4c57-b7d9-8bf1c992921b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.drop(...)`\n",
    "This method let's you remove columns from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cec6f148-dc48-44ed-85d4-8b86137c47d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[102]: DataFrame[]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[102]: DataFrame[]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.drop('position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aec90bff-7d19-4a9b-a604-eeac7807fdcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">++\n",
       "|\n",
       "++\n",
       "|\n",
       "|\n",
       "|\n",
       "|\n",
       "|\n",
       "++\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">++\n||\n++\n||\n||\n||\n||\n||\n++\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.drop('position').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0472ee67-c339-4dd0-a95c-accb75ac68dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.limit(num)`\n",
    "Like SQL's `LIMIT`.  \n",
    "Limits the DataFrame to `num` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bc3d5bf5-8ea6-454e-81d1-d6d9929b761c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "711054a2-25e1-4454-9192-4317b3a1a635",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.filter(...)`\n",
    "It just works like the WHERE clause in SQL and lets you keep only rows of the DataFrame that verify the condition inside the filter method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df7d8449-b94b-4379-8867-6ce70b0c31f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[105]: DataFrame[position: double]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[105]: DataFrame[position: double]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.filter(spark_df['position'] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c7b18242-8c7f-426d-89eb-1e2310ae13f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.filter(spark_df.position < 3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c6994914-de85-48cb-a9d5-a86a685d7ae5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "--- \n",
    "> üí° We can even mix both the SQL and SparkSQL APIs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "884b507a-de68-4330-b056-b00dbd892bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.selectExpr`\n",
    "This method lets you select columns in a DataFrame using SQL statements without having to store a temp view of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "92a26f39-09e2-417e-8d48-f8422a776c27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------+-------------+\n",
       "(position * 2)|abs(position)|\n",
       "+--------------+-------------+\n",
       "           2.0|          1.0|\n",
       "           4.0|          2.0|\n",
       "           6.0|          3.0|\n",
       "          null|         null|\n",
       "           6.0|          3.0|\n",
       "+--------------+-------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------+-------------+\n|(position * 2)|abs(position)|\n+--------------+-------------+\n|           2.0|          1.0|\n|           4.0|          2.0|\n|           6.0|          3.0|\n|          null|         null|\n|           6.0|          3.0|\n+--------------+-------------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.limit(5).selectExpr(\"position * 2\", \"abs(position)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "973462ca-09d3-4794-a941-44c9f98371f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.dropDuplicates(...)`\n",
    "As its name suggests, this method will drop rows that are identical to other rows in the DataFrame, returning a DataFrame where all rows are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "70b8014b-c527-4577-b799-df2151f67720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "856ecb11-41ff-45fc-bfc7-424043afe1ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.distinct()`\n",
    "This method will return all distinct non missing values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "85aca635-3663-444d-ae2d-d274ae027f4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "       1|\n",
       "       2|\n",
       "       3|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|       1|\n|       2|\n|       3|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2d15c231-19c9-4fb8-86e6-3fdf5d107123",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.orderBy(...)`\n",
    "Alias to `.sort(...)`\n",
    "Will sort the DataFrame according to some column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63b63b30-8d5f-4440-a69d-0ddae1561b36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "    null|\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|    null|\n|     1.0|\n|     2.0|\n|     3.0|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.orderBy('position').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9649f418-ea43-4ff1-857f-fea0ef42e20a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can call `.desc()` to get a descending order, but that means we need an actual `Column` object to call it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "27e2c66f-a5b8-492d-aefb-decc5f58a519",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4434948684774424&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># This will fail</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>orderBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;position&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>desc<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;str&#39; object has no attribute &#39;desc&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4434948684774424&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># This will fail</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>orderBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;position&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>desc<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;str&#39; object has no attribute &#39;desc&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;str&#39; object has no attribute &#39;desc&#39;",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will fail\n",
    "spark_df.orderBy(('position').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3154946c-c0a6-4b8e-aab7-f7d5474007b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     3.0|\n",
       "     3.0|\n",
       "     2.0|\n",
       "     1.0|\n",
       "    null|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     3.0|\n|     3.0|\n|     2.0|\n|     1.0|\n|    null|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This won't\n",
    "spark_df.orderBy(spark_df['position'].desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b152dc3c-5ed7-46d8-b264-12e1d4935f39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "That's actually one of the key to SparkSQL fluency, but it requires some practice.\n",
    "\n",
    "---\n",
    "\n",
    "‚≠êÔ∏è No worries, we will review all this later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c0254752-861d-4209-b62c-7871d99e6efb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.groupBy(...)`\n",
    "\n",
    "It is possible to group your data according to values in a certain column and then aggregate it, we will learn more on data aggregating in further lecture, this is just a brief introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "efd5a52e-e956-46bc-b41b-868abf080d78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[116]: &lt;pyspark.sql.group.GroupedData at 0x7f3967bdd4c0&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[116]: &lt;pyspark.sql.group.GroupedData at 0x7f3967bdd4c0&gt;</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.groupBy('position') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2b74c760-2a32-4f53-a78f-d6480d3f90a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Returns a `GroupedData` object. We need to take some action on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "668c97e4-5e80-43bb-b136-688e36591d1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4434948684774430&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># This won&#39;t work</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>groupBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;position&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;GroupedData&#39; object has no attribute &#39;show&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4434948684774430&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># This won&#39;t work</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>groupBy<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;position&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;GroupedData&#39; object has no attribute &#39;show&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;GroupedData&#39; object has no attribute &#39;show&#39;",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This won't work\n",
    "spark_df.groupBy('position').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "457b341c-8bf0-4b19-961b-94ac24b9c321",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[118]: DataFrame[position: double, count: bigint]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[118]: DataFrame[position: double, count: bigint]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another action, this one works\n",
    "spark_df.groupBy('position').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "93504cf6-6d85-441d-84c1-e6bbe3184961",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "‚ö†Ô∏è When applied to a DataFrame, `.count()` is an action. In this case we apply it to an object of type `GroupedData` and it returns a `DataFrame`, e.g. still waiting for an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5acf6022-89df-4fbe-926d-4103ed01c8ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+-----+\n",
       "position|count|\n",
       "+--------+-----+\n",
       "     1.0|    1|\n",
       "     2.0|    1|\n",
       "     3.0|    2|\n",
       "    null|    1|\n",
       "+--------+-----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+-----+\n|position|count|\n+--------+-----+\n|     1.0|    1|\n|     2.0|    1|\n|     3.0|    2|\n|    null|    1|\n+--------+-----+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.groupBy('position').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4c483a1-688b-4d34-8144-d0825d77cbb0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Adding columns ‚ûï\n",
    "Using pure select is possible, but can feel tedious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b38baa1a-d856-423c-834d-9c55e21c8a16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+---------+\n",
       "position|newColumn|\n",
       "+--------+---------+\n",
       "     1.0|      2.0|\n",
       "     2.0|      4.0|\n",
       "     3.0|      6.0|\n",
       "    null|     null|\n",
       "     3.0|      6.0|\n",
       "+--------+---------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+---------+\n|position|newColumn|\n+--------+---------+\n|     1.0|      2.0|\n|     2.0|      4.0|\n|     3.0|      6.0|\n|    null|     null|\n|     3.0|      6.0|\n+--------+---------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select('*', (spark_df.position*2).alias('newColumn')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "15531010-4d72-4abe-a7c5-cfaddf77c461",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `.withColumn(...)`\n",
    "It's usually easier to use `.withColumn` for the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8576c150-9366-421b-ad25-310fddca7f56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+---------+\n",
       "position|newColumn|\n",
       "+--------+---------+\n",
       "     1.0|      2.0|\n",
       "     2.0|      4.0|\n",
       "     3.0|      6.0|\n",
       "    null|     null|\n",
       "     3.0|      6.0|\n",
       "+--------+---------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+---------+\n|position|newColumn|\n+--------+---------+\n|     1.0|      2.0|\n|     2.0|      4.0|\n|     3.0|      6.0|\n|    null|     null|\n|     3.0|      6.0|\n+--------+---------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.withColumn('newColumn', 2*spark_df['position']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3db26dc1-89d4-40fa-944a-8fd05a75cc52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### `withColumnRenamed(...)`\n",
    "Will change the name of a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "251b9db7-2068-4eed-b297-b2b5345c5dee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+\n",
       "newName|\n",
       "+-------+\n",
       "    1.0|\n",
       "    2.0|\n",
       "    3.0|\n",
       "   null|\n",
       "    3.0|\n",
       "+-------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------+\n|newName|\n+-------+\n|    1.0|\n|    2.0|\n|    3.0|\n|   null|\n|    3.0|\n+-------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.withColumnRenamed('position', 'newName').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "21ee8027-10dc-402a-aadf-833f3c72fdca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Chaining everything together ‚õìÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "14a4885a-c2b8-46da-ab0d-33b4c222ac13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+-----+\n",
       "position|count|\n",
       "+--------+-----+\n",
       "     1.0|    1|\n",
       "+--------+-----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+-----+\n|position|count|\n+--------+-----+\n|     1.0|    1|\n+--------+-----+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df \\\n",
    "    .filter(spark_df.position < 2) \\\n",
    "    .groupBy('position') \\\n",
    "    .count() \\\n",
    "    .orderBy('count') \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b40c0f58-e0fa-4a5e-981b-3ad335796b95",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Some differences with pandas' DataFrames üêºüÜöüóÑÔ∏è\n",
    "\n",
    "- Accessor: `df.features`, `df['features']` vs `df.select('features')` -> more later\n",
    "- Also, most (if not all) transformations in PySpark are not `inplace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5466d62f-8bf8-46f0-b2a6-56dbba540f4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[93]: Column&lt;&#39;position&#39;&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[93]: Column&lt;&#39;position&#39;&gt;</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a0dc19a1-15b1-4468-9446-d850ce878869",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[94]: Column&lt;&#39;position&#39;&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[94]: Column&lt;&#39;position&#39;&gt;</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " spark_df['position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "92b5c092-73f2-4550-a281-e959bce1c318",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "But in a case like this, just like SQL, the executor can infer the \"table\" schema, this will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e206a30-3596-4ddc-84ff-f193551543a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[97]: DataFrame[position: double]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[97]: DataFrame[position: double]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select('position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a795eeeb-ce8b-4fb1-b059-1397eef5a627",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "It is recommended to always access columns with column objects in select statements and not by name in str directly as it will cause your jobs to fail when running more advanced queries on your DataFrame columns. Usin the column object removes any ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4c98a98-258c-4b14-a902-0804b947b49d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select('position').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ab7c5f87-60ec-462e-938e-41319062bbbd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "These two statements are returning column objects.\n",
    "Not very useful by themselves, but can be passed to a `.select(...)`, and then let you run more advanced operations on columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "faacc2aa-a55e-4881-9a2d-9176a805fe05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select(spark_df.position).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e07f709a-122a-4f63-b77f-1ce686c5544c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "position|\n",
       "+--------+\n",
       "     1.0|\n",
       "     2.0|\n",
       "     3.0|\n",
       "    null|\n",
       "     3.0|\n",
       "+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+\n|position|\n+--------+\n|     1.0|\n|     2.0|\n|     3.0|\n|    null|\n|     3.0|\n+--------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select(spark_df['position']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d8834c8f-6003-4f24-ad2f-ab68c21c3326",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Resources üìöüìö\n",
    "- The part about DataFrames in [Mastering Spark SQL](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-DataFrame.html) (Scala based)\n",
    "- [Learning Apache Spark with PySpark & Databricks](https://hackersandslackers.com/learning-to-use-apache-spark-pyspark/)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02-Hands_on_introduction_to_PySpark",
   "notebookOrigID": 4434948684774337,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc4d3870518eee81184ced0d2279c769a0eca59aab465c4e7ec13e5e6c47a3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
