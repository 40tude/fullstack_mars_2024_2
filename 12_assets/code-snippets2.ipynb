{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table des matières\n",
    "Dans VSCode, pensez aussi à utiliser la section **OUTLINE** (colonne de gauche, en bas, au dessus de TIMELINE)\n",
    "\n",
    "1. [Remplacer les valeurs absentes par 42 - fillna()](#remplacer-les-valeurs-absentes-par-42---fillna)\n",
    "1. [Remplacer les valeurs absentes par la médiane - fillna()](#remplacer-les-valeurs-absentes-par-la-médiane---fillna)\n",
    "1. [Remplacer les valeurs absentes par 42 - SimpleImputer()](#remplacer-les-valeurs-absentes-par-42---simpleimputer)\n",
    "1. [Remplacer une valeur par une autre](#remplacer-une-valeur-par-une-autre)\n",
    "1. [N'afficher que les lignes où le PIB est vide](#nafficher-que-les-lignes-où-le-pib-est-vide)\n",
    "1. [Afficher les lignes d'une même catégorie](#afficher-les-lignes-dune-même-catégorie)\n",
    "1. [Afficher les catégories où le % de valeurs manquantes est non nul](#afficher-les-catégories-où-le--de-valeurs-manquantes-est-non-nul)\n",
    "1. [Créer des colonnes avec le contenu d'une colonne](#créer-des-colonnes-avec-le-contenu-dune-colonne)\n",
    "1. [Calculer de nouvelles colonnes](#calculer-de-nouvelles-colonnes)\n",
    "1. [Créer une colonne qui contient des catégories](#créer-une-colonne-qui-contient-des-catégories)\n",
    "1. [Difference entre `apply()` et `transform()`](#difference-entre-apply-et-transform)\n",
    "  1. [aply()](#apply)\n",
    "  1. [transform()](#transform)\n",
    "1. [Extraire les nombres d'une chaîne et créer une colonne](#extraire-les-nombres-dune-chaîne-et-créer-une-colonne)\n",
    "1. [Extraire les valeurs d'une chaine, remplir une colone avec leur moyenne](#extraire-les-valeurs-dune-chaine-remplir-une-colone-avec-leur-moyenne)\n",
    "[Transform (s'applique à un groupe)](#transform-sapplique-à-un-groupe)\n",
    "1. [groupby : remplacer valeurs manquantes par moyenne de la catégorie](#groupby--remplacer-valeurs-manquantes-par-moyenne-de-la-catégorie)\n",
    "1. [groupby : remplacer valeurs manquantes par moyenne de la catégorie - V2](#groupby--remplacer-valeurs-manquantes-par-moyenne-de-la-catégorie---v2)\n",
    "1. [Supprimer une colonne](#supprimer-une-colonne)\n",
    "1. [Supprimer des colonnes en fonction d'un motif dans le titre](#supprimer-des-colonnes-en-fonction-dun-motif-dans-le-titre)\n",
    "1. [Merger 2 fichiers csv ou dataframe](#merger-2-fichiers-csv-ou-dataframe)\n",
    "1. [Sauver une Dataframe](#sauver-un-dataframe)\n",
    "1. [Merge avancé de 2 DataFrames](#merge-avancé-de-2-dataframes)\n",
    "1. [Classe pour valider les saisies](#classe-pour-valider-les-saisies)\n",
    "1. [Ajouter une ligne à un DataFrame - concat](#ajouter-une-ligne-à-un-DataFrame---concat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplacer les valeurs absentes par 42 - fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'A': [1, None, 3], \n",
    "  'B': [4, 5, 6]\n",
    "})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "df['A'].fillna(42, inplace=True)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplacer les valeurs absentes par la médiane - fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'A': [1, None, 4], \n",
    "  'B': [4, 5, 6]\n",
    "})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "median = df[\"A\"].median()  \n",
    "df[\"A\"].fillna(median, inplace=True)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "# df['A'].fillna(df['A'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplacer les valeurs absentes par 42 - SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'A': [1, None, 3], \n",
    "  'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "Zoubida = SimpleImputer(strategy=\"constant\", fill_value=42)\n",
    "Marcel_ndarray = Zoubida.fit_transform(df)\n",
    "# ! fit_transform() retroune un ndarray et PAS un DataFrame\n",
    "print(\"Table après : \\n\", Marcel_ndarray, \"\\n\")\n",
    "\n",
    "# On recréé un dataframe\n",
    "df = pd.DataFrame(Marcel_ndarray, columns=df.columns, index=df.index)\n",
    "print(\"Dataframe   : \\n\", df, \"\\n\")\n",
    "\n",
    "# on a accès à Zoubida.statistics_, Zoubida.strategy...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplacer une valeur par une autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 42, 3], 'B': [4, 5, 42]})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "df['A'].replace([42], '24', inplace=True)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N'afficher que les lignes où le PIB est vide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'Pays': [\"FR\", \"UK\", \"US\"], \n",
    "  'PIB': [44, None, 0]\n",
    "})\n",
    "print(\"Table : \\n\", df.head(), \"\\n\")\n",
    "print(df.loc[df['PIB'].isnull()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supprimer les lignes où le PIB est vaut 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'Pays': [\"FR\", \"UK\", \"US\", \"IT\", \"SP\", \"POR\"], \n",
    "  'PIB': [44, None, 42, 28, 42, 31]\n",
    "})\n",
    "\n",
    "# Affiche le DataFrame initial\n",
    "print(\"DataFrame initial :\")\n",
    "print(df)\n",
    "\n",
    "# Supprimer les lignes où le contenu de la colonne 2 est égal à 42\n",
    "df = df[df['PIB'] != 42]\n",
    "\n",
    "# Affiche le DataFrame après la suppression\n",
    "print(\"\\nDataFrame après suppression :\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afficher les lignes d'une même catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "  'Pays': [\"FR\", \"UK\", \"FR\"], \n",
    "  'Valeurs': [44, 58, 33]\n",
    "})\n",
    "print(df.loc[df['Pays'] == 'FR'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afficher les catégories où le % de valeurs manquantes est non nul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "  'Pays': [\"FR\", \"UK\", \"US\", \"FR\"], \n",
    "  'Feature-1': [10, 58, None, 20],\n",
    "  'Feature-2': [100, 580, 10, 2000],\n",
    "  'Feature-3': [10, 58, None, None],\n",
    "})\n",
    "\n",
    "print(\"Table : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "Bob = df.isna().sum() / len(df) * 100\n",
    "print(f\"Les '%' de valeurs manquantes dans les colonnes sont :\\n{Bob}\")\n",
    "\n",
    "print(f\"\\nIl y a des valeurs manquantes dans les colonnes suivantes : \\n{Bob.loc[Bob.ne(0)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer des colonnes avec le contenu d'une colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Colonne': ['Chaine1-Chaine2', 'A-B', 'X-Y']})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "df[['Colonne1', 'Colonne2']] = df['Colonne'].str.split('-', expand=True)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculer de nouvelles colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "df['Somme'] = df['A'] + df['B']\n",
    "df['Hypothénuse'] = np.sqrt(df['A']**2 + df['B']**2)\n",
    "\n",
    "taux = 0.5\n",
    "df[\"Prix-US\"]=df[\"A\"]*taux\n",
    "\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer une colonne qui contient des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'Id'        : [\"Riri\", \"Fifi\", \"Loulou\", \"Avasarala\", \"Holden\", \"Naomi\", \"Razorback\", \"Apollo\", \"Soyouz\"],\n",
    "  'Prix'      : [0, 25, 99, 80, 66, 13, 100, 56, 110] \n",
    "})\n",
    "print(\"Table avant :\\n\", df.head(10), \"\\n\")\n",
    "\n",
    "# Les bornes des intervalles\n",
    "# (0-25, 25-50, 50-75, 75-100) \n",
    "intervalles = [0, 25, 50, 75, 100]\n",
    "\n",
    "# Les étiquettes de chaque catégorie\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "\n",
    "# Utilise cut() pour créer la colonne 'Catégorie'\n",
    "# include_lowest=True => la 1ere catégorie inclura les valeurs égales à la borne inf de l'intervalle\n",
    "df['Catégorie'] = pd.cut(df['Prix'], bins=intervalles, labels=categories, include_lowest=True)\n",
    "\n",
    "print(\"Table après :\\n\", df.head(10), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference entre `apply()` et `transform()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `apply()`\n",
    "* `apply()` est plus générique que `transform()`\n",
    "* Utilisée pour appliquer une fonction sur des DataFrames entiers, des colonnes ou des lignes spécifiques\n",
    "* La fonction passée à `apply()` peut retourner un scalaire, une Serie ou un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'A': [1, 2, 3], \n",
    "  'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "def moyenne(row):\n",
    "  return (row['A']+ row['B'])/2\n",
    "\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "df[\"sqrt(A)\"] = df['A'].apply(lambda x: x **.5)     # fonction lambda\n",
    "df[\"Moyenne\"] = df.apply(moyenne, axis=1)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "result = df['A'].apply(lambda x: x **2)                 \n",
    "print(\"Serie A après\\n\", result, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `transform()`\n",
    "* **`transform()`** est spécifiquement conçue pour effectuer des opérations sur des groupes de données.\n",
    "* La fonction de transformation doit renvoyer une série de la même longueur que l'entrée, et elle est appliquée à chaque groupe de données.\n",
    "* Utile pour effectuer des opérations de groupe (par exemple, remplacer les valeurs manquantes par la moyenne du groupe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'Groupe': ['A', 'A', 'B', 'B', 'A', 'B'], \n",
    "  'Valeur': [None, 2, None, 4, 5, None]\n",
    "})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "# Rempli les valeurs manquantes avec la moyenne du groupe\n",
    "moyennes_par_groupe = df.groupby('Groupe')['Valeur'].transform('mean')\n",
    "df['Valeur'] = df['Valeur'].fillna(moyennes_par_groupe)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraire les nombres d'une chaîne et créer une colonne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re                                    # regular expression\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'Id'       : [\"Riri\", \"Fifi\", \"Loulou\"],\n",
    "  'Feature-0': [\"Val1\", \"Val2\", \"Val3\"], \n",
    "  'Feature-1': [\"Marcel11\", \"Robert2\", \"Antoine3\"],\n",
    "  'Feature-2': [\"NE-555\", \"20-USA-48\", \"Russia\"],\n",
    "})\n",
    "\n",
    "def get_digit(mystr):\n",
    "  chiffres = re.findall(r'\\d+', str(mystr))  # Trouver tous les chiffres\n",
    "  try:\n",
    "    return int(''.join(chiffres))\n",
    "  except:\n",
    "    return 0                                 # on peut aussi retourner np.nan\n",
    "\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "df['Feature-3'] = df['Feature-2'].apply(get_digit)         # voir le apply()\n",
    "df['Feature-1'] = df['Feature-1'].apply(get_digit)\n",
    "# df['Feature-0'] = df['Feature-0'].apply(keep_numbers)\n",
    "\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraire les valeurs d'une chaine, remplir une colone avec leur moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def moy(x):\n",
    "  try : \n",
    "    return np.mean([float(i) for i in x.split(\"~\")])\n",
    "  except: \n",
    "    return np.nan     # on peut aussi retrouner une valeur : 42...\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'Id'       : [\"Riri\", \"Fifi\", \"Loulou\"],\n",
    "  'Feature-0': [\"11~13\", \"10~20~30\", \"50~100\"], \n",
    "  'Feature-1': [\"18~20\", \"10~20\", \"50**100\"],\n",
    "})\n",
    "print(\"Avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "df['Feature-0'] = df['Feature-0'].apply(moy)          # voir le apply()\n",
    "df['Moy Feature-1'] = df['Feature-1'].apply(moy)\n",
    "\n",
    "print(\"Après : \\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform (s'applique à un groupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Groupe': ['A', 'A', 'B', 'B', 'A', 'B'],\n",
    "        'Valeur': [None, 15, None, 25, 30, None]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Avant : \\n\", df.head(), \"\\n\")\n",
    "\n",
    "# Calculer la moyenne par groupe\n",
    "moyennes_par_groupe = df.groupby('Groupe')['Valeur'].transform('mean')         # voir le transform sur le groupe\n",
    "print(\"Moyennes :\\n\", moyennes_par_groupe, \"\\n\")\n",
    "\n",
    "# Remplacer les valeurs manquantes par la moyenne correspondante\n",
    "df['Valeur'] = df['Valeur'].fillna(moyennes_par_groupe)\n",
    "\n",
    "# Afficher le DataFrame après transformation\n",
    "print(\"Après : \\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupby : remplacer valeurs manquantes par moyenne de la catégorie\n",
    "\n",
    "* Marche pas dans tous les cas\n",
    "* Il faut que chaque catégorie ait une moyenne à calculer\n",
    "* Si une catégorie n'a aucune moyenne à calculer rien n'est fait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  'Pays': ['A', 'A', 'B', 'B', 'A', 'B'],\n",
    "  'PIB': [None, None, 10, 25, None, 45]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Avant : \\n\", df.head(), \"\\n\")\n",
    "moyennes_par_pays = df.groupby('Pays')['PIB'].mean()\n",
    "df['PIB'] = df.apply(lambda row: moyennes_par_pays[row['Pays']] if pd.isna(row['PIB']) else row['PIB'], axis=1)\n",
    "print(\"Après : \\n\", df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupby : remplacer valeurs manquantes par moyenne de la catégorie - V2\n",
    "\n",
    "* Met 0 si la moyenne n'a pas pu être calculée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  'Pays': ['A', 'A', 'B', 'B', 'A', 'B'],\n",
    "  'PIB': [None, None, 10, 25, None, 45]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Avant : \\n\", df.head(), \"\\n\")\n",
    "moyennes_par_pays = df.groupby('Pays')['PIB'].mean()\n",
    "moyennes_par_pays.fillna(0.0, inplace=True)\n",
    "df['PIB'] = df.apply(lambda row: moyennes_par_pays[row['Pays']] if pd.isna(row['PIB']) else row['PIB'], axis=1)\n",
    "print(\"Après : \\n\", df.head(), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supprimer une colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "  'Id'      : [\"Riri\", \"Fifi\", \"Loulou\"],\n",
    "  'Feature0': [1, 2, 3], \n",
    "  'Feature1': [10, 20, 30], \n",
    "  'Feature2': [100, 200, 300], \n",
    "})\n",
    "print(\"Table avant : \\n\", df.head(), \"\\n\")\n",
    "df.drop(\"Feature1\", inplace=True, axis=1)\n",
    "print(\"Table après : \\n\", df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supprimer des colonnes en fonction d'un motif dans le titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "  'Id'      : [\"Riri\", \"Fifi\", \"Loulou\"],\n",
    "  'Feature0': [1, 2, 3], \n",
    "  'Feature1': [4, 5, 6],\n",
    "  'Feature2': [7, 8, 9],\n",
    "  'Feature3': [1, 2, 3],\n",
    "  'Feature4': [4, 5, 6],\n",
    "  'Feature5': [7, 8, 9],\n",
    "  'Feature6': [1, 2, 3]\n",
    "})\n",
    "print(\"Table avant : \\n\", df.head(1), \"\\n\")\n",
    "columns_to_drop=[f'Feature{i}' for i in range (2,5)]\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "print(\"Table après : \\n\", df.head(1), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merger 2 fichiers csv ou dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les deux fichiers CSV\n",
    "# df1 = pd.read_csv('fichier1.csv', delimiter=\";\")\n",
    "# df2 = pd.read_csv('fichier2.csv', delimiter=\";\")\n",
    "df1 = pd.DataFrame({\n",
    "  'Id' : [101, 1001, 200, 2000, 300],\n",
    "  'Valeur1' : ['a', 'b', 'c', 'd', 'e'],\n",
    "  'Valeur2' : ['aa', 'bb', 'cc', 'dd', 'ee']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "  'Id' : [101, 102, 200, 201, 300, 500],\n",
    "  'Valeur1' : [1,2,3,4,5,10],\n",
    "  'Valeur2' : [11,12,13,14,15,100]\n",
    "})\n",
    "\n",
    "# Effectue le merge sur la colonne 'Id'\n",
    "resultat_merge = pd.merge(df1, df2, on='Id')\n",
    "\n",
    "# Afficher le résultat\n",
    "print(resultat_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauver un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mon-fichier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge avancé de 2 Dataframes\n",
    "[top](#table-des-matières)\n",
    "* La seconde table contient des Types dont on veut calculer la moyennes des features\n",
    "* Voir le contenu de la Table 3\n",
    "* Une des features de la Table 1 est le type\n",
    "* On veut étendre la Table 1, avec pour chaque ligne, en fonction du type, les moyennes calculées avec la Table 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "  'Id'        : [\"Riri\", \"Fifi\", \"Loulou\", \"Avasarala\", \"Holden\", \"Naomi\", \"Razorback\", \"Apollo\", \"Soyouz\"],\n",
    "  'Type'      : [\"Type1\", \"Type2\", \"Type3\", \"Type1\", \"Type2\", \"Type3\", \"Type1\", \"Type2\", \"Type3\"], \n",
    "  'Feature-1' : [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "  'Value'     : [10, 20, 30, 11, 21, 31, 12, 22, 32],\n",
    "})\n",
    "print(\"Table 2 :\\n\", df2.head(10), \"\\n\")\n",
    "\n",
    "# df3 = df2.groupby('Type')[\"Value\"].transform(\"mean\")\n",
    "# df3 = df2.groupby('Type')[\"Value\"].mean()\n",
    "# print(\"Table 3 : Depuis Table 2, les moyennes de Value par Type\\n\", df3, \"\\n\")\n",
    "\n",
    "df3 = df2.groupby('Type')[[\"Feature-1\", \"Value\"]].mean()\n",
    "print(\"Table 3 : Depuis Table 2, les moyennes de Value et Feature-1 par Type\\n\", df3, \"\\n\")\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "  'Id'        : [\"Riri\", \"Avasarala\", \"Apollo\", \"Soyouz\"],\n",
    "  'Colonne-00': [\"BB\", \"SF\", \"Space\", \"Space\"], \n",
    "  'Colonne-01': [3.14, 42, 2.718, 1.618],\n",
    "  'Colonne-02': [\"Type1\", \"Type2\", \"Type2\", \"Type1\"],\n",
    "})\n",
    "print(\"Table 1 :\\n\", df1.head(), \"\\n\")\n",
    "\n",
    "# Voir que dans le join les colonnes n'ont pas le même nom\n",
    "df4 = pd.merge(df1, df3, left_on='Colonne-02', right_on='Type', how='inner' )\n",
    "# df4 = pd.merge(df1, df2.groupby('Type')[[\"Feature-1\",\"Value\"]].mean(),left_on='Colonne-02', right_on='Type', how='inner' )\n",
    "print(\"Merge de Table 1 et Table 3 sur le Type :\\n\", df4.head(10), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe pour valider les saisies\n",
    "[top](#table-des-matières)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInput:\n",
    "  \"\"\" A simple class to validate user input  \"\"\"\n",
    "  def __init__(self, datatype, prompt=\"\"):\n",
    "    while True:\n",
    "      try:\n",
    "        if(prompt!=\"\"):\n",
    "          self.value = datatype(input(prompt + \" :\"))\n",
    "        else:\n",
    "          self.value = datatype(input())\n",
    "        break\n",
    "      except ValueError:\n",
    "        print(\"Le montant devrait être un nombre\")\n",
    "        # self.value = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "deposit = UserInput(float, \"Montant initial\").value\n",
    "print (deposit)\n",
    "\n",
    "deposit = UserInput(float).value\n",
    "print (deposit)\n",
    "\n",
    "deposit = UserInput(int, \"Saisir un entier\").value\n",
    "print (deposit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajouter une ligne à un DataFrame - concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add new row at the end of the DataFrame\n",
    "df = pd.DataFrame({\"first_name\":[\"Lucien\", \"Jocelyne\", \"Brigitte\"], \"age\":[29, 43, 32]})\n",
    "new_row = pd.DataFrame ({\n",
    "  'first_name': ['Joséphine'],\n",
    "  'age': [43],\n",
    "})\n",
    "\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# À TERMINER et à CLASSER\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion d'un ndarray en dataframe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "dataframe = pd.DataFrame(data_array, columns=['Colonne1', 'Colonne2', 'Colonne3'])\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean indexing, masque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "mask = arr > 3\n",
    "result = arr[mask]\n",
    "print(result)  # Résultat : [4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Nom': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Âge': [25, 30, 35, 40]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "mask = df['Âge'] > 30\n",
    "result = df[mask]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation croisée\n",
    "* La validation croisée permet d'évaluer les performances d'un modèle en le testant sur différents sous-ensembles des données d'entraînement.\n",
    "* Habituellement, la validation croisée divise les données en plusieurs plis (folds), puis le modèle est entraîné sur plusieurs combinaisons d'ensembles d'entraînement et de validation.\n",
    "* Permet d'estimer la performance du modèle de manière plus robuste, car il est testé sur différentes parties des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement des données (exemple avec un dataset fictif)\n",
    "data = pd.read_csv(\"votre_dataset.csv\")\n",
    "X = data.drop(\"target_variable\", axis=1)\n",
    "y = data[\"target_variable\"]\n",
    "\n",
    "# Définition du modèle (exemple : régression logistique)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Définition de la validation croisée (ici, 5 plis)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluation du modèle avec la validation croisée\n",
    "cross_val_accuracy = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Précision moyenne avec validation croisée : {:.2f}%\".format(cross_val_accuracy.mean() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régulation\n",
    "\n",
    "* Prévient le surapprentissage en ajoutant une pénalité aux paramètres du modèle. \n",
    "* L'idée est d'éviter que le modèle s'ajuste trop précisément aux données d'entraînement et ne généralise mal sur de nouvelles données.\n",
    "* Deux types courants de régularisation  \n",
    "  * L2 (ridge) distance euclidienne\n",
    "  * L1 (lasso) distance de Manhattan  \n",
    "* En ajoutant ces termes de régularisation à la fonction de coût, le modèle est incité à maintenir les coefficients à des valeurs plus modestes, ce qui réduit le risque de surapprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement des données (exemple avec un dataset fictif)\n",
    "data = pd.read_csv(\"votre_dataset.csv\")\n",
    "X = data.drop(\"target_variable\", axis=1)\n",
    "y = data[\"target_variable\"]\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définition du modèle de régression logistique avec régularisation L2\n",
    "model = LogisticRegression(penalty='l2', C=1.0)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcul de la précision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Précision du modèle : {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Box plot for outlier detection\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='numerical_column', data=data)\n",
    "plt.title('Box Plot of Numerical Column')\n",
    "plt.show()\n",
    "\n",
    "# Address outliers (e.g., through winsorization)\n",
    "data['numerical_column'] = data['numerical_column'].clip(lower=data['numerical_column'].quantile(0.05), upper=data['numerical_column'].quantile(0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage avec loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict = {\n",
    "  \"Year\" : [2012, 1964, 1965, 2011, 2012],\n",
    "  \"Noms\"  : [\"riri\", \"fifi\", \"loulou\", \"falken\", \"bob\"]\n",
    "}\n",
    "df = pd.DataFrame(dict)\n",
    "df_2012 = df.loc[df['Year'] == 2012] # on crée un df_2012 qui est le résultat d'un filtre\n",
    "display(df_2012)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (646890108.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    y=liste_valeurs\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "fig = px.line(\n",
    "  x=range(2,10), \n",
    "  y=liste_valeurs,\n",
    "  width=800, \n",
    "  height=400\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"Inertia\",\n",
    "    xaxis_title=\"# Clusters\",\n",
    "    title=\"Inertia per cluster\"\n",
    ")\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "  x=range(2, 11), \n",
    "  y=liste_valeurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dataset, x = 'Annual_Income', y = \"Spending\", color = \"Groupe\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(dataset, x = 'Annual_Income', y = \"Spending\", z = 'Age', color = \"Groupe\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = load_sample_image(\"china.jpg\")\n",
    "fig = px.imshow(china)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "        df,\n",
    "        lat=\"lat\",\n",
    "        lon=\"lng\",\n",
    "        color=\"title\",\n",
    "        mapbox_style='open-street-map'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Répertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(\"Chemin de VSCode           : \", Path.cwd())\n",
    "\n",
    "p = Path(__file__).parent\n",
    "print(\"Chemin contenant le script : \", p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
