{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4N9XyPIoWHV"
      },
      "source": [
        "# <span style=\"color:orange\"><b>Run on PC</b></span>\n",
        "# Code Attention\n",
        "\n",
        "Show how to code an encoder decoder model with attention mechanism.\n",
        "Use generated data (the same generated data we used to demonstrate the encoder decoder project) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CqUIHNG_w-j"
      },
      "source": [
        "## Prelude\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PyeOCpH_yRRe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import os\n",
        "import time\n",
        "\n",
        "from random import randint\n",
        "from numpy import array\n",
        "\n",
        "\n",
        "k_Vocab_Size_In   = 100\n",
        "k_In_Seq_Length   = 10\n",
        "k_Out_Seq_Length  = 5\n",
        "k_Batch_Size      = 128\n",
        "\n",
        "k_N_Word_Embed    = 32 # number of units needed for the embedding layers\n",
        "k_N_GRU           = 32 # number of units needed for the GRU \n",
        "k_N_W1_W2         =  8 # number of neurons in W1 and W2\n",
        "\n",
        "k_Train_Samples   = 10_000 \n",
        "k_Val_Samples     =  5_000 \n",
        "\n",
        "k_Epochs          = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZhjrVO_6aw"
      },
      "source": [
        "## Generate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0HQ-jiYSAD0D"
      },
      "outputs": [],
      "source": [
        "# generate a sequence of n random integers from 2 to val_max-1 included\n",
        "# TODO : pourquoi (2, val_max-1) et pas (1, val_max)\n",
        "# Qu'est ce qui empêche d'avoir 1 et val_max ?\n",
        "        \n",
        "def generate_sequence(n, val_max):\n",
        "\treturn [randint(2, val_max-1) for _ in range(n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-N8q1gaBCsy",
        "outputId": "23017cd8-c562-4418-cfed-7357c15e4e16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[32, 38, 3, 25, 91, 51, 72, 8, 87, 21]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_sequence(k_In_Seq_Length, k_Vocab_Size_In)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "01pWZiHjAJFV"
      },
      "outputs": [],
      "source": [
        "# The data we are generating consists in a random sequence of numbers \n",
        "# they could represent encoded letters, words, sentences or anything you could think of.\n",
        "# The target is built using the first elements of the input in reversed order. \n",
        "# We add a special token at the beginning of every target sequence for teacher.\n",
        "# Since words are represented by number and since the translated sentence use the same number k_Vocab_Size_In and k_Vocab_Size_Out are the same  \n",
        "\n",
        "def create_Input_and_Target(n_in, n_out, voc_size, how_many, printing = False):\n",
        "  \n",
        "  X = list()\n",
        "  y  = list()\n",
        "  \n",
        "  for _ in range(how_many):\n",
        "    # generate source sequence\n",
        "    source = generate_sequence(n_in, voc_size)\n",
        "    source_pad = source\n",
        "    if printing:\n",
        "      print(\"source : \", source_pad)\n",
        "    \n",
        "    # add <start> token (0) at the beginning of each sequence\n",
        "    target = source[:n_out]\n",
        "    target.reverse()\n",
        "    target = [0] + target\n",
        "    if printing:\n",
        "      print(\"target : \", target)\n",
        "\n",
        "    X.append(source_pad)\n",
        "    y.append(target)\n",
        "  \n",
        "  return array(X), array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWkizklpBJpz",
        "outputId": "01993fa9-8560-4df0-d688-b2707b2dacae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source :  [48, 55, 66, 89, 35, 61, 44, 23, 66, 19]\n",
            "target :  [0, 35, 89, 66, 55, 48]\n",
            "source :  [9, 96, 31, 62, 83, 95, 71, 78, 17, 15]\n",
            "target :  [0, 83, 62, 31, 96, 9]\n"
          ]
        }
      ],
      "source": [
        "# Testing purpose\n",
        "# Generate 2 source and 2 target\n",
        "# Sources are \"strings\" of length k_In_Seq_Length words\n",
        "# Targets are \"strings\" of length k_Out_Seq_Length words\n",
        "input, target =  create_Input_and_Target(k_In_Seq_Length, k_Out_Seq_Length, k_Vocab_Size_In, 2, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VeOFZcCeFFGj"
      },
      "outputs": [],
      "source": [
        "# Create the training data and validation dataset\n",
        "\n",
        "X_train, y_train = create_Input_and_Target(k_In_Seq_Length, k_Out_Seq_Length, k_Vocab_Size_In, how_many = k_Train_Samples)\n",
        "X_val,   y_val   = create_Input_and_Target(k_In_Seq_Length, k_Out_Seq_Length, k_Vocab_Size_In, how_many = k_Val_Samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FSkcX2CUQoHb"
      },
      "outputs": [],
      "source": [
        "# Transform the train sets into batches \n",
        "train_batch   = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(k_Batch_Size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VdBoFXRzYrn"
      },
      "source": [
        "## Create the encoder decoder with attention\n",
        "\n",
        "![bahdanau](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/attention/Attention-encoder-decoder.drawio.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPzJHFiSFaeo"
      },
      "source": [
        "### Create encoder model\n",
        "\n",
        "* The goal of the encoder is to create a representation of the input data\n",
        "* This repreentation extract information from the input data which will then be interpreted by the decoder model\n",
        "* The encoder receives sequence inputs \n",
        "* It will output sequences with a given depth of representation (we called that dimension channels before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kquiEvuTHfYw"
      },
      "outputs": [],
      "source": [
        "# Hier on faisait \n",
        "# encoder = tf.keras.Model(inputs = encoder_input, outputs = encoder_output)\n",
        "# plot_model(encoder)\n",
        "# Là on peut plus\n",
        "\n",
        "class encoder_factory(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, in_vocab_size, embed_dim, n_units):\n",
        "    super().__init__()\n",
        "    self.n_units = n_units\n",
        "    # WE layer\n",
        "    self.embed = tf.keras.layers.Embedding(input_dim = in_vocab_size, output_dim = embed_dim)\n",
        "    # GRU layer\n",
        "    self.gru = tf.keras.layers.GRU(units = n_units, return_sequences = True, return_state = True)\n",
        "  \n",
        "  \n",
        "  def __call__(self, input_batch):\n",
        "    # each output is saved as a class attribute \n",
        "    # doing so we can access them to control the shapes throughout the demo\n",
        "    self.embed_out               = self.embed(input_batch)\n",
        "    self.gru_out, self.gru_state = self.gru(self.embed_out)    \n",
        "    return self.gru_out, self.gru_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mpIHpEbDxzHz"
      },
      "outputs": [],
      "source": [
        "# On fait un test \n",
        "encoder = encoder_factory(k_Vocab_Size_In, k_N_Word_Embed, k_N_GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[31 61 47 85 24 24 26  6  9 34]\n",
            "(10000, 10)\n",
            "tf.Tensor([[31 61 47 85 24 24 26  6  9 34]], shape=(1, 10), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# We already generated X_train (size k_Train_Samples)\n",
        "# Realise we can't pass X[train] to the ecoder which expect a tensor \n",
        "print(X_train[0])\n",
        "print(X_train.shape)\n",
        "print(tf.expand_dims(X_train[0],0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XkgQs5mXJmHO"
      },
      "outputs": [],
      "source": [
        "# On passe X après l'avoir transfromé en tenseur\n",
        "encoder_output, encoder_state = encoder(tf.expand_dims(X_train[0],0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Y4AA5U61cT",
        "outputId": "dd81a47b-64d1-434c-be72-eb2810c77748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10, 32), dtype=float32, numpy=\n",
              "array([[[ 0.0018117 , -0.01219099, -0.00447212,  0.01740521,\n",
              "          0.00206368,  0.00503232, -0.00234216,  0.00155127,\n",
              "          0.00764946, -0.00272848, -0.0032842 , -0.00414186,\n",
              "         -0.00387689,  0.00940679, -0.00597036, -0.00511418,\n",
              "          0.01037782,  0.00578577, -0.00524591,  0.00619613,\n",
              "         -0.00250725, -0.00741306, -0.02181177, -0.01128406,\n",
              "         -0.00030009,  0.00436511,  0.01109104, -0.00397885,\n",
              "         -0.00591367, -0.00156584, -0.00851023, -0.01285357],\n",
              "        [ 0.00086671, -0.00839399,  0.00393489,  0.00616573,\n",
              "          0.00420294,  0.01341602,  0.00573099,  0.01197856,\n",
              "          0.02816976,  0.01873257,  0.0022498 , -0.01051817,\n",
              "          0.00577455,  0.01576327,  0.0078271 , -0.01179696,\n",
              "          0.00314449,  0.02000825, -0.00499912,  0.00045766,\n",
              "          0.02114684, -0.01677737,  0.00156429,  0.00826093,\n",
              "         -0.0198865 ,  0.01031852, -0.01919936, -0.00163858,\n",
              "         -0.00792624,  0.00237086, -0.00382045,  0.00817855],\n",
              "        [ 0.00693197, -0.01297085,  0.0104532 ,  0.00776041,\n",
              "         -0.00427693,  0.0066466 ,  0.01404434,  0.01324821,\n",
              "          0.00382617,  0.01809704,  0.00423986,  0.00550113,\n",
              "          0.00162937,  0.01018455,  0.01492215, -0.0099756 ,\n",
              "         -0.01369109,  0.009105  ,  0.00291166, -0.00713633,\n",
              "          0.02050854,  0.0020565 , -0.01311293, -0.00962266,\n",
              "          0.01480413,  0.00703639, -0.00679524, -0.00180811,\n",
              "         -0.00649677, -0.0149438 , -0.00842174,  0.00966536],\n",
              "        [ 0.02718765, -0.00253524,  0.01009702, -0.00612335,\n",
              "         -0.00533675, -0.00070831,  0.01975967,  0.00019864,\n",
              "          0.01454827, -0.00650482, -0.00625377,  0.00258529,\n",
              "          0.00258622,  0.00309454,  0.00388403, -0.02463293,\n",
              "         -0.00676518, -0.00735984,  0.00862601,  0.00933487,\n",
              "          0.0337952 , -0.00953862, -0.00281774, -0.00491479,\n",
              "         -0.00575294,  0.00707641, -0.01011761, -0.01270576,\n",
              "         -0.01160561, -0.01139087, -0.00721272,  0.00616399],\n",
              "        [-0.00449598,  0.00550183,  0.00368491, -0.01604619,\n",
              "         -0.00962544,  0.00444857,  0.00570136,  0.00050591,\n",
              "          0.01492809,  0.00266448, -0.00323593,  0.00553371,\n",
              "          0.00834161, -0.01629715,  0.00714182, -0.00996892,\n",
              "          0.00777052, -0.00689426, -0.00947801, -0.00447862,\n",
              "          0.01676424, -0.00430375,  0.00700729,  0.00818871,\n",
              "         -0.00357841, -0.00140957, -0.01337775,  0.00613196,\n",
              "         -0.00071884,  0.00606555, -0.00157905,  0.00899019],\n",
              "        [-0.02010458,  0.00830416, -0.00184029, -0.02065724,\n",
              "         -0.01215862,  0.00829831,  0.00028137, -0.00020236,\n",
              "          0.01820766,  0.00614288, -0.00098918,  0.0065938 ,\n",
              "          0.01418846, -0.02589391,  0.00749847, -0.00153003,\n",
              "          0.01410517, -0.00751899, -0.01718809, -0.01120421,\n",
              "          0.00546049, -0.0023695 ,  0.01273097,  0.01437971,\n",
              "         -0.00646961, -0.00545188, -0.01714449,  0.01574281,\n",
              "          0.00700369,  0.01271683, -0.00144894,  0.01231023],\n",
              "        [-0.00253059,  0.00220346,  0.01549926, -0.01850783,\n",
              "         -0.01382446, -0.00220935,  0.00298499,  0.00156075,\n",
              "          0.00219636,  0.00695375, -0.00420811,  0.00156863,\n",
              "          0.01069388, -0.01032018,  0.01019682,  0.00310555,\n",
              "         -0.00234395,  0.01632107, -0.01806552,  0.00980726,\n",
              "         -0.00140341,  0.02284814,  0.0042279 ,  0.00251559,\n",
              "          0.00313404, -0.00131633, -0.01741553,  0.01254223,\n",
              "          0.00726904, -0.00012017, -0.00120978,  0.01603298],\n",
              "        [ 0.0080456 ,  0.00275732,  0.01632581, -0.01738789,\n",
              "          0.00101549, -0.00445126, -0.00962959,  0.00182114,\n",
              "         -0.00598168,  0.01015747, -0.00309535,  0.01257078,\n",
              "         -0.0135824 ,  0.00689797,  0.00430418, -0.01021111,\n",
              "         -0.0121608 , -0.00191548,  0.00394811,  0.00848101,\n",
              "         -0.00128053,  0.00868533, -0.00997238, -0.00149271,\n",
              "          0.01719032, -0.00710138, -0.01480843, -0.00012277,\n",
              "         -0.00732917, -0.01932466, -0.01651951,  0.00994688],\n",
              "        [-0.0077135 ,  0.01225952, -0.00969752,  0.02225909,\n",
              "          0.0044619 , -0.00595965, -0.00111176, -0.00216469,\n",
              "          0.00056667, -0.01140505, -0.00786753, -0.0081858 ,\n",
              "         -0.01537061, -0.0085629 ,  0.0150291 ,  0.01845724,\n",
              "         -0.0111117 ,  0.00133602, -0.00927373, -0.00919368,\n",
              "         -0.02550535, -0.00740283, -0.00487409,  0.0170752 ,\n",
              "          0.0092671 , -0.00987834, -0.01676971,  0.00048875,\n",
              "          0.00132746,  0.01472445,  0.00669738, -0.00254301],\n",
              "        [ 0.0166283 ,  0.01137532, -0.00853125,  0.00529761,\n",
              "          0.00379842,  0.01369195, -0.00229246, -0.00550406,\n",
              "          0.00634844, -0.00936119, -0.00909596, -0.02524787,\n",
              "          0.00035473, -0.00532388,  0.01445548,  0.00428359,\n",
              "          0.01009566,  0.00593811, -0.00879329, -0.00981067,\n",
              "         -0.02220128, -0.01617278, -0.00140102, -0.00135519,\n",
              "         -0.01227896,  0.02162432, -0.00843613, -0.01270058,\n",
              "         -0.00608672,  0.00822962, -0.01058873,  0.00363486]]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remember : k_n_seq = 10 & k_n_gru = 32\n",
        "# The first output as a shape of (1,10,32) which is normal because we applied the encoder to 1 input sequence of 10 elements \n",
        "# (we chose return_sequences = True for the gru layer) and 32 channels since we have 32 units on the gru layer.\n",
        "\n",
        "encoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrrjGUr263yS",
        "outputId": "9e5bf764-13ae-44a3-a3b1-cfccfd2f0437"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[ 0.0166283 ,  0.01137532, -0.00853125,  0.00529761,  0.00379842,\n",
              "         0.01369195, -0.00229246, -0.00550406,  0.00634844, -0.00936119,\n",
              "        -0.00909596, -0.02524787,  0.00035473, -0.00532388,  0.01445548,\n",
              "         0.00428359,  0.01009566,  0.00593811, -0.00879329, -0.00981067,\n",
              "        -0.02220128, -0.01617278, -0.00140102, -0.00135519, -0.01227896,\n",
              "         0.02162432, -0.00843613, -0.01270058, -0.00608672,  0.00822962,\n",
              "        -0.01058873,  0.00363486]], dtype=float32)>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The second output is the gru state which has shape (1,32) for one input sequence and 32 units on the gru layer.\n",
        "encoder_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9sEGN-Ly0Lb"
      },
      "source": [
        "### Create the Attention layer\n",
        "\n",
        "![bahdanau](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/attention/Attention-encoder-decoder.drawio.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Hb-bJzRXz49d"
      },
      "outputs": [],
      "source": [
        "class Bahdanau_attention_factory(tf.keras.layers.Layer):\n",
        "  def __init__(self, attention_units):\n",
        "    super().__init__()\n",
        "\n",
        "    # The attention layer contains three dense layers\n",
        "    self.W1 = tf.keras.layers.Dense(units=attention_units)\n",
        "    self.W2 = tf.keras.layers.Dense(units=attention_units)\n",
        "    self.V  = tf.keras.layers.Dense(units=1)                 # ! obligatoirement 1 seul neurone\n",
        "\n",
        "  def __call__(self, enc_out, state):\n",
        "    # enc_out represents the encoder output which will be used to create the attention weights and then used to create the context vector once we\n",
        "    # apply the attention weights \n",
        "    # the state will be a hidden state from a recurrent unit coming either from the encoder at first, and from the decoder as we make further predictions\n",
        "    self.W1_out = self.W1(enc_out)                                              # shape (1, 10, attention_units)\n",
        "\n",
        "    # we are going to sum the outputs from W1 and W2, though the shapes are incompatible\n",
        "    # the enc_out is (batch_size, 10, 32) -> W1 -> (batch_size,10,attention_units)\n",
        "    # the state is   (batch_size, 32)     -> W2 -> (batch_size, attention_units)\n",
        "    # thus we need to artificially add a dimension to the state along axis 1\n",
        "    self.state  = tf.expand_dims(state, axis = 1) \n",
        "    self.W2_out = self.W2(self.state)                                           # shape (batch_size, 1, attention_units)\n",
        "    self.sum        = self.W1_out + self.W2_out                                 # shape (batch_size, 10, attention_units)\n",
        "    \n",
        "    # tanh because we have positive and negatives values and we want to scale beetween -1 and 1                              \n",
        "    self.sum_scale  = tf.nn.tanh(self.sum)                                      # shape (batch_size, 10, attention_units)\n",
        "\n",
        "    self.score = self.V(self.sum_scale)                                         # shape (batch_size, 10, 1)\n",
        "    self.attention_weights = tf.nn.softmax(self.score, axis=1)                  # shape (batch_size, 10, 1)\n",
        "    self.weighted_enc_out = enc_out * self.attention_weights                    # shape (batch_size, 10, 32)\n",
        "    self.context_vector = tf.reduce_sum(self.weighted_enc_out, axis=1)          # shape (batch_size, 32)\n",
        "\n",
        "    return self.context_vector, self.attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U49YxP_s6v11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[ 2.7340678e-03,  5.4913631e-04,  3.5740056e-03, -1.9579534e-03,\n",
              "         -2.9608137e-03,  3.8503141e-03,  3.3869778e-03,  2.3422490e-03,\n",
              "          9.1212038e-03,  3.3197063e-03, -3.1294660e-03, -1.3630067e-03,\n",
              "          1.1034927e-03, -2.0108197e-03,  7.9029230e-03, -4.8542027e-03,\n",
              "         -6.2369509e-05,  3.4917251e-03, -5.6915828e-03, -7.2614109e-04,\n",
              "          4.6738074e-03, -3.0998839e-03, -2.8672973e-03,  2.1285904e-03,\n",
              "         -4.4008513e-04,  2.5750333e-03, -1.1274226e-02,  1.4739938e-04,\n",
              "         -3.1003163e-03, -3.8168224e-04, -5.2784132e-03,  5.9474581e-03]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 10, 1), dtype=float32, numpy=\n",
              " array([[[0.1004601 ],\n",
              "         [0.1019185 ],\n",
              "         [0.10097729],\n",
              "         [0.10205767],\n",
              "         [0.10023692],\n",
              "         [0.0992083 ],\n",
              "         [0.09869408],\n",
              "         [0.09910867],\n",
              "         [0.09838147],\n",
              "         [0.09895701]]], dtype=float32)>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_layer = Bahdanau_attention_factory(k_N_W1_W2)                         # k_N_W1_W2 neurones dans les couches denses W1 et W2\n",
        "attention_layer(encoder_output, encoder_state)                                  # on regarde ce qui se passe quand on lui passe \n",
        "\n",
        "# the first output is context vector\n",
        "# the second is weight attention vectore (32 de long because 32 in the GRU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Bd5XPCPrTJ"
      },
      "source": [
        "### Create decoder\n",
        "\n",
        "* The decoder use the encoder output and the previous target element to predict the next target element\n",
        "* Its output is a sequence with as many elements as the target \n",
        "* This is where the padded target comes in\n",
        "* It will serve as input and must have a number of channels equals to the number of possible values for target elements\n",
        "* \n",
        "* Two versions of the same model (with the same weights) have to be prepared\n",
        "    * One for training\n",
        "    * One for inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./decoder.png\"  />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zk0-USwT8k1o"
      },
      "outputs": [],
      "source": [
        "class decoder_factory(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, target_vocab_size, embed_dim, n_units):\n",
        "    super().__init__()\n",
        "    # The decoder contains \n",
        "    #     WE layer used with teacher forcing\n",
        "    #     GRU layer\n",
        "    #     Dense layer to make the predictions\n",
        "    #     Attention layer\n",
        "\n",
        "    # ! NOTE that the Embedding layer has an input size of target vocab size (10 000 wordds foar example)\n",
        "    # This is because in inference mode, at the end of the first iteration, pred(X) is connected to the word embedding layer\n",
        "    # pred(x) is a vector of size vocab_size whose most values are null exept the one which is the index of the translated word in the target vocabulary\n",
        "    self.embed = tf.keras.layers.Embedding(input_dim=target_vocab_size, output_dim=embed_dim)\n",
        "    \n",
        "    # ! return_state=True is important since we want to connect state to W2 at the next iteration \n",
        "    self.gru = tf.keras.layers.GRU(units=n_units, return_sequences=True, return_state=True)     \n",
        "    self.pred = tf.keras.layers.Dense(units = target_vocab_size, activation=\"softmax\")\n",
        "    self.attention = Bahdanau_attention_factory(attention_units=n_units)\n",
        "\n",
        "  def __call__(self, dec_in, enc_out, state):\n",
        "    # The Attention layer provides context_vector and  attention weights\n",
        "    self.context_vector, self.attention_weights = self.attention(enc_out,state)\n",
        "\n",
        "    # the decoder ingest one sequence element from the teacher forcing whose shape is (bacth_size, 1)\n",
        "    self.embed_out = self.embed(dec_in)                                                        # shape (batch_size,1,embed_dim)\n",
        "\n",
        "    # concatenate the embedding output and the context vector\n",
        "    # ! their shapes are incompatible\n",
        "    # embed out is of size      : (batch_size, 1, embed_dim)\n",
        "    # context vector is of size : (batch_size, n_units)                                         n_units is defined in the encoder\n",
        "    # => need to add one dimension along axis 1\n",
        "    self.context_vector_expanded = tf.expand_dims(self.context_vector, axis=1)                  # shape (batch_size, 1, n_units)\n",
        "    self.concat = tf.keras.layers.concatenate([self.embed_out, self.context_vector_expanded])   # shape (bacth_size, 1, embed_dim + n_units)\n",
        "    \n",
        "    self.gru_out, self.gru_state = self.gru(self.concat)                                        # shapes (batch_size, 1, n_units) and (batch_size, n_units)\n",
        "\n",
        "    self.gru_out_reshape = tf.reshape(self.gru_out, shape=(-1, self.gru_out.shape[2]))          # pourquoi un reshape ici ??? On est (1, 1, 32) on passe en (1, 32)\n",
        "                                                                                                # On met en (1,32) pour pouvoir le réutiliser ensuite dans la boucle\n",
        "                                                                                                # où on fait un concatenate avec context vector\n",
        "\n",
        "    self.pred_out = self.pred(self.gru_out_reshape)                                             # shape (batch_size, 1, tar_vocab_size)\n",
        "\n",
        "    return self.pred_out, self.gru_state, self.attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xPLQRrgfF49C"
      },
      "outputs": [],
      "source": [
        "# Testing : use the decoder using the encoder output, the encoder state and the first element of the teacher forcing\n",
        "# ! On force target vocab size à la même taille que le vocab size input \n",
        "decoder = decoder_factory(target_vocab_size=k_Vocab_Size_In, embed_dim=k_N_Word_Embed, n_units=k_N_GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aj54hhGHHHeJ"
      },
      "outputs": [],
      "source": [
        "# the teacher forcing is the first element of the target sequence \n",
        "# use expand_dims twice to feed the decoder with a tensor with right dims\n",
        "decoder_input = tf.expand_dims(tf.expand_dims(y_train[0][0], axis=0), axis=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XY5Sz4gJVbJ",
        "outputId": "d09e3052-087d-4928-e079-a9e171f18c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]])>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsQTURM5IynC",
        "outputId": "16d875ec-b18c-414d-e882-c38c05ea032f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              " array([[0.01000052, 0.00996335, 0.00990824, 0.01012561, 0.00995792,\n",
              "         0.00996186, 0.01009192, 0.00998276, 0.00996807, 0.00998539,\n",
              "         0.01001669, 0.00996236, 0.01003362, 0.00994417, 0.0099698 ,\n",
              "         0.01001042, 0.0100463 , 0.01002792, 0.01006363, 0.01009929,\n",
              "         0.00991508, 0.00996633, 0.01000384, 0.01000245, 0.01000163,\n",
              "         0.00998842, 0.00997958, 0.0100095 , 0.00993689, 0.00991234,\n",
              "         0.00994213, 0.00998204, 0.00993922, 0.00998854, 0.01003938,\n",
              "         0.01002309, 0.00999049, 0.01002568, 0.01005118, 0.00991194,\n",
              "         0.01006036, 0.00982559, 0.0098395 , 0.01000199, 0.01000774,\n",
              "         0.01001138, 0.01005291, 0.01006296, 0.01008629, 0.01007326,\n",
              "         0.01001926, 0.01003062, 0.0100176 , 0.00993883, 0.01002304,\n",
              "         0.0099733 , 0.01011093, 0.00997716, 0.01002331, 0.01004564,\n",
              "         0.01000636, 0.01005011, 0.01011498, 0.00998618, 0.00998816,\n",
              "         0.00994612, 0.00995747, 0.00995007, 0.01009317, 0.00991337,\n",
              "         0.00990723, 0.00999085, 0.01011489, 0.01002246, 0.01008744,\n",
              "         0.00992523, 0.01004205, 0.00996706, 0.01006035, 0.01005691,\n",
              "         0.00994553, 0.00997498, 0.00988323, 0.01003718, 0.01002855,\n",
              "         0.00994555, 0.00997109, 0.00989908, 0.01003055, 0.00995572,\n",
              "         0.00999093, 0.00999358, 0.01004328, 0.01003657, 0.0100542 ,\n",
              "         0.00999729, 0.00993356, 0.01005194, 0.0100799 , 0.01005559]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[-0.00426708,  0.01274476, -0.0096515 ,  0.00147294, -0.02181012,\n",
              "         -0.02010343, -0.0023173 ,  0.00906154,  0.00614297, -0.00861017,\n",
              "         -0.00972289,  0.01250843,  0.00122996,  0.00233764, -0.00360379,\n",
              "         -0.00264333, -0.00545225,  0.00604794, -0.00399296,  0.0092776 ,\n",
              "          0.01653193, -0.01058541, -0.00351163,  0.0073829 ,  0.007143  ,\n",
              "          0.00055102,  0.02591067, -0.00691134, -0.00306961,  0.01568064,\n",
              "         -0.00181091,  0.00598942]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 10, 1), dtype=float32, numpy=\n",
              " array([[[0.10173201],\n",
              "         [0.10342485],\n",
              "         [0.10313474],\n",
              "         [0.09964895],\n",
              "         [0.09818423],\n",
              "         [0.09771132],\n",
              "         [0.09918291],\n",
              "         [0.09838597],\n",
              "         [0.09962852],\n",
              "         [0.09896657]]], dtype=float32)>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The first tensor is pred(X) whose size is vocab_size\n",
        "# The second tensor is the hidden state of the decoder whowse size is n_units\n",
        "decoder(decoder_input, encoder_output, encoder_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBbC19IPxGju"
      },
      "source": [
        "## Training the encoder decoder model\n",
        "\n",
        "The encoder output is used for each prediction once weighted by the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8X6jktGKyIok"
      },
      "outputs": [],
      "source": [
        "optimizer     = tf.keras.optimizers.Adam()\n",
        "\n",
        "# SparseCategoricalCrossentropy because \n",
        "# CrossEntropy since it is multi categorieq\n",
        "# Sparce beacause the label are integers (not one hot encoded)\n",
        "# https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fb4UZsQMS8Lg"
      },
      "outputs": [],
      "source": [
        "\n",
        "checkpoint_dir    = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint        = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TFSjvz22KxsW"
      },
      "outputs": [],
      "source": [
        "def train_step(inp, targ):\n",
        "  loss = 0\n",
        "\n",
        "  # gradient tape to track the operations happening in the network in order to be able to compute the gradients later\n",
        "  with tf.GradientTape() as tape: \n",
        "     # the input sequence is fed to the encoder to produce the encoder output and the encoder state\n",
        "    enc_output, enc_state = encoder(inp)\n",
        "\n",
        "    # the initial state is the encoder state\n",
        "    dec_state = enc_state \n",
        "\n",
        "    # the first decoder input is the first sequence element of the target batch\n",
        "    # the <start> token for each sequence in the batch. \n",
        "    # This is the teacher forcing\n",
        "    dec_input = tf.expand_dims(targ[:,0], axis=1) \n",
        "\n",
        "    # we loop over the teacher forcing sequence to produce the predictions\n",
        "    # we loop from 1 to targ.shape[1] which is the target sequence length\n",
        "    \n",
        "    # t comme token\n",
        "    # targ c'est un batch de token (dim 32)\n",
        "    # Dans une boucle on regarde tous les indice 0, tous les indices 1...\n",
        "    # t = 2 on regarde en même temps \n",
        "    for t in range(1, targ.shape[1]):                                        # range 1... car on a dejà 0\n",
        "      # passing dec_input, dec_state and enc_output to the decoder\n",
        "      # in order to produce the prediction, the new state, and the attention weights which we will not need explicitely here\n",
        "      pred, dec_state, _ = decoder(dec_input, enc_output, dec_state)\n",
        "\n",
        "      # loss sur le token t du batch targ\n",
        "      # compare the prediction produced by teacher forcing with the next element of the target and increment the loss\n",
        "      loss += loss_function(targ[:, t], pred) \n",
        "\n",
        "      # The new decoder input becomes the next element of the target sequence which we just attempted to predict (teacher forcing)\n",
        "      # a l'itération t change. A la dernière iteration on utilise ...\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)                      \n",
        "\n",
        "  # On est en training\n",
        "  # On vient de faire une forward pass\n",
        "  # faut calculer la loss (qui a été incrémenté à chaque tour de boucle)\n",
        "  # rechercher la variable loss_function\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1])) # we divide the loss by the target\n",
        "  # sequence's length to get the average loss across the sequence\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # here\n",
        "  # we concatenate the lists of trainable variables for the encoder and the\n",
        "  # decoder\n",
        "\n",
        "  # compute the gradient based on the loss and the trainable variables\n",
        "  gradients = tape.gradient(loss, variables) \n",
        "\n",
        "  # then update the model's  parameters\n",
        "  optimizer.apply_gradients(zip(gradients, variables)) \n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_829K5bKQS6z",
        "outputId": "4854c9ea-5789-41fe-c40d-17666dafab32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.8376\n",
            "Epoch 1 Batch 10 Loss 3.8367\n",
            "Epoch 1 Batch 20 Loss 3.8363\n",
            "Epoch 1 Batch 30 Loss 3.8349\n",
            "Epoch 1 Batch 40 Loss 3.8319\n",
            "Epoch 1 Batch 50 Loss 3.8277\n",
            "Epoch 1 Batch 60 Loss 3.8216\n",
            "Epoch 1 Batch 70 Loss 3.8002\n",
            "Epoch 1 Loss 302.2227\n",
            "Time taken for 1 epoch 53.01007556915283 sec\n",
            "\n",
            " val loss : tf.Tensor(4.526805, shape=(), dtype=float32) \n",
            "\n",
            "Epoch 2 Batch 0 Loss 3.7559\n",
            "Epoch 2 Batch 10 Loss 3.7247\n",
            "Epoch 2 Batch 20 Loss 3.6976\n",
            "Epoch 2 Batch 30 Loss 3.6931\n",
            "Epoch 2 Batch 40 Loss 3.6976\n",
            "Epoch 2 Batch 50 Loss 3.6937\n",
            "Epoch 2 Batch 60 Loss 3.6729\n",
            "Epoch 2 Batch 70 Loss 3.6403\n",
            "Epoch 2 Loss 291.5589\n",
            "Time taken for 1 epoch 15.712606430053711 sec\n",
            "\n",
            " val loss : tf.Tensor(4.3574677, shape=(), dtype=float32) \n",
            "\n",
            "Epoch 3 Batch 0 Loss 3.6370\n",
            "Epoch 3 Batch 10 Loss 3.5671\n",
            "Epoch 3 Batch 20 Loss 3.6105\n",
            "Epoch 3 Batch 30 Loss 3.5436\n",
            "Epoch 3 Batch 40 Loss 3.5314\n",
            "Epoch 3 Batch 50 Loss 3.5303\n",
            "Epoch 3 Batch 60 Loss 3.4909\n",
            "Epoch 3 Batch 70 Loss 3.4481\n",
            "Epoch 3 Loss 279.2998\n",
            "Time taken for 1 epoch 14.83418083190918 sec\n",
            "\n",
            " val loss : tf.Tensor(4.1881633, shape=(), dtype=float32) \n",
            "\n",
            "Epoch 4 Batch 0 Loss 3.4333\n",
            "Epoch 4 Batch 10 Loss 3.3420\n",
            "Epoch 4 Batch 20 Loss 3.3510\n",
            "Epoch 4 Batch 30 Loss 3.2901\n",
            "Epoch 4 Batch 40 Loss 3.2150\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18964\\1922919803.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18964\\4010199348.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(inp, targ)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;31m# gradient tape to track the operations happening in the network in order to be able to compute the gradients later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m      \u001b[1;31m# the input sequence is fed to the encoder to produce the encoder output and the encoder state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# the initial state is the encoder state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdec_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18964\\3777620830.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, input_batch)\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# each output is saved as a class attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# doing so we can access them to control the shapes throughout the demo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_out\u001b[0m               \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         )\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# tensors, then add them to the inputs and temporarily modify the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    665\u001b[0m             )\n\u001b[0;32m    666\u001b[0m             \u001b[1;31m# This is a dummy tensor for testing purpose.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgru_lstm_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgru_lstm_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRUNTIME_UNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m             last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[0;32m    670\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m             )\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[0;32m    889\u001b[0m                     last_output, outputs, new_h, runtime = gpu_gru(\n\u001b[0;32m    890\u001b[0m                         \u001b[1;33m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                     )\n\u001b[0;32m    892\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                     last_output, outputs, new_h, runtime = standard_gru(\n\u001b[0m\u001b[0;32m    894\u001b[0m                         \u001b[1;33m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m                     )\n\u001b[0;32m    896\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;31m# previous and candidate state mixed by update gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_tm1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m     last_output, outputs, new_states = backend.rnn(\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[0;32m   5135\u001b[0m                     \u001b[0minitial_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_new_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5136\u001b[0m                 )\n\u001b[0;32m   5137\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             final_outputs = tf.compat.v1.while_loop(\n\u001b[0m\u001b[0;32m   5140\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m                 \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5142\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mwhile_loop_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2759\u001b[0m       loop_var_structure = nest.map_structure(type_spec.type_spec_from_value,\n\u001b[0;32m   2760\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2761\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2762\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2764\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m           \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m   5114\u001b[0m                     \u001b[0mTuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_ta_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5115\u001b[0m                 \"\"\"\n\u001b[0;32m   5116\u001b[0m                 \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5117\u001b[0m                 \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5118\u001b[1;33m                 output, new_states = step_function(\n\u001b[0m\u001b[0;32m   5119\u001b[0m                     \u001b[0mcurrent_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5120\u001b[0m                 )\n\u001b[0;32m   5121\u001b[0m                 \u001b[0mflat_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m         recurrent_z, recurrent_r, recurrent_h = tf.split(\n\u001b[0;32m    984\u001b[0m             \u001b[0mmatrix_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m         )\n\u001b[1;32m--> 986\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_z\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecurrent_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;31m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1408\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1409\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m         \u001b[1;31m# object that can implement the operator with knowledge of itself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;31m# and the tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1753\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    462\u001b[0m         _ctx, \"AddV2\", name, x, y)\n\u001b[0;32m    463\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       return add_v2_eager_fallback(\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for epoch in range(k_Epochs):\n",
        "  start = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_batch):\n",
        "    batch_loss = train_step(inp, targ)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 10 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "  \n",
        "  # saving (checkpoint) the model every epoch\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss))\n",
        "  print('Time taken for 1 epoch {} sec'.format(time.time() - start))\n",
        "\n",
        "  # classic encoder input\n",
        "  enc_input = X_val\n",
        "\n",
        "  # the first decoder input is the special token 0\n",
        "  dec_input = tf.zeros(shape=(len(X_val), 1))\n",
        "\n",
        "  \n",
        "  # compute once and for all the encoder output and the encoder h state and c state\n",
        "  enc_out, enc_state = encoder(enc_input)\n",
        "\n",
        "  # The encoder h state and c state will serve as initial states for the decoder\n",
        "  dec_state = enc_state\n",
        "\n",
        "  # we'll store the predictions in here\n",
        "  pred = []  \n",
        "\n",
        "  # we loop over the expected length of the target, but actually the loop can run\n",
        "  # for as many steps as we wish, which is the advantage of the encoder decoder\n",
        "  # architecture\n",
        "  \n",
        "  # Là on fait une inference sur le val set\n",
        "  # On pointe sur le start et après on boucle\n",
        "  for i in range(y_val.shape[1]-1):\n",
        "    dec_out, dec_state, attention_w = decoder(dec_input, enc_out, dec_state)\n",
        "    # the decoder state is updated and we get the first prediction probability vector\n",
        "    decoded_out = tf.expand_dims(tf.argmax(dec_out, axis=-1), axis=1)\n",
        "\n",
        "    # decode the softmax vector into and index and update the prediction list\n",
        "    pred.append(tf.expand_dims(dec_out, axis = 1)) \n",
        "\n",
        "    # the last pred is used as the new input\n",
        "    dec_input = decoded_out \n",
        "\n",
        "  pred = tf.concat(pred, axis=1).numpy()\n",
        "  print(\"\\n val loss :\", loss_function(y_val[:,1:], pred),\"\\n\") # on peut alors afficher la loss sur le val set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaF316p_02jy"
      },
      "source": [
        "Nice! The training is over, and it looks as though the model performs really well both on train and validation sets!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4C6vHoo1NqW"
      },
      "source": [
        "## Make predictions with the inference model\n",
        "\n",
        "To make predictions on the validation set, we cannot use teacher forcing, the model has to base itself on its own predictions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgymx0a41s-g",
        "outputId": "ad51b7b1-50d5-4986-e6e4-d97898cc5adb"
      },
      "outputs": [],
      "source": [
        "# le val set fait 5000\n",
        "# on fait pareil qu'avant en fait\n",
        "\n",
        "\n",
        "enc_input = X_val # 5000 seq en anglais\n",
        "#classic encoder input\n",
        "\n",
        "dec_input = tf.zeros(shape=(len(X_val),1))                 # 5000 token start\n",
        "# the first decoder input is the special token 0\n",
        "\n",
        "#initial_state = encoder.state_initializer(len(X_val))\n",
        "\n",
        "enc_out, enc_state = encoder(enc_input)#, initial_state)\n",
        "# we compute once and for all the encoder output and the encoder\n",
        "# h state and c state\n",
        "\n",
        "dec_state = enc_state\n",
        "# The encoder h state and c state will serve as initial states for the\n",
        "# decoder\n",
        "\n",
        "pred = []  # we'll store the predictions in here\n",
        "\n",
        "# we loop over the expected length of the target, but actually the loop can run\n",
        "# for as many steps as we wish, which is the advantage of the encoder decoder\n",
        "# architecture\n",
        "for i in range(y_val.shape[1]-1):\n",
        "  dec_out, dec_state, attention_w = decoder(dec_input, enc_out, dec_state)\n",
        "  # the decoder state is updated and we get the first prediction probability \n",
        "  # vector\n",
        "  decoded_out = tf.expand_dims(tf.argmax(dec_out, axis=-1), axis=1) # argmax pour trouver le mot prdit, on l'enregistre\n",
        "  # we decode the softmax vector into and index\n",
        "  pred.append(decoded_out) # update the prediction list\n",
        "  dec_input = decoded_out # the previous pred will be used as the new input\n",
        "\n",
        "pred = tf.concat(pred, axis=-1).numpy()\n",
        "for i in range(10):\n",
        "  print(\"pred:\", pred[i,:].tolist())\n",
        "  print(\"true:\", y_val[i,:].tolist()[1:])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN9kGOmC3E57"
      },
      "source": [
        "The results do not look so bad, almost perfect actually! This is a clear improvement from the encoder decoder! Attention must be really powerful!\n",
        "\n",
        "The fact that the model reuses the encoder output at each step with different weights is helping the model achieve better predictions in a shorter amount of time (understand epochs).\n",
        "\n",
        "I hope you found this demonstration useful! Now it is time for you to apply what you have learned to a real world automatic translation problem!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03-Code_Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
