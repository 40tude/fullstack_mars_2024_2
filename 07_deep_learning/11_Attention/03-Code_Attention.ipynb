{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4N9XyPIoWHV"
      },
      "source": [
        "# <span style=\"color:red\"><b>TOURNE SUR PC</b></span>\n",
        "# Code Attention\n",
        "\n",
        "The goal of this demo is to teach you how to code an encoder decoder model with attention mechanism!\n",
        "Since this is just a demo we will use generated data, the same generated data we used to demonstrate the encoder decoder. You'll be able to tackle the real problem during the exercise, the goal here is to focus on building the model and the training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CqUIHNG_w-j"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyeOCpH_yRRe"
      },
      "outputs": [],
      "source": [
        "# ################################################\n",
        "# On garde les mêmes data que dans l'exemple d'hier\n",
        "# vocabulaire de 100 mots\n",
        "# sequences de taille fixe\n",
        "#     10 en entrée\n",
        "#      5 en sortie\n",
        "# 10_000 exemples train\n",
        "#  5_000 exemple de validation\n",
        "\n",
        "\n",
        "import tensorflow as tf \n",
        "# import pathlib \n",
        "# import pandas as pd \n",
        "import os\n",
        "import io\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# import json\n",
        "from random import randint\n",
        "from numpy import array\n",
        "# from numpy import argmax\n",
        "# from numpy import array_equal\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Input\n",
        "# from tensorflow.keras.layers import LSTM\n",
        "# from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZhjrVO_6aw"
      },
      "source": [
        "## Generate data\n",
        "\n",
        "We will generate random input and target data for the purpose of the demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDwgQyLDHzbN"
      },
      "outputs": [],
      "source": [
        "k_voc_size_input    = 100\n",
        "k_in_seq_len     = 10\n",
        "k_out_seq_len    = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HQ-jiYSAD0D"
      },
      "outputs": [],
      "source": [
        "# generate a sequence of random integers from 2 to n_unique-1 included\n",
        "def generate_sequence(length, n_unique):\n",
        "\treturn [randint(2, n_unique-1) for _ in range(length)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-N8q1gaBCsy",
        "outputId": "23017cd8-c562-4418-cfed-7357c15e4e16"
      },
      "outputs": [],
      "source": [
        "generate_sequence(k_in_seq_len, k_voc_size_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01pWZiHjAJFV"
      },
      "outputs": [],
      "source": [
        "# prepare data\n",
        "def get_dataset(n_in, n_out, cardinality, n_samples, printing=False):\n",
        "  X1, y = list(), list()\n",
        "  for _ in range(n_samples):\n",
        "    # generate source sequence\n",
        "    source = generate_sequence(n_in, cardinality)\n",
        "    source_pad = source\n",
        "    if printing:\n",
        "      print(\"source:\", source_pad)\n",
        "    # define padded target sequence\n",
        "    # we add the <start> token at the beginning of each sequence\n",
        "    # here we'll simply consider that the start token will coded\n",
        "    # by the index 0\n",
        "    target = source[:n_out]\n",
        "    target.reverse()\n",
        "    target = [0] + target\n",
        "    if printing:\n",
        "      print(\"target:\", target)\n",
        "    # store\n",
        "    X1.append(source_pad)\n",
        "    y.append(target)\n",
        "  return array(X1), array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWkizklpBJpz",
        "outputId": "01993fa9-8560-4df0-d688-b2707b2dacae"
      },
      "outputs": [],
      "source": [
        "input, target =  get_dataset(k_in_seq_len, k_out_seq_len, k_voc_size_input, 1, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-6_AV5lD-6Y"
      },
      "source": [
        "The data we are generating consists in a random sequence of numbers (they could very well represent encoded letters, words, sentences or anything you could think of).\n",
        "\n",
        "The target is built using the first elements of the input in reversed order. We add a special token at the beginning of every target sequence for teacher.\n",
        "\n",
        "Now that we understand this, let's create the training data and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeOFZcCeFFGj"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = get_dataset(k_in_seq_len,k_out_seq_len,k_voc_size_input,10_000)\n",
        "X_val, y_val     = get_dataset(k_in_seq_len,k_out_seq_len,k_voc_size_input,5_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azNpl-pyQgwo"
      },
      "source": [
        "Let's transform these train sets into batch datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSkcX2CUQoHb"
      },
      "outputs": [],
      "source": [
        "k_Batch_Size  = 128\n",
        "train_batch = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(k_Batch_Size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VdBoFXRzYrn"
      },
      "source": [
        "## Create the encoder decoder with attention\n",
        "\n",
        "In what follows we will code a model that will reproduce the following architecture for an encoder decoder model with Bahdanau style attention\n",
        "\n",
        "![bahdanau](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/attention/Attention-encoder-decoder.drawio.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPzJHFiSFaeo"
      },
      "source": [
        "### Create encoder model\n",
        "\n",
        "In this step we will define the encoder model.\n",
        "\n",
        "The goal of the encoder is to create a representation of the input data, to extract information from the input data which will then be interpreted by the decoder model.\n",
        "\n",
        "The encoder receives sequence inputs and will output sequences with a given depth of representation (we  usually called that dimension channels before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D_EKSjfLxd4"
      },
      "outputs": [],
      "source": [
        "# let's start by defining the number of units needed for the embedding and\n",
        "# the lstm layers\n",
        "\n",
        "k_n_embed = 32\n",
        "k_n_gru   = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kquiEvuTHfYw"
      },
      "outputs": [],
      "source": [
        "class encoder_factory(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, in_vocab_size, embed_dim, n_units):\n",
        "    super().__init__()\n",
        "    # instanciate an embedding layer\n",
        "    self.n_units = n_units\n",
        "    self.embed = tf.keras.layers.Embedding(input_dim = in_vocab_size, output_dim = embed_dim)\n",
        "    # instantiate GRU layer\n",
        "    self.gru = tf.keras.layers.GRU(units = n_units, return_sequences = True, return_state = True)\n",
        "  \n",
        "  \n",
        "  def __call__(self, input_batch):\n",
        "    # each output will be saved as a class attribute so we can easily access\n",
        "    # them to control the shapes throughout the demo\n",
        "    self.embed_out = self.embed(input_batch)\n",
        "    self.gru_out, self.gru_state = self.gru(self.embed_out)    #, initial_state=initial_state)\n",
        "    return self.gru_out, self.gru_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxjlemPeKTt8"
      },
      "source": [
        "That's it, it does not need to be anymore complicated than this, note though that we did not preserve the sequential nature of the data, but we output the cell state, which will serve as input state for the decoder!\n",
        "\n",
        "Let's try it out on an input to see what comes out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpIHpEbDxzHz"
      },
      "outputs": [],
      "source": [
        "# On fait un test \n",
        "encoder = encoder_factory(k_voc_size_input, k_n_embed, k_n_gru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Voir que size = 10\n",
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkgQs5mXJmHO"
      },
      "outputs": [],
      "source": [
        "# On passe \n",
        "encoder_output, encoder_state = encoder(tf.expand_dims(X_train[0],0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Y4AA5U61cT",
        "outputId": "dd81a47b-64d1-434c-be72-eb2810c77748"
      },
      "outputs": [],
      "source": [
        "# n_seq = 10\n",
        "# n_gru = 32\n",
        "encoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrrjGUr263yS",
        "outputId": "9e5bf764-13ae-44a3-a3b1-cfccfd2f0437"
      },
      "outputs": [],
      "source": [
        "encoder_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhWJAuuGyXOL"
      },
      "source": [
        "The first output as a shape of (1,10,16) which is normal because we applied the encoder to 1 input sequence of 10 elements (we chose return_sequences = True for the gru layer) and 16 channels since we have 16 units on the gru layer.\n",
        "\n",
        "The second output is the gru state which has shape (1,16) for one input sequence and 16 units on the gru layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9sEGN-Ly0Lb"
      },
      "source": [
        "### Create the Attention layer\n",
        "\n",
        "Let's now create the attention layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb-bJzRXz49d"
      },
      "outputs": [],
      "source": [
        "class Bahdanau_attention_factory(tf.keras.layers.Layer):\n",
        "  def __init__(self, attention_units):\n",
        "    super().__init__()\n",
        "\n",
        "    # The attention layer contains three dense layers\n",
        "    self.W1 = tf.keras.layers.Dense(units=attention_units)\n",
        "    self.W2 = tf.keras.layers.Dense(units=attention_units)\n",
        "    self.V  = tf.keras.layers.Dense(units=1)                 # ! obligatoirement 1 seul neurone\n",
        "\n",
        "  def __call__(self, enc_out, state):\n",
        "    # the choice of name of the arguments here is not random, enc_out\n",
        "    # will represent the encoder output which will be used to create\n",
        "    # the attention weights and then used to create the context vector once we\n",
        "    # apply the attention weights\n",
        "    # the state will be a hidden state from a recurrent unit coming either\n",
        "    # from the encoder at first, and from the decoder as we make further \n",
        "    # predictions\n",
        "    self.W1_out = self.W1(enc_out) # shape (1, 10, attention_units)\n",
        "\n",
        "    # If you have taken a close look the model's schema you would have noticed\n",
        "    # that we are going to sum the outputs from W1 and W2, though the shapes\n",
        "    # are incompatible\n",
        "    # the enc_out is (batch_size,10,16) -> W1 -> (batch_size,10,attention_units)\n",
        "    # the state is (batch_size,16) -> W2 -> (batch_size,attention_units)\n",
        "    # thus we need to artificially add a dimension to the stata along axis 1\n",
        "    self.state  = tf.expand_dims(state, axis = 1) \n",
        "    self.W2_out = self.W2(self.state)                                           # shape (batch_size,1,attention_units)\n",
        "\n",
        "    self.sum        = self.W1_out + self.W2_out                                 # shape (batch_size,10,attention_units)\n",
        "    self.sum_scale  = tf.nn.tanh(self.sum)                                      # shape (batch_size,10,attention_units)\n",
        "\n",
        "    self.score = self.V(self.sum_scale)                                         # shape (batch_size,10,1)\n",
        "\n",
        "    self.attention_weights = tf.nn.softmax(self.score, axis=1)                  # shape (batch_size,10,1)\n",
        "\n",
        "    self.weighted_enc_out = enc_out * self.attention_weights                    # shape (batch_size,10,16)\n",
        "\n",
        "    self.context_vector = tf.reduce_sum(self.weighted_enc_out, axis=1)          # shape (batch_size,16)\n",
        "\n",
        "    return self.context_vector, self.attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U49YxP_s6v11"
      },
      "outputs": [],
      "source": [
        "attention_layer = Bahdanau_attention_factory(8)                                 # 8 neurones dans les couches denses W1 et W2\n",
        "attention_layer(encoder_output, encoder_state)                                  # on regarde ce qui se passe quand on lui passe \n",
        "\n",
        "# le 1er c'est le context vector\n",
        "# le second c'est vect de poids d'attention (32 de long car 32 dans le GRU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Bd5XPCPrTJ"
      },
      "source": [
        "### Create decoder\n",
        "\n",
        "The goal of the decoder is to use the encoder output and the previous target element to predict the next target element!\n",
        "Which means its output is a sequence with as many elements as the target (this is where the padded target comes in, it will serve as input) and must have a number of channels equals to the number of possible values for target elements.\n",
        "\n",
        "Here we can't use the standard Sequential framework to build the model because the initial state of the decoder as to be set as the encoder states.\n",
        "\n",
        "In addition to this, two versions of the same model (with the same weights) have to be prepared, one of them for training, and one of them for inference (prediction on new unknown data). We'll detail the reason for this in what follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<img src=\"./decoder.png\"  />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk0-USwT8k1o"
      },
      "outputs": [],
      "source": [
        "class decoder_factory(tf.keras.Model):\n",
        "  def __init__(self, tar_vocab_size, embed_dim, n_units):\n",
        "    super().__init__()\n",
        "    # The decoder contains an embedding layer to play with the teacher forcing\n",
        "    # input, which comes from the target data\n",
        "    # A gru layer\n",
        "    # A dense layer to make the predictions\n",
        "    # And an attention layer\n",
        "    self.embed = tf.keras.layers.Embedding(input_dim=tar_vocab_size, output_dim=embed_dim)\n",
        "    self.gru = tf.keras.layers.GRU(units=n_units, return_sequences=True, return_state=True)     # ! return_state=True est important \n",
        "    self.pred = tf.keras.layers.Dense(units = tar_vocab_size, activation=\"softmax\")\n",
        "    self.attention = Bahdanau_attention_factory(attention_units=n_units)\n",
        "\n",
        "  def __call__(self, dec_in, enc_out, state):\n",
        "    # first let's apply the attention layer\n",
        "    self.context_vector, self.attention_weights = self.attention(enc_out,state)\n",
        "\n",
        "    # now the decoder will ingest one sequence element from the teacher forcing\n",
        "    # this will be of shape (bacth_size, 1)\n",
        "    self.embed_out = self.embed(dec_in)                                                        # shape (batch_size,1,embed_dim)\n",
        "\n",
        "    # then we need to concatenate the embedding output and the context vector\n",
        "    # though their shapes are incompatible\n",
        "    # embed out (batch_size, 1, embed_dim)\n",
        "    # context vector (batch_size, n_units) where n_units was defined in the encoder\n",
        "    # so we need to add one dimension along axis 1\n",
        "    self.context_vector_expanded = tf.expand_dims(self.context_vector, axis=1)                  # shape (batch_size,1,n_units)\n",
        "    self.concat = tf.keras.layers.concatenate([self.embed_out, self.context_vector_expanded])   # shape (bacth_size,1, embed_dim + n_units)\n",
        "    \n",
        "    # now we get to apply the gru layer\n",
        "    self.gru_out, self.gru_state = self.gru(self.concat)                                        # shapes (batch_size, 1, n_units) and (batch_size, n_units)\n",
        "\n",
        "    # let's reshape the gru output before feeding it to the dense layer\n",
        "    self.gru_out_reshape = tf.reshape(self.gru_out, shape=(-1, self.gru_out.shape[2]))          # pourquoi un reshape ici ??? On est (1, 1, 32) on passe en (1, 32)\n",
        "                                                                                                # On met en (1,32) pour pouvoir le réutiliser ensuite dans la boucle\n",
        "                                                                                                # où on fait un concatenate avec context vector\n",
        "\n",
        "    # now let's make a prediction\n",
        "    self.pred_out = self.pred(self.gru_out_reshape)                                             # shape (batch_size, 1, tar_vocab_size)\n",
        "\n",
        "    return self.pred_out, self.gru_state, self.attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmKLDPIaFvT9"
      },
      "source": [
        "Let's now try and use the decoder using the encoder output, the encoder state and the first element of the teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPLQRrgfF49C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ! On force output vocab size à la même taile que le vocab size input \n",
        "decoder = decoder_factory(tar_vocab_size=k_voc_size_input, embed_dim=k_n_embed, n_units=k_n_gru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj54hhGHHHeJ"
      },
      "outputs": [],
      "source": [
        "decoder_input = tf.expand_dims(tf.expand_dims(y_train[0][0], axis=0), axis=0) # the teacher forcing is\n",
        "# the first element of the target sequence which corresponds to the <start> token\n",
        "# we use expand dim to artificially add the batch size dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XY5Sz4gJVbJ",
        "outputId": "d09e3052-087d-4928-e079-a9e171f18c9f"
      },
      "outputs": [],
      "source": [
        "decoder_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsQTURM5IynC",
        "outputId": "16d875ec-b18c-414d-e882-c38c05ea032f"
      },
      "outputs": [],
      "source": [
        "decoder(decoder_input,encoder_output, encoder_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl3Rm6GPJzwu"
      },
      "source": [
        "Everything worked well, now all there is to do is to apply the decoder again to the second element of the teacher forcing and replacing the encoder state with the decoder state to produce the subsequent predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBbC19IPxGju"
      },
      "source": [
        "## Training the encoder decoder model\n",
        "\n",
        "We are almost there, but contrary to the classic encoder decoder architecture, using attention forces us to manually code the training steps because the encoder output is used for each prediction once weighted by the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X6jktGKyIok"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb4UZsQMS8Lg"
      },
      "outputs": [],
      "source": [
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFSjvz22KxsW"
      },
      "outputs": [],
      "source": [
        "def train_step(inp, targ):#, enc_initial_state):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape: # we use the gradient tape to track all\n",
        "  # the different operations happening in the network in order to be able\n",
        "  # to compute the gradients later\n",
        "\n",
        "    enc_output, enc_state = encoder(inp)#,enc_initial_state) # the input sequence is fed to the \n",
        "    # encoder to produce the encoder output and the encoder state\n",
        "\n",
        "    dec_state = enc_state # the initial state used in the decoder is the encoder\n",
        "    # state\n",
        "\n",
        "    dec_input = tf.expand_dims(targ[:,0], axis=1) # the first decoder input\n",
        "    # is the first sequence element of the target batch, which in our case\n",
        "    # represents the <start> token for each sequence in the batch. This is\n",
        "    # what we call the teacher forcing!\n",
        "\n",
        "    # Everything is set up for the first step, now we need to loop over the\n",
        "    # teacher forcing sequence to produce the predictions, we already have \n",
        "    # defined the first step (element 0) so we will loop from 1 to targ.shape[1]\n",
        "    # which is the target sequence length\n",
        "    \n",
        "    # t comme token\n",
        "    # targ c'est un batch de token (dim 16)\n",
        "    # Dans une boucle on regarde tout les indice 0, tous les indices 1...\n",
        "    # t = 2 on regarde en même temps \n",
        "    # targ c'est un batch \n",
        "    for t in range(1, targ.shape[1]):                                        # range 1... car on a dejà 0\n",
        "      # passing dec_input, dec_state and enc_output to the decoder\n",
        "      # in order to produce the prediction, the new state, and the attention\n",
        "      # weights which we will not need explicitely here\n",
        "      pred, dec_state, _ = decoder(dec_input, enc_output, dec_state)\n",
        "\n",
        "      # loss sur le token t du batch targ\n",
        "      loss += loss_function(targ[:, t], pred) # we compare the prediction\n",
        "      # produced by teacher forcing with the next element of the target and\n",
        "      # increment the loss\n",
        "\n",
        "      # The new decoder input becomes the next element of the target sequence\n",
        "      # which we just attempted to predict (teacher forcing)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)                      # a l'itération t  change. A la dernière iteration on utilise \n",
        "\n",
        "  # On est en training\n",
        "  # On vient de faire une forward pass\n",
        "  # faut calculer la loss (qui a été incrémenté à chaque tour de boucle)\n",
        "  # rechercher la variable loss_function\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1])) # we divide the loss by the target\n",
        "  # sequence's length to get the average loss across the sequence\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # here\n",
        "  # we concatenate the lists of trainable variables for the encoder and the\n",
        "  # decoder\n",
        "\n",
        "  # compute the gradient based on the loss and the trainable variables\n",
        "  gradients = tape.gradient(loss, variables) \n",
        "\n",
        "  # then update the model's  parameters\n",
        "  optimizer.apply_gradients(zip(gradients, variables)) \n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_829K5bKQS6z",
        "outputId": "4854c9ea-5789-41fe-c40d-17666dafab32"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_batch):\n",
        "    batch_loss = train_step(inp, targ)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 10 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "  \n",
        "  # saving (checkpoint) the model every epoch\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss))\n",
        "  print('Time taken for 1 epoch {} sec'.format(time.time() - start))\n",
        "\n",
        "  #classic encoder input\n",
        "  enc_input = X_val\n",
        "\n",
        "  # the first decoder input is the special token 0\n",
        "  dec_input = tf.zeros(shape=(len(X_val),1))\n",
        "\n",
        "  \n",
        "  # we compute once and for all the encoder output and the encoder\n",
        "  # h state and c state\n",
        "  enc_out, enc_state = encoder(enc_input) #, initial_state)\n",
        "\n",
        "  # The encoder h state and c state will serve as initial states for the decoder\n",
        "  dec_state = enc_state\n",
        "\n",
        "  pred = []  # we'll store the predictions in here\n",
        "\n",
        "  # we loop over the expected length of the target, but actually the loop can run\n",
        "  # for as many steps as we wish, which is the advantage of the encoder decoder\n",
        "  # architecture\n",
        "  \n",
        "  # Là on fait une inference sur le val set\n",
        "  # On pointe sur le start et après on boucle\n",
        "  for i in range(y_val.shape[1]-1):\n",
        "    dec_out, dec_state, attention_w = decoder(dec_input, enc_out, dec_state)\n",
        "    # the decoder state is updated and we get the first prediction probability \n",
        "    # vector\n",
        "    decoded_out = tf.expand_dims(tf.argmax(dec_out, axis=-1), axis=1)\n",
        "    # we decode the softmax vector into and index\n",
        "    pred.append(tf.expand_dims(dec_out,axis=1)) # update the prediction list\n",
        "    dec_input = decoded_out # the previous pred will be used as the new input\n",
        "\n",
        "  pred = tf.concat(pred, axis=1).numpy()\n",
        "  print(\"\\n val loss :\", loss_function(y_val[:,1:],pred),\"\\n\") # on peut alors afficher la loss sur le val set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaF316p_02jy"
      },
      "source": [
        "Nice! The training is over, and it looks as though the model performs really well both on train and validation sets!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4C6vHoo1NqW"
      },
      "source": [
        "## Make predictions with the inference model\n",
        "\n",
        "To make predictions on the validation set, we cannot use teacher forcing, the model has to base itself on its own predictions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgymx0a41s-g",
        "outputId": "ad51b7b1-50d5-4986-e6e4-d97898cc5adb"
      },
      "outputs": [],
      "source": [
        "# le val set fait 5000\n",
        "# on fait pareil qu'avant en fait\n",
        "\n",
        "\n",
        "enc_input = X_val # 5000 seq en anglais\n",
        "#classic encoder input\n",
        "\n",
        "dec_input = tf.zeros(shape=(len(X_val),1))                 # 5000 token start\n",
        "# the first decoder input is the special token 0\n",
        "\n",
        "#initial_state = encoder.state_initializer(len(X_val))\n",
        "\n",
        "enc_out, enc_state = encoder(enc_input)#, initial_state)\n",
        "# we compute once and for all the encoder output and the encoder\n",
        "# h state and c state\n",
        "\n",
        "dec_state = enc_state\n",
        "# The encoder h state and c state will serve as initial states for the\n",
        "# decoder\n",
        "\n",
        "pred = []  # we'll store the predictions in here\n",
        "\n",
        "# we loop over the expected length of the target, but actually the loop can run\n",
        "# for as many steps as we wish, which is the advantage of the encoder decoder\n",
        "# architecture\n",
        "for i in range(y_val.shape[1]-1):\n",
        "  dec_out, dec_state, attention_w = decoder(dec_input, enc_out, dec_state)\n",
        "  # the decoder state is updated and we get the first prediction probability \n",
        "  # vector\n",
        "  decoded_out = tf.expand_dims(tf.argmax(dec_out, axis=-1), axis=1) # argmax pour trouver le mot prdit, on l'enregistre\n",
        "  # we decode the softmax vector into and index\n",
        "  pred.append(decoded_out) # update the prediction list\n",
        "  dec_input = decoded_out # the previous pred will be used as the new input\n",
        "\n",
        "pred = tf.concat(pred, axis=-1).numpy()\n",
        "for i in range(10):\n",
        "  print(\"pred:\", pred[i,:].tolist())\n",
        "  print(\"true:\", y_val[i,:].tolist()[1:])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN9kGOmC3E57"
      },
      "source": [
        "The results do not look so bad, almost perfect actually! This is a clear improvement from the encoder decoder! Attention must be really powerful!\n",
        "\n",
        "The fact that the model reuses the encoder output at each step with different weights is helping the model achieve better predictions in a shorter amount of time (understand epochs).\n",
        "\n",
        "I hope you found this demonstration useful! Now it is time for you to apply what you have learned to a real world automatic translation problem!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03-Code_Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
