{"cells":[{"cell_type":"markdown","metadata":{"id":"5NFuUYKHABlD"},"source":["# Translations 2.0 - Neural Machine Translation\n","\n","According to the Google paper [*Attention is all you need*](https://arxiv.org/abs/1706.03762), you only need layers of Attention to make a Deep Learning model understand the complexity of a sentence. We will try to implement this type of model for our translator. \n","\n","### Data import \n","\n","You will have the same `.txt` file containing a sentence with its translation separated by a tab (`\\t`). You will have to import this data and read it via `pandas`.\n","\n","Your data can be found on this link: https://go.aws/38ECHUB\n","\n","### Preprocessing \n","\n","The whole purpose of your preprocessing is to express your (French) entry sentence in a sequence of clues.\n","\n","i.e. :\n","\n","* je suis heureux---> `[123, 21, 34, 0, 0, 0, 0, 0]`\n","\n","This gives a *shape* -> `(batch_size, max_len_of_a_sentence)`.\n","\n","The zeros correspond to what are called [*padded_sequences*](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) which allow all word sequences to have the same length across a set of sequences (mandatory for your algorithm). \n","\n","You will run the same preprocessing on the target sequences, and add a `<start>` token at the beginning of each sequence.\n","\n","* `<start>` I am happy ---> `[1, 43, 2, 42, 0, 0]`\n","\n","### Modeling \n","\n","For modeling, you will need to set up layers of attention. You'll need to: \n","\n","* Create an `Encoder` class that inherits from `tf.keras.Model`.\n","* Create a Bahdanau Attention Layer that will be a class that inherits `tf.keras.layers.Layer`\n","* Finally create a `Decoder` class that inherits from `tf.keras.Model`.\n","\n","\n","You will need to create your own cost function as well as your own training loop. \n","\n","\n","### Tips \n","\n","Don't take the whole dataset at the beginning for your experiments, just take 5000 or even 3000 sentences. This will allow you to iterate faster and avoid bugs simply related to your need for computing power, and memory space.\n","\n","Good Luck!\n"]},{"cell_type":"code","execution_count":108,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1636996857858,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"2qUhyNPnhBtk","outputId":"16dcd3fe-be81-472b-a345-b80033b28729"},"outputs":[{"data":{"text/plain":["'2.10.0'"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["# Import necessaries librairies\n","import pandas               as pd\n","# import numpy                as np \n","# import tensorflow_datasets  as tfds\n","import tensorflow           as tf \n","import os\n","import time\n","from tensorflow.keras.utils import plot_model\n","\n","from sklearn.model_selection import train_test_split\n","\n","tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"VSWse8KgHmQw"},"source":["## Importing data & Preprocessing\n","\n","1. Load the data using the following url https://go.aws/38ECHUB you can read this using `pd.read_csv` with the `\"\\t\"` delimiter and `header=None`"]},{"cell_type":"code","execution_count":109,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1636996858527,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"U2-Sd6lq_8ax"},"outputs":[],"source":["# Loading function for txt document\n","def load_doc(url):\n","  df = pd.read_csv(url, delimiter=\"\\t\", header=None)\n","  return df"]},{"cell_type":"code","execution_count":110,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1699,"status":"ok","timestamp":1636996860208,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"Yj34GLiihGw1","outputId":"8d16ddaa-c4a5-49f6-c76d-c2a1cf97be4f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0           1\n","0   Go.        Va !\n","1   Hi.     Salut !\n","2  Run!     Cours !\n","3  Run!    Courez !\n","4  Wow!  Ça alors !"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["# Loading txt document\n","doc = load_doc(\"https://go.aws/38ECHUB\")\n","doc.head()"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1636996860210,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"2jiXcCi0FFSr","outputId":"676cf847-b5b4-4149-9ac4-3cf205cb8fc0"},"outputs":[{"data":{"text/plain":["160538"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["len(doc)"]},{"cell_type":"markdown","metadata":{"id":"syRLJiG0YkXR"},"source":["2. Create an object `doc` containing the first 5000 rows from the file."]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1636996860212,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"YrcFSfBZMuQ7"},"outputs":[],"source":["# Let's just take a sample of 5000 sentences to avoid slowness. \n","doc = doc.iloc[:5_000,:]"]},{"cell_type":"markdown","metadata":{"id":"8CKnrs_wYuYn"},"source":["3. Add the word `<start>` to the beginning of each target sentence in order to create a new column named `padded_en`"]},{"cell_type":"code","execution_count":113,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1636996860213,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"7Z1Ih3M2jVr_"},"outputs":[],"source":["# Add a <start> token \n","def begin_sentence(sentence):\n","  sentence = \"<start> \"+ sentence\n","  return sentence"]},{"cell_type":"code","execution_count":114,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1636996860214,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"XVMl6744jmrq","outputId":"c66b55ca-bc2b-46f7-dcef-93b57682206d"},"outputs":[],"source":["# Add <start> and <end> token\n","doc.iloc[:, 0] = doc.iloc[:, 0].apply(lambda x: begin_sentence(x))\n"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1636996860215,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"r2fZfDCqFPko","outputId":"8ad461b9-b087-4555-e7b0-a066323956ed"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;start&gt; Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;start&gt; Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>&lt;start&gt; Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>&lt;start&gt; Help me, please.</td>\n","      <td>Aide-moi, s'il te plait.</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>&lt;start&gt; Help me, please.</td>\n","      <td>Aidez-moi, je vous en supplie.</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>&lt;start&gt; Help us, please.</td>\n","      <td>Aidez-nous, je vous prie !</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>&lt;start&gt; Help us, please.</td>\n","      <td>Aide-nous, je te prie !</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>&lt;start&gt; Help us, please.</td>\n","      <td>Aide-nous, je t'en prie !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 2 columns</p>\n","</div>"],"text/plain":["                             0                               1\n","0                  <start> Go.                            Va !\n","1                  <start> Hi.                         Salut !\n","2                 <start> Run!                         Cours !\n","3                 <start> Run!                        Courez !\n","4                 <start> Wow!                      Ça alors !\n","...                        ...                             ...\n","9995  <start> Help me, please.        Aide-moi, s'il te plait.\n","9996  <start> Help me, please.  Aidez-moi, je vous en supplie.\n","9997  <start> Help us, please.      Aidez-nous, je vous prie !\n","9998  <start> Help us, please.         Aide-nous, je te prie !\n","9999  <start> Help us, please.       Aide-nous, je t'en prie !\n","\n","[10000 rows x 2 columns]"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["doc"]},{"cell_type":"markdown","metadata":{"id":"Z4gI_rGRY1Zr"},"source":["4. Create two objects : `tokenizer_fr` and `tokenizer_en` that will be instances of the `tf.keras.preprocessing.text.Tokenizer` class. \n","\n","Be careful! Since we added a special token containing special characters, make sure you setup the tokenizers right so this token is well interpreted! (use the `filters` argument for example)."]},{"cell_type":"code","execution_count":116,"metadata":{"executionInfo":{"elapsed":579,"status":"ok","timestamp":1636996860774,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"bQQOU7OI7-xV"},"outputs":[],"source":["tokenizer_fr = tf.keras.preprocessing.text.Tokenizer()\n","tokenizer_en = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')"]},{"cell_type":"markdown","metadata":{"id":"zdcfQ9k9Y_Jo"},"source":["5. Fit the tokenizers on the french, and english sentences respectively."]},{"cell_type":"code","execution_count":117,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1636996860776,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"CwCN5z21xo5H"},"outputs":[],"source":["tokenizer_en.fit_on_texts(doc.iloc[:,0])\n","tokenizer_fr.fit_on_texts(doc.iloc[:,1])"]},{"cell_type":"markdown","metadata":{"id":"HKHvD-syZH4_"},"source":["6. Create three new columns in your Dataframe for the encoded french, english sentences."]},{"cell_type":"code","execution_count":118,"metadata":{"executionInfo":{"elapsed":65,"status":"ok","timestamp":1636996860777,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"zIwlGhNDykzn"},"outputs":[],"source":["doc[\"fr_indices\"] = tokenizer_fr.texts_to_sequences(doc.iloc[:,1])\n","doc[\"en_indices\"] = tokenizer_en.texts_to_sequences(doc.iloc[:,0])"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1636996860778,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"XUjLaIjB0e-e","outputId":"094461c2-5357-48b5-f436-33bffa481ff3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>fr_indices</th>\n","      <th>en_indices</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;start&gt; Go.</td>\n","      <td>Va !</td>\n","      <td>[42]</td>\n","      <td>[1, 14]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;start&gt; Hi.</td>\n","      <td>Salut !</td>\n","      <td>[546]</td>\n","      <td>[1, 868]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>Cours !</td>\n","      <td>[2234]</td>\n","      <td>[1, 123]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>Courez !</td>\n","      <td>[2235]</td>\n","      <td>[1, 123]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>&lt;start&gt; Wow!</td>\n","      <td>Ça alors !</td>\n","      <td>[24, 2236]</td>\n","      <td>[1, 1493]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              0           1  fr_indices en_indices\n","0   <start> Go.        Va !        [42]    [1, 14]\n","1   <start> Hi.     Salut !       [546]   [1, 868]\n","2  <start> Run!     Cours !      [2234]   [1, 123]\n","3  <start> Run!    Courez !      [2235]   [1, 123]\n","4  <start> Wow!  Ça alors !  [24, 2236]  [1, 1493]"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["doc.head()"]},{"cell_type":"markdown","metadata":{"id":"b88_o-58ZVjG"},"source":["7. It's rather difficult to work with sequences with variable length, use zero-padding to normalize the length of all the sequences in each category."]},{"cell_type":"code","execution_count":120,"metadata":{"executionInfo":{"elapsed":58,"status":"ok","timestamp":1636996860779,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"-6miVbPY0xZw"},"outputs":[],"source":["# Use of Keras to create token sequences of the same length\n","padded_fr_indices = tf.keras.preprocessing.sequence.pad_sequences(doc[\"fr_indices\"], padding=\"post\")\n","padded_en_indices = tf.keras.preprocessing.sequence.pad_sequences(doc[\"en_indices\"], padding=\"post\")"]},{"cell_type":"markdown","metadata":{"id":"tUOuoN8TZc5M"},"source":["8. What are the shapes of the arrays you just created for the french, and english sentences?"]},{"cell_type":"code","execution_count":121,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1636996860780,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"va8k_PnnZhw1","outputId":"b4148049-9613-466f-8bfe-942ac36a0e31"},"outputs":[{"data":{"text/plain":["(10000, 10)"]},"execution_count":121,"metadata":{},"output_type":"execute_result"}],"source":["padded_fr_indices.shape"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1636996860780,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"1BIxc5eeZkrf","outputId":"ad7eed35-a484-4374-ba9d-c86927013320"},"outputs":[{"data":{"text/plain":["(10000, 6)"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["padded_en_indices.shape"]},{"cell_type":"markdown","metadata":{"id":"yXmSlILiZoZW"},"source":["9. Use `sklearn` `train_test_split` function to divide your sample into train and validation sets."]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1636996860781,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"VrJp0Jk_B8g7"},"outputs":[],"source":["\n","X_train, X_val, y_train, y_val = train_test_split(padded_fr_indices, padded_en_indices)"]},{"cell_type":"markdown","metadata":{"id":"Zn1bP-0hZwH9"},"source":["10. Set a `BATCH_SIZE` then create a `train`, and `val` tensor datasets, apply `.shuffle` on the `train` set and `.batch` on both sets."]},{"cell_type":"code","execution_count":124,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1636996860782,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"_blzVK_dCIvi"},"outputs":[],"source":["BATCH_SIZE = 128\n","train = tf.data.Dataset.from_tensor_slices((X_train,y_train)).shuffle(len(X_train)).batch(BATCH_SIZE)\n","val = tf.data.Dataset.from_tensor_slices((X_val,y_val)).batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"oQ-tj3tBbHrg"},"source":["## Modeling\n","\n","1. Set up the following variables:\n","  * `n_embed` for the models' embedding output dimensions\n","  * `n_gru` for the models' gru number of units\n","  * `vocab_inp_size` for the french vocab size\n","  * `vocab_tar_size` for the english vocab size"]},{"cell_type":"code","execution_count":125,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1636996860784,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"ueIigsED1nWq"},"outputs":[],"source":["# Creation of variables that we will reuse for our models\n","# let's start by defining the number of units needed for the embedding and\n","# the lstm layers\n","\n","n_embed         = 1024\n","n_gru           = 256\n","vocab_in_size   = len(tokenizer_fr.word_index)\n","vocab_out_size  = len(tokenizer_en.word_index)"]},{"cell_type":"markdown","metadata":{"id":"l6fPfVW8cdNh"},"source":["### Encoder\n","\n","2. Define a class `encoder_maker` inheriting from `tf.keras.Model` that can instanciate and encoder type model according to the following schema: \n","\n","![bahdanau](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/attention/Attention-encoder-decoder.drawio.png)"]},{"cell_type":"code","execution_count":126,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1636996860785,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"XbbOi7sYVDU2"},"outputs":[],"source":["class encoder_factory(tf.keras.Model):\n","  \n","  def __init__(self, in_vocab_size, embed_dim, n_units):\n","    super().__init__()\n","    # instanciate an embedding layer\n","    self.n_units = n_units\n","    self.embed = tf.keras.layers.Embedding(input_dim=in_vocab_size, output_dim=embed_dim)\n","    # instantiate GRU layer\n","    self.gru = tf.keras.layers.GRU(units=n_units, return_sequences=True, return_state=True)\n","  \n","  \n","  def __call__(self, input_batch):\n","    # each output will be saved as a class attribute so we can easily access\n","    # them to control the shapes throughout the demo\n","    self.embed_out = self.embed(input_batch)\n","    self.gru_out, self.gru_state = self.gru(self.embed_out)#, initial_state=initial_state)\n","\n","    return self.gru_out, self.gru_state\n"]},{"cell_type":"markdown","metadata":{"id":"SGfDVRdddYZH"},"source":["3. Define an instance of the class called... `encoder`!"]},{"cell_type":"code","execution_count":128,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1636996860787,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"wYTHi-p7DRN7"},"outputs":[],"source":["encoder = encoder_factory(vocab_in_size + 1, n_embed, n_gru)"]},{"cell_type":"markdown","metadata":{"id":"hY2pMguseEuH"},"source":["4. Use the `__call__` method of `encoder` on some data to create an object `encoder_output`, and an `encoder_state` (remember your encoder has two different outputs!). Then print out `encoder_output`, and `encoder_state`."]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1636996860788,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"4cmD6jUP74Rx"},"outputs":[],"source":["encoder_output, encoder_state = encoder(tf.expand_dims(X_train[0],0))"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\utils\\vis_utils.py:430\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m  This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     )\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_graphviz():\n\u001b[0;32m    437\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor plot_model to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."]}],"source":[]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1636996861011,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"Xzno1nYRDeEF","outputId":"22feeb46-27c6-429a-8065-c77b0797ec1a"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 12, 256), dtype=float32, numpy=\n","array([[[ 0.00905645, -0.02516365, -0.01188511, ..., -0.01581522,\n","          0.02389781,  0.01224535],\n","        [ 0.00900744, -0.01763661, -0.01643122, ..., -0.00787944,\n","         -0.00081653,  0.00402039],\n","        [ 0.00947303,  0.00433335, -0.00149967, ...,  0.0033477 ,\n","          0.03288288, -0.00484431],\n","        ...,\n","        [-0.05784671, -0.0274683 , -0.02136509, ..., -0.00858189,\n","         -0.0159177 ,  0.02291612],\n","        [-0.05779962, -0.02760827, -0.02112174, ..., -0.00958698,\n","         -0.01513653,  0.02328783],\n","        [-0.05757864, -0.02765651, -0.02094681, ..., -0.01013853,\n","         -0.01453455,  0.02355005]]], dtype=float32)>"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["encoder_output"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1636996861011,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"VHwCMwX6Di4J","outputId":"44931875-57be-462d-fcca-d0a490ec3ba9"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n","array([[-0.05757864, -0.02765651, -0.02094681,  0.06427027,  0.00590402,\n","         0.0217327 ,  0.00020604,  0.02051996, -0.00044382,  0.04917082,\n","         0.07857566, -0.0086846 , -0.01751825,  0.01698195,  0.03614137,\n","         0.0180245 , -0.00389607,  0.00564247, -0.01470011, -0.02662497,\n","         0.06235842, -0.03729329,  0.03318333,  0.00102663,  0.03631185,\n","        -0.02107344,  0.01817353, -0.00698844,  0.00273566, -0.04410892,\n","        -0.00393473,  0.01625925,  0.01973428, -0.01830165, -0.0603941 ,\n","        -0.00653724,  0.01747008,  0.0251917 , -0.02825532, -0.01008458,\n","        -0.02244198,  0.08356526,  0.01149821,  0.04836292, -0.00207378,\n","        -0.00800344,  0.00935877, -0.00093986, -0.01929062, -0.00657349,\n","        -0.00496154, -0.07652334, -0.0070941 ,  0.01111371,  0.00632809,\n","        -0.03125188, -0.0059572 ,  0.04404977, -0.01731559,  0.00066816,\n","         0.03259735,  0.01874358,  0.00758127,  0.02120544, -0.00584927,\n","        -0.02016695,  0.02512697, -0.03479108, -0.02202838, -0.01856899,\n","        -0.05359584, -0.0219896 ,  0.01393683,  0.03462218, -0.01038269,\n","        -0.02503795,  0.01464789,  0.01633003, -0.03907134,  0.02779272,\n","        -0.00058844, -0.03465067,  0.03429323, -0.0135415 , -0.01292007,\n","        -0.03622659,  0.033287  ,  0.01803792, -0.04507095, -0.00438046,\n","        -0.02864617,  0.00539104,  0.03895685, -0.03099572, -0.02349588,\n","        -0.07233824, -0.06154908, -0.0162889 ,  0.02641441,  0.01187615,\n","        -0.0385545 , -0.0359233 , -0.0104354 , -0.02102633,  0.06564881,\n","        -0.03055348,  0.00183992, -0.01942483,  0.02364779,  0.08998567,\n","        -0.04718118,  0.00746067,  0.03002897, -0.03345437, -0.08123158,\n","         0.02078347,  0.02274737,  0.01295746, -0.00374019, -0.00703167,\n","         0.0317223 , -0.01727436, -0.05561231, -0.02619209, -0.05592529,\n","         0.00566538,  0.01750182,  0.02302428,  0.00613022, -0.01537685,\n","         0.00790321,  0.01304484,  0.05251225,  0.0307447 ,  0.01584643,\n","         0.05715589,  0.01768892,  0.04344271,  0.01209039, -0.01232315,\n","        -0.01779252, -0.0592105 ,  0.00018487, -0.0143246 , -0.06198449,\n","         0.00211491, -0.01036565,  0.07478254,  0.03710726,  0.06531344,\n","         0.02082529, -0.00159413,  0.00364039, -0.04225305, -0.01552774,\n","        -0.08972283,  0.00794962,  0.01758876,  0.05691966, -0.03152512,\n","        -0.01957304,  0.03678017,  0.00812887,  0.03966067,  0.04018407,\n","        -0.05891055,  0.02863701, -0.01442763,  0.01005568,  0.005008  ,\n","        -0.00015971, -0.04495298,  0.01246889,  0.02682175, -0.02875291,\n","         0.06027719, -0.02159351,  0.00835632, -0.00121002, -0.00484802,\n","         0.06437445,  0.01372599, -0.05208428, -0.00375936, -0.04132155,\n","        -0.06276722, -0.01336592, -0.02379557, -0.06368348, -0.00595001,\n","        -0.03016689, -0.04662694,  0.04912783,  0.03894078,  0.0039113 ,\n","        -0.0339168 ,  0.04018883, -0.0575681 , -0.05910387, -0.02755795,\n","         0.00958924,  0.00913467, -0.03684664,  0.00171744,  0.01931169,\n","         0.03557296,  0.0273864 ,  0.01150169,  0.02679287,  0.06640823,\n","         0.04769847,  0.02640536,  0.04527302, -0.00717073,  0.00997412,\n","         0.00448325,  0.10151085, -0.03732156,  0.01367215,  0.0215358 ,\n","         0.02767043,  0.02549818,  0.01640702,  0.00231716, -0.00464814,\n","         0.00601464,  0.03685936,  0.03033831,  0.01022641, -0.01759017,\n","         0.03489126, -0.00587294, -0.01593158, -0.04514156,  0.00899701,\n","        -0.02982874,  0.01233395,  0.07056522,  0.01761119, -0.04021225,\n","        -0.01278589,  0.0001949 , -0.00792048,  0.04573929, -0.04970191,\n","         0.00890872,  0.04254136, -0.01059741, -0.01049495, -0.04489791,\n","         0.02792871, -0.00495757,  0.02724271, -0.01013853, -0.01453455,\n","         0.02355005]], dtype=float32)>"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["encoder_state"]},{"cell_type":"markdown","metadata":{"id":"Y-4Vni1Lek2f"},"source":["### Attention layer\n","\n","5. Create a `Bahdanau_attention_maker` class that lets you instanciate an attention layer that you will include in your decoder model. You may follow the instructions from this schema: \n","\n","![bahdanau](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/attention/Attention-encoder-decoder.drawio.png)\n","\n","And get inspiration (as much as you want) from the lecture's demo!"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1636996861012,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"Uq2nP5l_76LS"},"outputs":[],"source":["class Bahdanau_attention_maker(tf.keras.layers.Layer):\n","  \n","  def __init__(self, attention_units):\n","    super().__init__()\n","\n","    # The attention layer contains three dense layers\n","    self.W1 = tf.keras.layers.Dense(units=attention_units)\n","    self.W2 = tf.keras.layers.Dense(units=attention_units)\n","    self.V = tf.keras.layers.Dense(units=1)\n","\n","  def __call__(self, enc_out, state):\n","    # the choice of name of the arguments here is not random, enc_out\n","    # will represent the encoder output which will be used to create\n","    # the attention weights and then used to create the context vector once we\n","    # apply the attention weights\n","    # the state will be a hidden state from a recurrent unit coming either\n","    # from the encoder at first, and from the decoder as we make further \n","    # predictions\n","    self.W1_out = self.W1(enc_out) # shape (1,12,attention_units)\n","\n","    # If you have taken a close look the model's schema you would have noticed\n","    # that we are going to sum the outputs from W1 and W2, though the shapes\n","    # are incompatible\n","    # the enc_out is (batch_size,12,16) -> W1 -> (batch_size,12,attention_units)\n","    # the state is (batch_size,16) -> W2 -> (batch_size,attention_units)\n","    # thus we need to artificially add a dimension to the stata along axis 1\n","    self.state = tf.expand_dims(state, axis = 1)\n","    self.W2_out = self.W2(self.state) # shape (batch_size,1,attention_units)\n","\n","    self.sum = self.W1_out + self.W2_out  # shape (batch_size,12,attention_units)\n","    self.sum_scale = tf.nn.tanh(self.sum) # shape (batch_size,12,attention_units)\n","\n","    self.score = self.V(self.sum_scale) # shape (batch_size,12,1)\n","\n","    self.attention_weights = tf.nn.softmax(self.score, axis=1) # shape (batch_size,12,1)\n","\n","    self.weighted_enc_out = enc_out * self.attention_weights # shape (batch_size,12,16)\n","\n","    self.context_vector = tf.reduce_sum(self.weighted_enc_out, axis=1) # Somme selon l'axe 1 du tenseur (b, 12, 16), donc colonne => shape (batch_size,16)\n","\n","    return self.context_vector, self.attention_weights"]},{"cell_type":"markdown","metadata":{"id":"nNUh8ANHfmP0"},"source":["6. Create an instance of the class called `attention_layer`."]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1636996861012,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"KetnxQvd8bF0"},"outputs":[],"source":["attention_layer = Bahdanau_attention_maker(8)"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'plot_model' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m(attention_layer)\n","\u001b[1;31mNameError\u001b[0m: name 'plot_model' is not defined"]}],"source":["plot_model(attention_layer)"]},{"cell_type":"markdown","metadata":{"id":"SZREk1XRfxzf"},"source":["7. Try out the `__call__` method on the `encoder_output`, and `encoder_state`."]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1636996861013,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"M4CORsJZD8m0","outputId":"f618c45c-1f25-4eec-8212-e95014144c8f"},"outputs":[{"data":{"text/plain":["(<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n"," array([[-0.03044341, -0.01617486, -0.0163315 ,  0.03019225, -0.00105563,\n","          0.01620287, -0.00621167,  0.01842681, -0.00171171,  0.03193591,\n","          0.03495656, -0.00626692, -0.00456389,  0.01549913,  0.01471619,\n","          0.01473392, -0.00562287,  0.0090839 , -0.00797053, -0.01652147,\n","          0.04017272, -0.03352743,  0.01866774, -0.00043037,  0.0133545 ,\n","         -0.0002742 ,  0.00795678, -0.00210773,  0.00408419, -0.02375865,\n","         -0.01870133,  0.00274507,  0.01029423, -0.01120158, -0.03912488,\n","         -0.00025478,  0.01719798,  0.0068701 , -0.01790881, -0.00913726,\n","         -0.00990078,  0.05565539, -0.00016384,  0.02713146, -0.00375317,\n","         -0.01437655,  0.01637932, -0.0075435 , -0.0047624 , -0.00221256,\n","         -0.0091235 , -0.05413564, -0.0133197 ,  0.00675143,  0.00341251,\n","         -0.01962358,  0.00178746,  0.03600667, -0.01437644,  0.00047946,\n","          0.01887695,  0.01412492,  0.00887732,  0.00489913, -0.00269612,\n","         -0.00173233,  0.01984429, -0.02574448, -0.00836706, -0.00935257,\n","         -0.02415156, -0.01364131,  0.00364317,  0.0203252 , -0.00634583,\n","         -0.01521568,  0.00174991,  0.00308215, -0.03022245,  0.02451263,\n","          0.00872472, -0.02870876,  0.02164322, -0.00518941, -0.00923212,\n","         -0.02551443,  0.02008129,  0.01169484, -0.02952336,  0.00313194,\n","         -0.02492367,  0.00140732,  0.02216332, -0.01726988, -0.01210609,\n","         -0.04420643, -0.03179445, -0.01177461,  0.0185341 ,  0.00502532,\n","         -0.00959116, -0.0113941 , -0.00820005, -0.01456234,  0.0383639 ,\n","         -0.02418705,  0.0042353 , -0.01999263,  0.01734757,  0.05315508,\n","         -0.02353852,  0.00568534,  0.01909112, -0.02743873, -0.04008442,\n","          0.00330814,  0.00554259,  0.01133466, -0.00299705, -0.01130947,\n","          0.02176538, -0.01231394, -0.03044923, -0.02040347, -0.03006542,\n","          0.00539397,  0.00303894,  0.01271229,  0.00689177, -0.0023194 ,\n","          0.01513009,  0.00541555,  0.02837753,  0.01756709,  0.01523034,\n","          0.03243683,  0.01095058,  0.01501421,  0.00611916, -0.01628073,\n","         -0.00809101, -0.04343653,  0.01082036, -0.00036727, -0.02897594,\n","         -0.00643039,  0.00214497,  0.03096143,  0.01519023,  0.03224308,\n","          0.00799009, -0.00596778, -0.00737224, -0.01942456, -0.0128664 ,\n","         -0.05834547,  0.01598439,  0.00879003,  0.04199648, -0.0168818 ,\n","         -0.00563597,  0.02074771, -0.00039042,  0.03171137,  0.01839914,\n","         -0.04050615,  0.02454848, -0.00526309,  0.0100081 ,  0.00706948,\n","         -0.00495235, -0.03128126,  0.0124405 ,  0.01452245, -0.00542635,\n","          0.04491238, -0.00953943,  0.00501005, -0.01183267,  0.00752227,\n","          0.03117188, -0.00145279, -0.02835361, -0.01191329, -0.02760836,\n","         -0.03980441, -0.01410108, -0.00615459, -0.04073974, -0.00780632,\n","         -0.01263548, -0.03285014,  0.03078134,  0.01038175,  0.00111263,\n","         -0.01391789,  0.02371871, -0.03655935, -0.02776102, -0.0177405 ,\n","          0.00111355,  0.00981635, -0.01856048, -0.00569201,  0.01139057,\n","          0.01338391,  0.0150808 ,  0.01314296,  0.01337173,  0.05399828,\n","          0.03376323,  0.01132   ,  0.02560586, -0.0053905 ,  0.00740761,\n","          0.00371893,  0.06154347, -0.02536461,  0.00284143,  0.01248684,\n","          0.01924215,  0.01139565,  0.0160457 ,  0.00590976,  0.00307962,\n","          0.00531927,  0.03081713,  0.02055752,  0.00817694, -0.02672709,\n","          0.02429259, -0.00227222, -0.01549425, -0.0301178 ,  0.00485574,\n","         -0.01466656,  0.0071113 ,  0.04225159,  0.00937934, -0.02504155,\n","         -0.01225058, -0.00527019, -0.00774394,  0.03382981, -0.04099786,\n","          0.01762559,  0.01274429, -0.00655404, -0.01223935, -0.01839942,\n","          0.01845318, -0.00236863,  0.01619464, -0.00015443, -0.00312111,\n","          0.01316551]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 12, 1), dtype=float32, numpy=\n"," array([[[0.08279728],\n","         [0.08318987],\n","         [0.08275916],\n","         [0.08398324],\n","         [0.08423065],\n","         [0.0838999 ],\n","         [0.08355244],\n","         [0.08330707],\n","         [0.08315787],\n","         [0.08307524],\n","         [0.08303321],\n","         [0.08301412]]], dtype=float32)>)"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["attention_layer(encoder_output, encoder_state)"]},{"cell_type":"markdown","metadata":{"id":"eectqIKPgGdM"},"source":["### Decoder\n","\n","8. Set up a `decoder_maker` class that will let you create decoder models according to the demo and the following schema: \n","\n","![bahdanau](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/attention/Attention-encoder-decoder.drawio.png)"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1636996861014,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"Ruo6sIk98eLs"},"outputs":[],"source":["class decoder_maker(tf.keras.Model):\n","  def __init__(self, target_vocab_size, embed_dim, n_units):\n","    super().__init__()\n","    # The decoder contains an embedding layer to play with the teacher forcing\n","    # input, which comes from the target data\n","    # A gru layer\n","    # A dense layer to make the predictions\n","    # And an attention layer\n","    self.embed = tf.keras.layers.Embedding(input_dim=target_vocab_size, output_dim=embed_dim)\n","    self.gru = tf.keras.layers.GRU(units=n_units, return_sequences=True, return_state=True)\n","    self.pred = tf.keras.layers.Dense(units=target_vocab_size, activation=\"softmax\")\n","    self.attention = Bahdanau_attention_maker(attention_units=n_units)\n","\n","  def __call__(self, dec_in, enc_out, state):\n","    # first let's apply the attention layer\n","    self.context_vector, self.attention_weights = self.attention(enc_out,state)\n","\n","    # now the decoder will ingest one sequence element from the teacher forcing\n","    # this will be of shape (bacth_size, 1)\n","    self.embed_out = self.embed(dec_in) # shape (batch_size,1,embed_dim)\n","\n","    # then we need to concatenate the embedding output and the context vector\n","    # though their shapes are incompatible\n","    # embed out (batch_size, 1, embed_dim)\n","    # context vector (batch_size, n_units) where n_units was defined in the encoder\n","    # so we need to add one dimension along axis 1\n","    self.context_vector_expanded = tf.expand_dims(self.context_vector, axis=1)\n","    # shape (batch_size,1,n_units)\n","    self.concat = tf.keras.layers.concatenate([self.embed_out,\n","                                               self.context_vector_expanded])\n","    # shape (bacth_size,1, embed_dim + n_units)\n","    \n","    # now we get to apply the gru layer\n","    self.gru_out, self.gru_state = self.gru(self.concat) \n","    # shapes (batch_size, 1, n_units) and (batch_size, n_units)\n","\n","    # let's reshape the gru output before feeding it to the dense layer\n","    self.gru_out_reshape = tf.reshape(self.gru_out, shape=(-1,\n","                                                           self.gru_out.shape[2]))\n","\n","    # now let's make a prediction\n","    self.pred_out = self.pred(self.gru_out_reshape) # shape (batch_size, 1, tar_vocab_size)\n","\n","    return self.pred_out, self.gru_state, self.attention_weights"]},{"cell_type":"markdown","metadata":{"id":"pBkX8N8zgj9F"},"source":["9. Create an instance of the class called...... `decoder` !"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636996861014,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"jPW5WmrY8hyT"},"outputs":[],"source":["decoder = decoder_maker(target_vocab_size=vocab_out_size+1, embed_dim=n_embed, n_units=n_gru)"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\utils\\vis_utils.py:430\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m  This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     )\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_graphviz():\n\u001b[0;32m    437\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor plot_model to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"KW5RF79Pg-AY"},"source":["10. Try out the decoder on some teacher forcing data and the encoder outputs."]},{"cell_type":"code","execution_count":99,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636996861014,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"OrRgi6Q-ELHb"},"outputs":[],"source":["decoder_input = tf.expand_dims(tf.expand_dims(y_train[0][0], axis=0), axis=0) # the teacher forcing is\n","# the first element of the target sequence which corresponds to the <start> token\n","# we use expand dim to artificially add the batch size dimension"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1636996861208,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"zA00Pv8EEaQJ","outputId":"f25fed40-f50f-4a50-9cec-3fd2b46c7fcd"},"outputs":[{"data":{"text/plain":["(<tf.Tensor: shape=(1, 4576), dtype=float32, numpy=\n"," array([[0.00021811, 0.00021775, 0.0002189 , ..., 0.00021817, 0.00021816,\n","         0.00021865]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n"," array([[-2.88544083e-03, -3.03292628e-02,  7.15822607e-05,\n","         -1.95521731e-02, -2.61017941e-02,  4.24746536e-02,\n","          5.47750574e-03,  2.46608350e-03, -3.41445976e-03,\n","          4.65776538e-03, -3.36298607e-02,  2.46483716e-03,\n","          2.89762742e-03,  3.58047560e-02, -9.09270905e-03,\n","          6.08691666e-03, -2.06586923e-02,  5.87580958e-03,\n","          1.05534857e-02, -1.12922722e-02,  2.30217315e-02,\n","          1.21390994e-03,  1.67560820e-02,  6.45752717e-03,\n","         -1.26004629e-02, -1.85700646e-03,  8.72948673e-03,\n","         -1.73054803e-02,  5.02653420e-03, -1.94900595e-02,\n","          1.59663074e-02, -7.44627044e-03, -3.24146799e-03,\n","         -1.46506950e-02,  5.02036139e-03, -5.25137177e-03,\n","         -1.44381355e-02,  5.82653238e-03,  2.10345294e-02,\n","          1.36452988e-02,  7.12916208e-03,  3.67003563e-03,\n","          1.15309916e-02,  8.70960020e-03,  5.16868569e-03,\n","          6.18282845e-03, -8.14947198e-05, -1.66983716e-03,\n","          1.76552013e-02,  5.77426981e-03, -2.11572694e-03,\n","         -1.60622373e-02,  4.37980052e-04, -1.43807178e-04,\n","          2.14957938e-04, -5.01995115e-03, -8.86856858e-03,\n","         -2.41257425e-04, -1.34306354e-02, -1.29634142e-02,\n","         -5.32987388e-03,  1.52280945e-02, -1.10196983e-02,\n","          8.57679639e-03, -3.55153643e-02, -2.56619067e-03,\n","         -2.10868940e-02, -2.05933303e-02, -1.43799176e-02,\n","          1.03677688e-02, -1.81811322e-02,  1.08242109e-02,\n","         -4.34344076e-03, -8.07269756e-03, -2.06283238e-02,\n","         -1.20549817e-02,  1.54639706e-02, -1.29675893e-02,\n","         -2.26022070e-03, -8.36782157e-03,  4.45267092e-03,\n","         -3.60920243e-02,  1.39643736e-02,  1.91363611e-03,\n","          1.29268263e-02,  1.25983991e-02,  3.35694849e-02,\n","         -6.24271063e-03, -1.52224004e-02,  2.44568139e-02,\n","          1.13861281e-02,  1.55952135e-02, -2.30289400e-02,\n","         -5.25137484e-02,  9.17430315e-03, -3.45657510e-03,\n","          1.63453873e-02, -2.13101264e-02, -1.08558452e-02,\n","          3.00725289e-02, -1.61966048e-02,  1.59330480e-02,\n","          3.27830985e-02,  8.92479066e-03,  2.36865077e-02,\n","          3.52305174e-03,  2.03223107e-03,  2.43497137e-02,\n","         -1.22970557e-02,  1.59730837e-02, -3.12267337e-02,\n","          1.83435380e-02,  1.73399951e-02,  9.05673951e-03,\n","          1.83098251e-03, -1.22312619e-03,  1.28187193e-02,\n","         -1.15662767e-02,  4.20328975e-03, -4.46171686e-03,\n","          2.38391627e-02, -9.07186233e-03,  2.72631482e-03,\n","          1.48241911e-02, -1.62281673e-02,  1.08141024e-02,\n","         -1.16765769e-02, -2.27942858e-02,  8.52268946e-04,\n","         -3.57998721e-03,  1.14656589e-03, -1.09915808e-02,\n","          1.91054214e-02, -5.84253576e-04, -1.07617779e-02,\n","          1.07412953e-02, -8.51318054e-03,  2.79454179e-02,\n","          2.14913418e-03,  1.35381464e-02, -1.05695054e-02,\n","          1.67245977e-02, -6.06098585e-03,  2.24160799e-03,\n","         -3.20547121e-03,  1.20884869e-02,  2.59922422e-03,\n","          7.77939521e-03,  2.39742151e-03, -1.33217331e-02,\n","         -3.39287100e-03, -1.38251241e-02, -1.81704294e-02,\n","          2.66354326e-02,  1.92255713e-02,  1.93302501e-02,\n","         -9.35666636e-03, -1.11628184e-02, -2.15437524e-02,\n","          1.37276761e-02,  4.02476825e-02,  2.05582436e-02,\n","         -1.97517257e-02,  4.16306034e-03, -1.16441734e-02,\n","         -5.88629628e-05,  5.01527730e-03, -4.30340553e-03,\n","         -1.45393731e-02,  9.39164218e-03,  3.23710628e-02,\n","          1.65066663e-02, -4.88500064e-03,  1.21862916e-02,\n","         -1.28935918e-03,  1.11207888e-02,  2.28232730e-05,\n","          2.13415660e-02,  4.38032526e-04, -5.19776298e-03,\n","          2.17214139e-04,  6.90096850e-03,  8.43088981e-03,\n","          1.99557338e-02, -2.60860077e-03,  2.79432838e-03,\n","         -1.40059618e-02, -7.81689491e-03, -1.35205071e-02,\n","         -4.03438509e-03, -8.03355779e-03, -8.42007436e-03,\n","          1.44571401e-04, -7.95133878e-03, -3.33322707e-04,\n","          9.02136974e-03,  1.12103792e-02, -5.90552576e-03,\n","          4.48909122e-03,  7.67312187e-04,  1.37739806e-02,\n","          2.11435761e-02, -5.92715852e-03,  2.32724231e-02,\n","         -1.06663089e-02,  4.73639555e-03,  2.00263672e-02,\n","         -2.78156698e-02, -1.10386768e-02, -4.15781094e-03,\n","         -5.33646857e-03,  1.87130794e-02, -6.45918818e-03,\n","         -4.54663485e-03, -1.18954908e-02,  1.08336741e-02,\n","          1.46748284e-02, -6.77601947e-03, -1.57050360e-02,\n","         -1.10575687e-02,  5.06500481e-03,  1.44933921e-03,\n","          1.75641738e-02,  4.74905036e-03,  9.18247178e-03,\n","         -3.60841723e-03,  3.44558875e-03, -7.32471282e-03,\n","         -1.65361967e-02,  1.56948692e-03, -1.90148745e-02,\n","         -7.80359260e-04, -7.91184139e-03, -1.20069878e-02,\n","          1.07819010e-02, -4.97886399e-03,  3.40835191e-03,\n","          4.18828968e-05,  1.76022965e-02, -1.53665366e-02,\n","         -8.24834313e-03, -7.35917129e-03,  1.35257561e-03,\n","         -3.24113620e-03, -1.42307663e-02,  8.93084740e-04,\n","          2.22217534e-02,  9.35823563e-03, -1.14735486e-02,\n","         -8.96065589e-03,  1.69117562e-02, -2.55802460e-02,\n","          6.25917048e-04,  2.46235188e-02,  4.12316388e-03,\n","          4.11307439e-03]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 12, 1), dtype=float32, numpy=\n"," array([[[0.0859136 ],\n","         [0.08509496],\n","         [0.0846616 ],\n","         [0.08758913],\n","         [0.08415357],\n","         [0.0826329 ],\n","         [0.0819766 ],\n","         [0.08170647],\n","         [0.08160257],\n","         [0.08156581],\n","         [0.08155365],\n","         [0.08154911]]], dtype=float32)>)"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["decoder(decoder_input,encoder_output,encoder_state)"]},{"cell_type":"markdown","metadata":{"id":"r2h8jDTT8wHq"},"source":["### Loss\n","\n","11. Look at the following loss function, what is the purpose of it, what will it change about the way the model learns?"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636996861208,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"3ldPbErh8j1x"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"]},{"cell_type":"markdown","metadata":{"id":"9zMoWHITh1Pk"},"source":["12. Set up a checkpoint for the optimizer, the encoder, and the decoder."]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636996861209,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"RBFavAT78w25"},"outputs":[],"source":["\n","checkpoint_dir = './training_checkpoints2'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"]},{"cell_type":"markdown","metadata":{"id":"z8V4m-De84om"},"source":["## Training \n","\n","1. Define a `train_step` function that will take as arguments `inp` which represents a batch of input sequences, and `targ` which represents an input of target sequences.\n","\n","This function will:\n","* Initiate `loss` to zero\n","* Track all operations with `tf.GradientTape() as tape`\n","* Use the encoder on `inp` to compute its outputs\n","* Set `dec_state` as the encoder state\n","* Set `dec_input` as the first sequence element of the target batch `targ` (careful with the shapes)\n","* Start a loop that will go through each subsequent elements of the target sequence, and will do:\n","  * Apply the decoder on the encoder outputs and `dec_input`, this will create the prediction's probability vector, and update the decoder state\n","  * Calculate  the loss based on the next element of `targ`, and the prediction probability vector and add it to `loss`\n","  * Set the new decoder input as the next element of `targ`\n","* Create `batch_loss` as equal to the average value of the loss over the target sequence.\n","* Create a `variables` object containing both the encoder's and the decoder's training variables.\n","* Compute the gradient and update the training variables.\n","* Return `batch_loss`\n"]},{"cell_type":"code","execution_count":103,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636996861209,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"bUAgTA4-8zsX"},"outputs":[],"source":["def train_step(inp, targ):#, enc_initial_state):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape: # we use the gradient tape to track all\n","  # the different operations happening in the network in order to be able\n","  # to compute the gradients later\n","\n","    enc_output, enc_state = encoder(inp)#,enc_initial_state) # the input sequence is fed to the \n","    # encoder to produce the encoder output and the encoder state\n","\n","    dec_state = enc_state # the initial state used in the decoder is the encoder\n","    # state\n","\n","    dec_input = tf.expand_dims(targ[:,0], axis=1) # the first decoder input\n","    # is the first sequence element of the target batch, which in our case\n","    # represents the <start> token for each sequence in the batch. This is\n","    # what we call the teacher forcing!\n","\n","    # Everything is set up for the first step, now we need to loop over the\n","    # teacher forcing sequence to produce the predictions, we already have \n","    # defined the first step (element 0) so we will loop from 1 to targ.shape[1]\n","    # which is the target sequence length\n","    for t in range(1, targ.shape[1]):\n","      # passing dec_input, dec_state and enc_output to the decoder\n","      # in order to produce the prediction, the new state, and the attention\n","      # weights which we will not need explicitely here\n","      pred, dec_state, _ = decoder(dec_input, enc_output, dec_state)\n","\n","      loss += loss_function(targ[:, t], pred) # we compare the prediction\n","      # produced by teacher forcing with the next element of the target and\n","      # increment the loss\n","\n","      # The new decoder input becomes the next element of the target sequence\n","      # which we just attempted to predict (teacher forcing)\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1])) # we divide the loss by the target\n","  # sequence's length to get the average loss across the sequence\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables # here\n","  # we concatenate the lists of trainable variables for the encoder and the\n","  # decoder\n","\n","  gradients = tape.gradient(loss, variables) # compute the gradient based on the\n","  # loss and the trainable variables\n","\n","  optimizer.apply_gradients(zip(gradients, variables)) # then update the model's\n","  # parameters\n","\n","  return batch_loss"]},{"cell_type":"markdown","metadata":{"id":"dnp_T-Yukiag"},"source":["2. Code the training loop.\n","It needs to loop across the number of epochs you wish to train for, use the train step, print out the train loss every now and then, and the val loss at the end of each epoch (optional)"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502374,"status":"ok","timestamp":1636997363577,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"XgoAc_Sd85tt","outputId":"feddf990-7b8b-444f-c73d-f20bc16b96c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 0 Loss 3.6464\n","Epoch 1 Batch 10 Loss 3.0781\n","Epoch 1 Batch 20 Loss 2.7352\n","Epoch 1 Batch 30 Loss 2.7237\n","Epoch 1 Batch 40 Loss 2.5665\n","Epoch 1 Batch 50 Loss 2.5956\n","Epoch 1 Batch 60 Loss 2.6283\n","Epoch 1 Batch 70 Loss 2.4825\n","Epoch 1 Batch 80 Loss 2.4743\n","Epoch 1 Batch 90 Loss 2.5013\n","Epoch 1 Batch 100 Loss 2.4846\n","Epoch 1 Batch 110 Loss 2.4850\n","Epoch 1 Batch 120 Loss 2.4214\n","Epoch 1 Batch 130 Loss 2.4074\n","Epoch 1 Batch 140 Loss 2.5011\n","Epoch 1 Batch 150 Loss 2.4017\n","Epoch 1 Batch 160 Loss 2.3676\n","Epoch 1 Batch 170 Loss 2.3941\n","Epoch 1 Loss 455.0478\n","Time taken for 1 epoch 78.25395655632019 sec\n","\n"," val loss : tf.Tensor(3.2851744, shape=(), dtype=float32) \n","\n","Epoch 2 Batch 0 Loss 2.4032\n","Epoch 2 Batch 10 Loss 2.4467\n","Epoch 2 Batch 20 Loss 2.1991\n","Epoch 2 Batch 30 Loss 2.3230\n","Epoch 2 Batch 40 Loss 2.2807\n","Epoch 2 Batch 50 Loss 2.2440\n","Epoch 2 Batch 60 Loss 2.3523\n","Epoch 2 Batch 70 Loss 2.2965\n","Epoch 2 Batch 80 Loss 2.2317\n","Epoch 2 Batch 90 Loss 2.2456\n","Epoch 2 Batch 100 Loss 2.1492\n","Epoch 2 Batch 110 Loss 2.1918\n","Epoch 2 Batch 120 Loss 2.1690\n","Epoch 2 Batch 130 Loss 2.2188\n","Epoch 2 Batch 140 Loss 2.1772\n","Epoch 2 Batch 150 Loss 2.1123\n","Epoch 2 Batch 160 Loss 2.1102\n","Epoch 2 Batch 170 Loss 2.1604\n","Epoch 2 Loss 392.0936\n","Time taken for 1 epoch 73.60500836372375 sec\n","\n"," val loss : tf.Tensor(3.181182, shape=(), dtype=float32) \n","\n","Epoch 3 Batch 0 Loss 2.0259\n","Epoch 3 Batch 10 Loss 2.0577\n","Epoch 3 Batch 20 Loss 2.0134\n","Epoch 3 Batch 30 Loss 2.0764\n","Epoch 3 Batch 40 Loss 1.9923\n","Epoch 3 Batch 50 Loss 2.0254\n","Epoch 3 Batch 60 Loss 2.0034\n","Epoch 3 Batch 70 Loss 1.9962\n","Epoch 3 Batch 80 Loss 1.9685\n","Epoch 3 Batch 90 Loss 1.8943\n","Epoch 3 Batch 100 Loss 1.9663\n","Epoch 3 Batch 110 Loss 1.9335\n","Epoch 3 Batch 120 Loss 1.8493\n","Epoch 3 Batch 130 Loss 1.9078\n","Epoch 3 Batch 140 Loss 1.9244\n","Epoch 3 Batch 150 Loss 1.8483\n","Epoch 3 Batch 160 Loss 1.9252\n","Epoch 3 Batch 170 Loss 1.9155\n","Epoch 3 Loss 343.4679\n","Time taken for 1 epoch 74.09487962722778 sec\n","\n"," val loss : tf.Tensor(3.1634364, shape=(), dtype=float32) \n","\n","Epoch 4 Batch 0 Loss 1.7913\n","Epoch 4 Batch 10 Loss 1.7789\n","Epoch 4 Batch 20 Loss 1.7630\n","Epoch 4 Batch 30 Loss 1.7395\n","Epoch 4 Batch 40 Loss 1.7293\n","Epoch 4 Batch 50 Loss 1.7048\n","Epoch 4 Batch 60 Loss 1.6459\n","Epoch 4 Batch 70 Loss 1.7339\n","Epoch 4 Batch 80 Loss 1.7386\n","Epoch 4 Batch 90 Loss 1.6456\n","Epoch 4 Batch 100 Loss 1.6652\n","Epoch 4 Batch 110 Loss 1.6202\n","Epoch 4 Batch 120 Loss 1.6828\n","Epoch 4 Batch 130 Loss 1.6326\n","Epoch 4 Batch 140 Loss 1.6392\n","Epoch 4 Batch 150 Loss 1.6042\n","Epoch 4 Batch 160 Loss 1.6080\n","Epoch 4 Batch 170 Loss 1.6194\n","Epoch 4 Loss 299.7670\n","Time taken for 1 epoch 73.79272484779358 sec\n","\n"," val loss : tf.Tensor(2.9960904, shape=(), dtype=float32) \n","\n","Epoch 5 Batch 0 Loss 1.6188\n","Epoch 5 Batch 10 Loss 1.5751\n","Epoch 5 Batch 20 Loss 1.4401\n","Epoch 5 Batch 30 Loss 1.4949\n","Epoch 5 Batch 40 Loss 1.4628\n","Epoch 5 Batch 50 Loss 1.4082\n","Epoch 5 Batch 60 Loss 1.3748\n","Epoch 5 Batch 70 Loss 1.4747\n","Epoch 5 Batch 80 Loss 1.5155\n","Epoch 5 Batch 90 Loss 1.4705\n","Epoch 5 Batch 100 Loss 1.4002\n","Epoch 5 Batch 110 Loss 1.4770\n","Epoch 5 Batch 120 Loss 1.3677\n","Epoch 5 Batch 130 Loss 1.2782\n","Epoch 5 Batch 140 Loss 1.3361\n","Epoch 5 Batch 150 Loss 1.3340\n","Epoch 5 Batch 160 Loss 1.3622\n","Epoch 5 Batch 170 Loss 1.3983\n","Epoch 5 Loss 255.2357\n","Time taken for 1 epoch 73.20464587211609 sec\n","\n"," val loss : tf.Tensor(2.7807271, shape=(), dtype=float32) \n","\n","Epoch 6 Batch 0 Loss 1.2760\n","Epoch 6 Batch 10 Loss 1.2419\n","Epoch 6 Batch 20 Loss 1.2960\n","Epoch 6 Batch 30 Loss 1.2256\n","Epoch 6 Batch 40 Loss 1.3021\n","Epoch 6 Batch 50 Loss 1.2409\n","Epoch 6 Batch 60 Loss 1.2103\n","Epoch 6 Batch 70 Loss 1.2248\n","Epoch 6 Batch 80 Loss 1.2228\n","Epoch 6 Batch 90 Loss 1.2617\n","Epoch 6 Batch 100 Loss 1.2057\n","Epoch 6 Batch 110 Loss 1.1975\n","Epoch 6 Batch 120 Loss 1.2204\n","Epoch 6 Batch 130 Loss 1.1455\n","Epoch 6 Batch 140 Loss 1.1930\n","Epoch 6 Batch 150 Loss 1.1832\n","Epoch 6 Batch 160 Loss 1.2574\n","Epoch 6 Batch 170 Loss 1.2907\n","Epoch 6 Loss 215.4189\n","Time taken for 1 epoch 73.79615259170532 sec\n","\n"," val loss : tf.Tensor(2.584747, shape=(), dtype=float32) \n","\n","Epoch 7 Batch 0 Loss 1.0854\n","Epoch 7 Batch 10 Loss 1.0744\n","Epoch 7 Batch 20 Loss 1.0720\n","Epoch 7 Batch 30 Loss 0.9861\n","Epoch 7 Batch 40 Loss 1.0302\n","Epoch 7 Batch 50 Loss 1.0500\n","Epoch 7 Batch 60 Loss 1.0158\n","Epoch 7 Batch 70 Loss 1.0746\n","Epoch 7 Batch 80 Loss 0.9649\n","Epoch 7 Batch 90 Loss 1.0127\n","Epoch 7 Batch 100 Loss 1.0478\n","Epoch 7 Batch 110 Loss 1.0248\n","Epoch 7 Batch 120 Loss 1.0417\n","Epoch 7 Batch 130 Loss 0.9590\n","Epoch 7 Batch 140 Loss 0.9729\n","Epoch 7 Batch 150 Loss 0.9110\n","Epoch 7 Batch 160 Loss 0.9487\n","Epoch 7 Batch 170 Loss 1.0771\n","Epoch 7 Loss 178.2588\n","Time taken for 1 epoch 79.63338160514832 sec\n","\n"," val loss : tf.Tensor(2.3774216, shape=(), dtype=float32) \n","\n","Epoch 8 Batch 0 Loss 0.8910\n","Epoch 8 Batch 10 Loss 0.8206\n","Epoch 8 Batch 20 Loss 0.8414\n","Epoch 8 Batch 30 Loss 0.8023\n","Epoch 8 Batch 40 Loss 0.7894\n","Epoch 8 Batch 50 Loss 0.8490\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\3465965888.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, initial_state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\2272049794.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(inp, targ)\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# we use the gradient tape to track all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# the different operations happening in the network in order to be able\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# to compute the gradients later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,enc_initial_state) # the input sequence is fed to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# encoder to produce the encoder output and the encoder state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdec_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_state\u001b[0m \u001b[1;31m# the initial state used in the decoder is the encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\1145582843.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, input_batch)\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# each output will be saved as a class attribute so we can easily access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# them to control the shapes throughout the demo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, initial_state=initial_state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         )\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# tensors, then add them to the inputs and temporarily modify the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    665\u001b[0m             )\n\u001b[0;32m    666\u001b[0m             \u001b[1;31m# This is a dummy tensor for testing purpose.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgru_lstm_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgru_lstm_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRUNTIME_UNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m             last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[0;32m    670\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m             )\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[0;32m    889\u001b[0m                     last_output, outputs, new_h, runtime = gpu_gru(\n\u001b[0;32m    890\u001b[0m                         \u001b[1;33m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                     )\n\u001b[0;32m    892\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                     last_output, outputs, new_h, runtime = standard_gru(\n\u001b[0m\u001b[0;32m    894\u001b[0m                         \u001b[1;33m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m                     )\n\u001b[0;32m    896\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;31m# previous and candidate state mixed by update gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_tm1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m     last_output, outputs, new_states = backend.rnn(\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[0;32m   4950\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflatted_inputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4951\u001b[0m         )\n\u001b[0;32m   4952\u001b[0m         \u001b[1;31m# output_time_zero is used to determine the cell output shape and its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4953\u001b[0m         \u001b[1;31m# dtype.  the value is discarded.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4954\u001b[1;33m         output_time_zero, _ = step_function(\n\u001b[0m\u001b[0;32m   4955\u001b[0m             \u001b[0minput_time_zero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_states\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m         )\n\u001b[0;32m   4957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\keras\\layers\\rnn\\gru.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecurrent_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;31m# previous and candidate state mixed by update gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_tm1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;31m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1408\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1409\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m         \u001b[1;31m# object that can implement the operator with knowledge of itself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;31m# and the tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1763\u001b[0m     new_vals = gen_sparse_ops.sparse_dense_cwise_mul(y.indices, y.values,\n\u001b[0;32m   1764\u001b[0m                                                      y.dense_shape, x, name)\n\u001b[0;32m   1765\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1766\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1767\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m    \u001b[1;33m*\u001b[0m \u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mWhen\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mincompatible\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m   \"\"\"\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\jedha_tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6576\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[0;32m   6577\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6578\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6579\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6580\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6581\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6582\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6583\u001b[0m       return mul_eager_fallback(\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["EPOCHS = 100\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(train):\n","    batch_loss = train_step(inp, targ)#, initial_state)\n","    total_loss += batch_loss\n","\n","    if batch % 10 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  \n","  # saving (checkpoint) the model every epoch\n","  checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss))\n","  print('Time taken for 1 epoch {} sec'.format(time.time() - start))\n","\n","  enc_input = X_val\n","  #classic encoder input\n","\n","  dec_input = tf.zeros(shape=(len(X_val),1))\n","  # the first decoder input is the special token 0\n","\n","  enc_out, enc_state = encoder(enc_input)#, initial_state)\n","  # we compute once and for all the encoder output and the encoder\n","  # h state and c state\n","\n","  dec_state = enc_state\n","  # The encoder h state and c state will serve as initial states for the\n","  # decoder\n","\n","  pred = []  # we'll store the predictions in here\n","\n","  # we loop over the expected length of the target, but actually the loop can run\n","  # for as many steps as we wish, which is the advantage of the encoder decoder\n","  # architecture\n","  for i in range(y_val.shape[1]-1):\n","    dec_out, dec_state, attention_w = decoder(dec_input, enc_out, dec_state)\n","    # the decoder state is updated and we get the first prediction probability \n","    # vector\n","    decoded_out = tf.expand_dims(tf.argmax(dec_out, axis=-1), axis=1)\n","    # we decode the softmax vector into and index\n","    pred.append(tf.expand_dims(dec_out,axis=1)) # update the prediction list\n","    dec_input = decoded_out # the previous pred will be used as the new input\n","\n","  pred = tf.concat(pred, axis=1).numpy()\n","  print(\"\\n val loss :\", loss_function(y_val[:,1:],pred),\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"rnnEFJ4elsda"},"source":["3. What do you think of the training process, did it work well on the train set?  On the validation set?"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1636997363787,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"WLK_47Bg_iU2"},"outputs":[],"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","encoder_latest=checkpoint.encoder\n","decoder_latest=checkpoint.decoder"]},{"cell_type":"markdown","metadata":{"id":"L1zjfpzkl2dl"},"source":["4. Use `X_val` to compute all the predictions for the validation set and convert them  back to text. Compare them with the actual target values, what do you think? What about the results on the training set?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1636997413027,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhACbICY03s2M31yuvkFW6Ft-VOK5GyGu_Tz68=s64","userId":"11930294859591867631"},"user_tz":-60},"id":"q_2bS3Cm_aDM","outputId":"8dc3c439-4a98-4724-9701-ade48daa3d61"},"outputs":[{"name":"stdout","output_type":"stream","text":["pred: my job my job\n","true: it's my cd\n","\n","\n","pred: i'm certain i'm certain\n","true: i'm baffled\n","\n","\n","pred: i guess please i\n","true: i wonder who\n","\n","\n","pred: you're stuck on cops\n","true: you're stuck\n","\n","\n","pred: they won they won\n","true: they won\n","\n","\n","pred: we are we done\n","true: we're done\n","\n","\n","pred: i'm not sad duty\n","true: i'm not shy\n","\n","\n","pred: tom is mad tom\n","true: tom's crazy\n","\n","\n","pred: you were shy you\n","true: you're thin\n","\n","\n","pred: i will did it\n","true: i did see it\n","\n","\n"]}],"source":["enc_input = X_val\n","#classic encoder input\n","\n","dec_input = tf.zeros(shape=(len(X_val),1))\n","# the first decoder input is the special token 0\n","\n","enc_out, enc_state = encoder_latest(enc_input)#, initial_state)\n","# we compute once and for all the encoder output and the encoder\n","# h state and c state\n","\n","dec_state = enc_state\n","# The encoder h state and c state will serve as initial states for the\n","# decoder\n","\n","pred = []  # we'll store the predictions in here\n","\n","# we loop over the expected length of the target, but actually the loop can run\n","# for as many steps as we wish, which is the advantage of the encoder decoder\n","# architecture\n","for i in range(y_val.shape[1]-1):\n","  dec_out, dec_state, attention_w = decoder_latest(dec_input, enc_out, dec_state)\n","  # the decoder state is updated and we get the first prediction probability \n","  # vector\n","  decoded_out = tf.expand_dims(tf.argmax(dec_out, axis=-1), axis=1)\n","  # we decode the softmax vector into and index\n","  pred.append(decoded_out) # update the prediction list\n","  dec_input = decoded_out # the previous pred will be used as the new input\n","\n","pred = tf.concat(pred, axis=-1).numpy()\n","\n","pred_text = tokenizer_en.sequences_to_texts(pred)\n","y_val_text = tokenizer_en.sequences_to_texts(y_val[:,1:])\n","for i in range(10):\n","  print(\"pred:\", pred_text[i])\n","  print(\"true:\", y_val_text[i])\n","  print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"WN2jMgLxmKPu"},"source":["5. Now that everything works well, it's time to increase our number of samples and start another training, did the results improve?"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"01-Translation_with_attention_solution.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
