{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Projects\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/mlflow-project.png\" width=\"600\" />\n",
    "\n",
    "## What you will learn in this course 🧐🧐\n",
    "\n",
    "What is very cool is to have a standard way of organizing your ML projects so that you can implement trainings easily. MLFlow projects lets you do that. In this course, you will learn: \n",
    "\n",
    "* What is MLFlow projects\n",
    "* How to organize an MLFlow projects\n",
    "* Understand config files in MLFlow projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MLFlow Projects? 🤔\n",
    "\n",
    "MLFlow Project is a way for you to standardize your projects so that you can use them with any types of technologies and train your models remotely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is structured an MLFlow Project 🗂️\n",
    "\n",
    "Now that you registered your metrics and your model, check out your working directory on your local machine. You should see an architecture that looks like this: \n",
    "\n",
    "```shell \n",
    "├── mlruns\n",
    "│   └── 0\n",
    "│       ├── 0a2b502f674949b4acb8dfce6549a7fb\n",
    "│       │   ├── artifacts\n",
    "│       │   │   └── model\n",
    "│       │   │       ├── MLmodel\n",
    "│       │   │       ├── conda.yaml\n",
    "│       │   │       └── model.pkl\n",
    "│       │   ├── meta.yaml\n",
    "│       │   ├── metrics\n",
    "│       │   │   └── Accuracy\n",
    "│       │   ├── params\n",
    "│       │   │   └── C\n",
    "│       │   └── tags\n",
    "│       │       ├── mlflow.log-model.history\n",
    "│       │       ├── mlflow.source.name\n",
    "│       │       ├── mlflow.source.type\n",
    "│       │       └── mlflow.user\n",
    "│       └── meta.yaml\n",
    "├── train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this structure what is actually important to understand is: \n",
    "\n",
    "- `artifacts` folder: where you store informations about your model to deploy it.\n",
    "- `meta.yaml` file: where you have all the information regarding your run.\n",
    "\n",
    "You can also find all that information on your **Mlflow tracking server**: \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/Mlflow_project_presentation.gif)\n",
    "\n",
    "\n",
    "> 👋 You might not exactly see the above structure on your local directory. It's okay, simply verify that the information is at least present on your remote server. \n",
    "\n",
    "For almost all folders, you already know what they are about (checkout our previous course on MLFlow if that's not the case). The main one that we haven't talked about is the `artifacts` folder. Let's explain the purpose of each of the containing files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifacts 🏛️\n",
    "\n",
    "Artifacts are the place where you have all the information regarding the environment when your model has been trained. Especially, you have three files: \n",
    "\n",
    "* `MLModel`\n",
    "* `conda.yml`\n",
    "* `model.pkl`, if you persisted a sklearn model. But you can have other types of files if you persisted a TensorFlow, Pytorch or any other type of model.\n",
    "\n",
    "Now if you set up your MLFLow tracking server remotely, you most likely have chosen Amazon S3 as your Artifact Store location instead of a local one. \n",
    "\n",
    "### `MLModel` \n",
    "\n",
    "An `MLModel` file should look something like this: \n",
    "\n",
    "```yaml\n",
    "artifact_path: model\n",
    "flavors:\n",
    "  python_function:\n",
    "    data: model.pkl\n",
    "    env: conda.yaml\n",
    "    loader_module: mlflow.sklearn\n",
    "    python_version: 3.7.3\n",
    "  sklearn:\n",
    "    pickled_model: model.pkl\n",
    "    serialization_format: cloudpickle\n",
    "    sklearn_version: 0.23.1\n",
    "run_id: 0a2b502f674949b4acb8dfce6549a7fb\n",
    "utc_time_created: '2020-06-14 17:23:39.122114'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives all necessary informations to run your model. Especially pay attention to: \n",
    "\n",
    "- `env`: by default you'll get a `conda` environment but you can setup a `Docker` environment,\n",
    "- `sklearn_version`: be really careful with the versions registered here as it might not be available in your servers.\n",
    "\n",
    "> 👋 If you are interested about the format of this file, `MLModel` takes its structure from `yaml` serialization language. It's a file extension widely used for configuration. Check out this documentation if you want to learn more: https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `conda.yaml`\n",
    "\n",
    "Just like `Docker`, Conda is a package and environment management system that is widely used in Data Science. MLFlow uses it to package models so that you can run your project on any server. A `conda.yaml` look like this: \n",
    "\n",
    "```yaml\n",
    "channels:\n",
    "- defaults\n",
    "dependencies:\n",
    "- python=3.7.3\n",
    "- scikit-learn=0.23.1\n",
    "- pip\n",
    "- pip:\n",
    "  - mlflow\n",
    "  - cloudpickle==1.4.1\n",
    "name: mlflow-env\n",
    "```\n",
    "\n",
    "As you can see, you have all the dependencies stated here. Again be careful with versions stated in your YAML file as some servers might not be able to run them.\n",
    "\n",
    "> 👋 Most likely you won't have to touch anything in this file. \n",
    "\n",
    "### `model.pkl`\n",
    "\n",
    "When you log a model using MLFlow, a file containing the model's information will be created. When it's a `sklearn` model, it's going to be a `.pkl` but you can have other types of files if you persisted a TensorFlow, Pytorch or any other type of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources 📚📚\n",
    "\n",
    "* <a href=\"https://mlflow.org/docs/latest/projects.html\" target=\"_blank\">Mlflow Projects</a>\n",
    "* <a href=\"https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html\" target=\"_blank\">Mflow Tutorial</a>\n",
    "* <a href=\"https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started\" target=\"_blank\">YAML Tutorial: Everything You Need to Get Started in Minutes</a>\n",
    "* <a href=\"https://docs.conda.io/en/latest/\" target=\"_blank\">Conda</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
