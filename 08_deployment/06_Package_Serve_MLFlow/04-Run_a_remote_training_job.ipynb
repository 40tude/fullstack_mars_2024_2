{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![snap](https://media4.giphy.com/media/Sb7WSbjHFNIL6/200.gif)\n",
    "\n",
    "# Run a remote training job\n",
    "\n",
    "## What you will learn in this course 🧐🧐\n",
    "\n",
    "Let's now experience the power of MLFlow. One of the main perks of packaging your training script is that you can run it on remote servers. In this course we will learn:\n",
    "\n",
    "* How to run a remote training job on a EC2 Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "\n",
    "For this course, we want to train an `sklearn` Random Forest and run a `GridSearch`. As you already know, this can be quite computation heavy. Therefore it makes it a perfect usecase for remote training! \n",
    "\n",
    "Here is what our project looks like:\n",
    "\n",
    "```\n",
    "├── MLproject\n",
    "├── secrets.sh\n",
    "└── train.py\n",
    "```\n",
    "\n",
    "👉 Check out the source code here: https://github.com/antoinekrajnc/mlflow_101 👈\n",
    "\n",
    "> 👋 You can also clone that repository: `git clone https://github.com/antoinekrajnc/mlflow_101`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote training process \n",
    "\n",
    "Now that you are familiar with the code, let us explain what we need to do to run a remote training job: \n",
    "\n",
    "1. We need to setup an EC2 instance where we need to: \n",
    "    * Choose lots of CPUs & RAM \n",
    "    * Install `docker`,  `git` and `mlflow` \n",
    "\n",
    "2. Set environment variables \n",
    "\n",
    "3. Run the project (`mlflow run PROJECT_URI`)\n",
    "\n",
    "Let's walk you through these steps one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step-1**: Setup EC2 Instance \n",
    "\n",
    "### Launch EC2 \n",
    "\n",
    "Let's first setup our EC2. If you feel a little rusty on how to setup an EC2, simply go back to our course **Introduction_to_EC2**. The higher CPU & RAM you choose the faster the training job. However checkout pricing before so that you don't get surprised! \n",
    "\n",
    "* [**EC2 Pricing List**](https://aws.amazon.com/fr/ec2/pricing/on-demand/)\n",
    "\n",
    "In this example, we will choose a `g4dn.8xlarge` Amazon Linux instance with:\n",
    "\n",
    "* 32 CPUs\n",
    "* 128 Go RAM \n",
    "\n",
    "This is basically a rocket computer 🚀\n",
    "\n",
    "### Configurations\n",
    " \n",
    "Before launching your EC2 instance though, go to *Configure Instance* > *User Data* and paste the following code:\n",
    "\n",
    "NB: Note that the initial #! to indicate EC2 that we are giving it a shell script to execute, you may find more specific info about this in the [AWS documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html#user-data-shell-scripts)\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "sudo yum update -y\n",
    "sudo yum install docker -y\n",
    "echo -e \"sudo service docker start\" >> .bashrc\n",
    "sudo usermod -a -G docker ec2-user\n",
    "sudo yum install git -y\n",
    "sudo yum install python3 -y\n",
    "sudo yum install python3-pip -y\n",
    "pip3 install mlflow\n",
    "```\n",
    "\n",
    "Just like this:\n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/EC2_Remote_tracking_setup.png)\n",
    "\n",
    "This code will be run when the instance will boot up. It simply:\n",
    "\n",
    "* Updates all currently installed packages \n",
    "* installs `docker` \n",
    "* turns on `docker` each time you connect to the instance\n",
    "* gives `ec2-user` sudo privileges \n",
    "* installs `git` \n",
    "* installs `python`\n",
    "* installs `pip`\n",
    "* installs `mlflow`\n",
    "\n",
    "> 👋 Don't worry, you don't need to remember this code by heart, you will go back to it when necessary! \n",
    "\n",
    "### Allow SSH\n",
    "\n",
    "Make sure you allowed SSH in your security group and you can launch your machine!\n",
    "\n",
    "\n",
    "### **Reboot your machine** \n",
    "\n",
    "As a final config, **you need to reboot your machine** as you ran commands that gave sudo privileges to `ec2-user`:\n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/EC2_Reboot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step-2**: Set environment variables \n",
    "\n",
    "### Securely send files to your EC2 instance\n",
    "Your EC2 instance is a new machine that you can connect to from your local computer, which means that by default any file that's on your local computer may not be accessed from the EC2 instance and vice versa. If you wish to send some file to your EC2 instance (for example a `secrets.sh` file with your environment variables) you may do so using a command like this:\n",
    "\n",
    "```shell\n",
    "scp -i name_of_your_ec2_authentication_file.pem name_of_the_file_you_want_to_send ec2-user@ec2-00-00-000-000.eu-west-3.compute.amazonaws.com:~/.\n",
    "```\n",
    "\n",
    "Note that you will need to modify the ec2 access point according the info in the ssh connect information page.\n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/EC2_SSH_connect.png)\n",
    "\n",
    "\n",
    "### SSH Into your instance \n",
    "\n",
    "Now you need to set your environment variables that you wrote in your `MLProject` file. In our case we have: \n",
    "\n",
    "*   `MLFLOW_TRACKING_URI`\n",
    "*   `AWS_ACCESS_KEY_ID`\n",
    "*   `AWS_SECRET_ACCESS_KEY`\n",
    "*   `BACKEND_STORE_URI`\n",
    "*   `ARTIFACT_ROOT`\n",
    "* `MLFLOW_EXPERIMENT_NAME`\n",
    "\n",
    "What you can do is to locally create a `secrets.sh` file containing the following commands:\n",
    "\n",
    "```bash\n",
    "export MLFLOW_TRACKING_URI=REPLACE_ME_WITH_YOUR_MLFLOW_TRACKING_URI\n",
    "export AWS_ACCESS_KEY_ID=REPLACE_ME_WITH_YOUR_AWS_ACCESS_KEY_ID\n",
    "export AWS_SECRET_ACCESS_KEY=REPLACE_ME_WITH_YOUR_AWS_SECRET_ACCESS_KEY\n",
    "export BACKEND_STORE_URI=REPLACE_ME_WITH_YOUR_BACKEND_STORE_URI\n",
    "export ARTIFACT_ROOT=REPLACE_ME_WITH_YOUR_ARTIFACT_ROOT\n",
    "export MLFLOW_EXPERIMENT_NAME=REPLACE_ME_WITH_YOUR_EXPERIMENT_NAME\n",
    "```\n",
    "\n",
    "Send it to your ec2 instance using `scp`.\n",
    "\n",
    "Ok now let's SSH into your instance. You can do it through your local terminal with a `.pem` file or you can SSH directly using Amazon GUI. Simply click on *Connect* \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/EC2_SSH_connect.png)\n",
    "\n",
    "> 👋 **IMPORTANT** Make sure that your user is set `ec2-user`\n",
    "\n",
    "Then run `source secrets.sh`. \n",
    "\n",
    "> 👋 you can verify that everything works correctly by running `echo $MLFLOW_TRACKING_URI` if you see your remote server URL appearing. It means that everything worked correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step-3**: Run the project\n",
    "\n",
    "Now the easiest way to run your project is to host it on a Github Repository and then, in your remote shell run: \n",
    "\n",
    "\n",
    "`mlflow run GITHUB_URL --build-image`\n",
    "\n",
    "The `--build-image` option is only valid for Docker projects. If specified, it will build a new Docker image that’s based on the image specified by the image field in the MLproject file, and contains files in the project directory.\n",
    "\n",
    "If the project is not running, it's probably because EC2 does not have access to other AWS services that let it use docker properly.\n",
    "\n",
    "And that's it! 😮\n",
    "\n",
    "If you want to try it out, you can use this course's Github URL - `https://github.com/antoinekrajnc/mlflow_101`\n",
    "\n",
    "> 👋 If you feel a little rusty on Git & Github, feel free to go back to our [Git & Github course](https://app.jedha.co/course/git-and-github-ft/git-and-github-ft-replay) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "Now lean back on your chair and watch your computer do the job! If you didn't have any errors, you will see some logs on your MLFlow remote server. In our case, the hyperparameter tuning took **8.4 min** on our `g4dn.8xlarge` against **48.6 min** on our local computer!! \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/remote_training_experience.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting \n",
    "\n",
    "Computers can be grumpy and therefore, you might encounter some bugs. To help you get through them, here is a list of verifications you can run: \n",
    "\n",
    "### scp file transfer is not working\n",
    "Type the following command in your local machine's console (make sure the `.pem` key is in your working directory):\n",
    "\n",
    "```bash\n",
    "chmod 400 your_key.pem\n",
    "```\n",
    "\n",
    "### Make sure installations were made\n",
    "\n",
    "First, there might be a problem with installations. It can be dependencies or with `docker`. To verify that everything has been installed, simply run: \n",
    "\n",
    "`mlflow --version` \n",
    "\n",
    "You should see a version number for mlflow appearing. If you see something like `mlflow is not a command` it means that it hasn't been installed. \n",
    "\n",
    "To check whether docker is installed, simply run: \n",
    "\n",
    "`sudo docker info`\n",
    "\n",
    "You should again see some information coming up about Docker.\n",
    "\n",
    "If some packages are not installed, you can copy-paste the following commands in the EC2 terminal and then **reboot** your EC2 instance:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "sudo yum update -y\n",
    "sudo yum install docker -y\n",
    "echo -e \"sudo service docker start\" >> .bashrc\n",
    "sudo usermod -a -G docker ec2-user\n",
    "sudo yum install git -y\n",
    "sudo yum install python3 -y\n",
    "sudo yum install python3-pip -y\n",
    "pip3 install mlflow\n",
    "```\n",
    "\n",
    "### Docker is not turned on\n",
    "\n",
    "Another verification that you need to run is whether `docker` is turned on. TO verify that, you should run:\n",
    "\n",
    "`sudo docker info` \n",
    "\n",
    "If you see an output like this:\n",
    "\n",
    "```\n",
    "Client:\n",
    " Context:    default\n",
    " Debug Mode: false\n",
    " Plugins:\n",
    "  app: Docker App (Docker Inc., v0.9.1-beta3)\n",
    "  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)\n",
    "  compose: Docker Compose (Docker Inc., 2.0.0-beta.1)\n",
    "  scan: Docker Scan (Docker Inc., v0.8.0)\n",
    "\n",
    "Server:\n",
    " Containers: 9\n",
    "  Running: 0\n",
    "  Paused: 0\n",
    "  Stopped: 9\n",
    " Images: 29\n",
    " Server Version: 20.10.6\n",
    "...\n",
    " HTTP Proxy: http.docker.internal:3128\n",
    " HTTPS Proxy: http.docker.internal:3128\n",
    " Registry: https://index.docker.io/v1/\n",
    " Labels:\n",
    " Experimental: false\n",
    " Insecure Registries:\n",
    "  127.0.0.0/8\n",
    " Live Restore Enabled: false\n",
    " ```\n",
    "\n",
    " It means that it is turned on. If you don't see it, simply run:\n",
    "\n",
    " `sudo service docker start`\n",
    "\n",
    "### Sudo is still necessary for your user \n",
    "\n",
    "Finally, one final verification you can do is to check whether your user has `sudo` privilege, meaning you don't have to `sudo COMMMAND` everything. Especially you need to be able to run `docker` directly without `sudo`. \n",
    "\n",
    "To verify that, simply run: \n",
    "\n",
    "`docker info`\n",
    "\n",
    "If you see an output like `Permission denied`, it means that your user doesn't have `sudo` privilege and you need to grant it. To do so, run:\n",
    "\n",
    "`sudo usermod -a -G docker REPLACE_BY_YOUR_USERNAME`\n",
    "\n",
    "then you need to **reboot** your instance and it should work. \n",
    "\n",
    "> 👋 In the tutorial, our username was `ec2-user` which is usually the default username. To verify that it is yours too, simply search for it here when you SSH to your instance: \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/EC2_username.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources 📚📚\n",
    "\n",
    "* [EC2 Pricing List](https://aws.amazon.com/fr/ec2/pricing/on-demand/)\n",
    "* [How to run a command at EC2 Instance RE-boot?](https://stackoverflow.com/questions/70582211/how-to-run-a-command-at-ec2-instance-re-boot?noredirect=1#comment124780237_70582211)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
