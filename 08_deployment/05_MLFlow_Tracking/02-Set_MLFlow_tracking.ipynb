{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set MLFlow Tracking \n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/mlflow-tracking.png\" width=\"600\" />\n",
    "\n",
    "## What you will learn in this course ðŸ§ðŸ§\n",
    "\n",
    "Let's start with MLFlow Tracking. This component of the API lets you collaborate on building Machine Learning models as you will be able to track each important metric of your models as you are training them.\n",
    "\n",
    "* What is MLFlow Tracking \n",
    "* How to install MLFlow\n",
    "* Set up MLFLow tracking on a remote server using Docker & Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MLFlow Tracking?\n",
    "\n",
    "MLFlow tracking is here to help you to: \n",
    "\n",
    "* Monitor your ML trainings,\n",
    "* Log parameters for hyper-parameter tuning,\n",
    "* Log metrics for assessing for model performance.\n",
    "\n",
    "When you are working in teams, an MLFlow tracking server is setup and all data scientists logs into it when they are building their models. This is what we will be building in this course.\n",
    "\n",
    "> ðŸ‘‹ From now on, we will be using a little bit of vocabulary that you need to be familiar with to understand the rest of the course: \n",
    "> * **Experiment**: We qualify anything related to building an ML model as an experiment. \n",
    "> * **Persisting**: Relates to save (a model) as a set of files to be able to use it in a production environment. \n",
    "> * **Serve a model**: Relates to using a model in a production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MLFlow remote server \n",
    "\n",
    "At the heart of MLFlow is the idea of **collaboration**. Using it locally would be underestimating its capacities. Therefore, we'll be building a **remote tracking server** to use MLFlow tracking to its fullest. Here is the architecture we will need to build: \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/MLFlow-tracking-server.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain this diagram a little bit: \n",
    "\n",
    "* **MLFlow (tracking) Server**: This is the first step. We will need to build a tracking server using [Heroku](https://www.heroku.com/) & [Docker](https://docker.com) so that anybody in our Data Science team will be able to monitor their experiments. \n",
    "\n",
    "* **Backend Store**: All the information related to an experiment needs to be stored in a SQL Database as MLFlow uses [SQLAlchemy](https://app.jedha.co/course/etl-processes-ft/sqlalchemy-ft) as its backend language to store data. For this, we will be using [Heroku Postgres](https://data.heroku.com/) datastore. It's free and works exactly as a PostgreSQL DB.\n",
    "\n",
    "* **Artifact Store**: Finally, each time anybody in your team will train a model, we will want to persist it somewhere so that anybody can use it and serve it. \n",
    "\n",
    "\n",
    "Although it seems complicated at a first glance, it's actually not. We'll be using technologies that we already know about: \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/MLFlow-tracking-server-Technologies.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example App \n",
    "\n",
    "Before we start, you can check out the end work on this app:\n",
    "\n",
    "* [Checkout MLFlow remote tracking server](https://sample-mlflow-app.herokuapp.com/)\n",
    "\n",
    "> ðŸ‘‹ It might take up to 2 minutes to open up since the app is hosted on a heroku free dyno. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your own remote server ðŸ—ï¸\n",
    "\n",
    "Alright, let's build our own remote server. You will need to follow these steps:\n",
    "\n",
    "#### **Step-1a**: Build a Docker container \n",
    "\n",
    "Your first step is to build a Docker container by writing a `Dockerfile`. Here is an example you can follow: \n",
    "\n",
    "```Dockerfile\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "WORKDIR /home/app\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get install nano unzip\n",
    "RUN apt install curl -y\n",
    "\n",
    "RUN curl -fsSL https://get.deta.dev/cli.sh | sh\n",
    "\n",
    "RUN curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "RUN unzip awscliv2.zip\n",
    "RUN ./aws/install\n",
    "\n",
    "COPY requirements.txt /dependencies/requirements.txt\n",
    "RUN pip install -r /dependencies/requirements.txt\n",
    "\n",
    "ENV AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID\n",
    "ENV AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY\n",
    "ENV BACKEND_STORE_URI=$BACKEND_STORE_URI\n",
    "ENV ARTIFACT_STORE_URI=$ARTIFACT_STORE_URI\n",
    "\n",
    "CMD mlflow server -p $PORT \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --backend-store-uri $BACKEND_STORE_URI \\\n",
    "    --default-artifact-root $ARTIFACT_STORE_URI\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "This `Dockerfile` starts from [`miniconda`](https://hub.docker.com/r/continuumio/miniconda3) image in which we add:\n",
    "\n",
    "* `aws` cli \n",
    "* `nano` - to be able to edit files directly from console\n",
    "* `curl` - to be able to download files\n",
    "* `unzip` - to be able to unzip files \n",
    "* `requirements.txt` - dependencies that contains:\n",
    "    ```\n",
    "    boto3\n",
    "    pandas \n",
    "    gunicorn \n",
    "    streamlit \n",
    "    sklearn \n",
    "    matplotlib \n",
    "    seaborn \n",
    "    plotly\n",
    "    mlflow\n",
    "    psycopg2-binary\n",
    "    ```\n",
    "* We setup several *environment variables* that we will setup on Heroku later on \n",
    "\n",
    "\n",
    "Now once you `Dockerfile` is ready, you can build you image:\n",
    "\n",
    "* `docker build . -t sample-mlflow-server`\n",
    "\n",
    "Then you can run your container:\n",
    "\n",
    "```\n",
    ">docker run -it\\\n",
    "> -p 4000:4000\\\n",
    "> -v \"$(pwd):/home/app\"\\\n",
    "> -e PORT=4000\\\n",
    "> -e AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID\\\n",
    "> -e AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY\\\n",
    "> -e BACKEND_STORE_URI=YOUR_BACKEND_STORE_URI\\\n",
    "> -e ARTIFACT_STORE_URI=ARTIFACT_STORE_URI\\\n",
    "sample-mlflow-server\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "\n",
    "```\n",
    "[2022-01-02 17:01:40 +0000] [15] [INFO] Starting gunicorn 20.1.0\n",
    "[2022-01-02 17:01:40 +0000] [15] [INFO] Listening at: http://0.0.0.0:4000 (15)\n",
    "[2022-01-02 17:01:40 +0000] [15] [INFO] Using worker: sync\n",
    "[2022-01-02 17:01:40 +0000] [16] [INFO] Booting worker with pid: 16\n",
    "[2022-01-02 17:01:40 +0000] [17] [INFO] Booting worker with pid: 17\n",
    "[2022-01-02 17:01:40 +0000] [18] [INFO] Booting worker with pid: 18\n",
    "[2022-01-02 17:01:40 +0000] [19] [INFO] Booting worker with pid: 19\n",
    "```\n",
    "\n",
    "Now open up your browser and paste `http://0.0.0.0:4000`, you should see MLFlow UI appearing on your screen (if it does not work do not worry and keep following the demo):\n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/MLFlow_local_server.png)\n",
    "\n",
    "\n",
    "If you see it, you are done with half of the first step ðŸŽ‰\n",
    "\n",
    "> ðŸ‘‹ If you move around your app, you will see some bugs appearing. It's completely normal. It's because we haven't setup our Backend & Artifact Store and we haven't set them up in our Environment variables. But we will do them later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step-1b**: Ship your container to heroku \n",
    "\n",
    "Now that your container works locally, you can directly ship it to Heroku: \n",
    "\n",
    "* `heroku create APP_NAME` - Create your app\n",
    "* `heroku container:login` - make sure heroku and docker can talk together\n",
    "* `heroku container:push web -a APP_NAME` - Push your container to heroku \n",
    "* `heroku container:release web -a APP_NAME` - Release container \n",
    "* `heroku open -a APP_NAME` - Open your app on your web browser.\n",
    "\n",
    "Now you should see the exact same application with a real URL this time. \n",
    "\n",
    "> ðŸ‘‹ Again, you will see bugs on your app if you navigate it. It's for the exact same reason than in `step-1a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step-2**: Create your Backend store \n",
    "\n",
    "Now, let's create our Backend store. To do so: \n",
    "\n",
    "1. [Install Heroku Postgres](https://elements.heroku.com/addons/heroku-postgresql) on your heroku Account\n",
    "2. On the submission form, select a **Hobby Dev - Free** plan and choose the application you need attach your DB to. \n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/Heroku_postgres_installation.png)\n",
    "\n",
    "3. You should be prompted to this screen\n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/Heroku_postgres_dashboard.png)\n",
    "\n",
    "4. Now click on `Heroku postgres` > `Settings` > `View Credentials` and you will be able to see the backend store uri that you will need to copy/paste in your environment variable\n",
    "\n",
    "![crack](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/Heroku_postgres_URI.png)\n",
    "\n",
    "> ðŸ‘‹ **IMPORTANT**, your URI looks something like this: `postgres://...`. **YOU NEED TO REPLACE IT BY**: `postgresql://...` in your `$BACKEND_STORE_URI` environment variable\n",
    "\n",
    "<Video video='https://vimeo.com/661767872' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step-3**: Create your Artifact Store\n",
    "\n",
    "To create your artifact store, simply [create an S3 Bucket](https://app.jedha.co/course/data-storage-ft/simple-storage-service-ft). Now look for your bucket's URI: \n",
    "\n",
    "![snap](https://full-stack-assets.s3.eu-west-3.amazonaws.com/Deployment/S3_URI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step-4**: Paste your environment variables at the right place\n",
    "\n",
    "Alright, we have all the components we need. Now the final thing to do is to set up **environment variables**. You need to gather the following:\n",
    "\n",
    "* Your [AWS credentials](https://app.jedha.co/course/data-storage-ft/iam-ft). Especially:\n",
    "    * `AWS_ACCESS_KEY_ID`\n",
    "    * `AWS_SECRET_ACCESS_KEY`\n",
    "* Your `BACKEND_STORE_URI` (on Heroku)\n",
    "* Your `ARTIFACT_STORE_URI` (Your S3 Bucket)\n",
    "\n",
    "> ðŸ‘‹ Also if you want to run your app locally using Docker, you can simply run the following command:\n",
    "> ```\n",
    ">docker run -it\\\n",
    "> -p 4000:4000\\\n",
    "> -v \"$(pwd):/home/app\"\\\n",
    "> -e PORT=4000\\\n",
    "> -e AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID\\\n",
    "> -e AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY\\\n",
    "> -e BACKEND_STORE_URI=YOUR_BACKEND_STORE_URI\\\n",
    "> -e ARTIFACT_STORE_URI=ARTIFACT_STORE_URI\\\n",
    "sample-mlflow-server\n",
    "> ```\n",
    ">\n",
    "> ðŸ‘‹ ðŸ‘‹ **IMPORTANT** Again, for your `BACKEND_STORE_URI` you need to replace `postgres://...` by `postgresql://...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try MLFlow tracking\n",
    "\n",
    "Now if everything works correctly, we should be able to run an experiment and our server should be able to track it. Create a `train.py` file and copy/past the following code:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "from random import random, randint\n",
    "\n",
    "# Set tracking URI to your Heroku application\n",
    "mlflow.set_tracking_uri(os.environ[\"APP_URI\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Log a parameter (key-value pair)\n",
    "    log_param(\"param1\", randint(0, 100))\n",
    "\n",
    "    # Log a metric; metrics can be updated throughout the run\n",
    "    log_metric(\"foo\", random())\n",
    "    log_metric(\"foo\", random() + 1)\n",
    "    log_metric(\"foo\", random() + 2)\n",
    "\n",
    "    # Log an artifact (output file)\n",
    "    if not os.path.exists(\"outputs\"):\n",
    "        os.makedirs(\"outputs\")\n",
    "    with open(\"outputs/test.txt\", \"w\") as f:\n",
    "        f.write(\"hello world!\")\n",
    "    log_artifacts(\"outputs\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your code using Docker and the image you built in your Dockerfile at the beginning of this tutorial. Here is the command: \n",
    "\n",
    "```\n",
    "docker run -it\\\n",
    " -p 4000:4000\\\n",
    " -v \"$(pwd):/home/app\"\\\n",
    " -e APP_URI=\"APP_URI\"\\\n",
    " -e AWS_ACCESS_KEY_ID=\"AWS_ACCESS_KEY_ID\"\\\n",
    " -e AWS_SECRET_ACCESS_KEY=\"AWS_SECRET_ACCESS_KEY\"\\\n",
    " sample-mlflow-server python train.py\n",
    "```\n",
    "\n",
    "Go back to your heroku app, refresh the page and you should see some new information that appeared ðŸ˜‰\n",
    "\n",
    "> ðŸ‘‹ If, for some reason, your image is not working use Jedha's image `jedha/sample-mlflow-server`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources ðŸ“šðŸ“š\n",
    "\n",
    "* [SQLAlchemy Core Engine](https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls)\n",
    "* [Heroku Postgres](https://devcenter.heroku.com/articles/heroku-postgresql)\n",
    "* [Connecting to Heroku Postgres Databases from Outside of Heroku](https://devcenter.heroku.com/articles/connecting-to-heroku-postgres-databases-from-outside-of-heroku)\n",
    "* [Set Up MLflow on AWS EC2 Using Docker, S3, and RDS](https://aws.plainenglish.io/set-up-mlflow-on-aws-ec2-using-docker-s3-and-rds-90d96798e555)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
